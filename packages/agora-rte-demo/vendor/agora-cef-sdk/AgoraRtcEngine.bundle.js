/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else {
		var a = factory();
		for(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];
	}
})(self, function() {
return /******/ (function() { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./src/AgoraRtcEngine.ts":
/*!*******************************!*\
  !*** ./src/AgoraRtcEngine.ts ***!
  \*******************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AgoraRtcEngine\": function() { return /* binding */ AgoraRtcEngine; }\n/* harmony export */ });\nvar __spreadArrays = (undefined && undefined.__spreadArrays) || function () {\n    for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\n    for (var r = Array(s), k = 0, i = 0; i < il; i++)\n        for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\n            r[k] = a[j];\n    return r;\n};\nvar YUVCanvas = __webpack_require__(/*! yuv-canvas */ \"./node_modules/yuv-canvas/src/yuv-canvas.js\");\nvar YUVBuffer = __webpack_require__(/*! yuv-buffer */ \"./node_modules/yuv-buffer/yuv-buffer.js\");\n/**\n * @ignore\n */\nvar API_TYPE;\n(function (API_TYPE) {\n    API_TYPE[API_TYPE[\"INITIALIZE\"] = 0] = \"INITIALIZE\";\n    API_TYPE[API_TYPE[\"RELEASE\"] = 1] = \"RELEASE\";\n    API_TYPE[API_TYPE[\"SET_CHANNEL_PROFILE\"] = 2] = \"SET_CHANNEL_PROFILE\";\n    API_TYPE[API_TYPE[\"SET_CLIENT_ROLE\"] = 3] = \"SET_CLIENT_ROLE\";\n    API_TYPE[API_TYPE[\"JOIN_CHANNEL\"] = 4] = \"JOIN_CHANNEL\";\n    API_TYPE[API_TYPE[\"SWITCH_CHANNEL\"] = 5] = \"SWITCH_CHANNEL\";\n    API_TYPE[API_TYPE[\"LEAVE_CHANNEL\"] = 6] = \"LEAVE_CHANNEL\";\n    API_TYPE[API_TYPE[\"RE_NEW_TOKEN\"] = 7] = \"RE_NEW_TOKEN\";\n    API_TYPE[API_TYPE[\"REGISTER_LOCAL_USER_ACCOUNT\"] = 8] = \"REGISTER_LOCAL_USER_ACCOUNT\";\n    API_TYPE[API_TYPE[\"JOIN_CHANNEL_WITH_USER_ACCOUNT\"] = 9] = \"JOIN_CHANNEL_WITH_USER_ACCOUNT\";\n    API_TYPE[API_TYPE[\"GET_USER_INFO_BY_USER_ACCOUNT\"] = 10] = \"GET_USER_INFO_BY_USER_ACCOUNT\";\n    API_TYPE[API_TYPE[\"GET_USER_INFO_BY_UID\"] = 11] = \"GET_USER_INFO_BY_UID\";\n    API_TYPE[API_TYPE[\"START_ECHO_TEST\"] = 12] = \"START_ECHO_TEST\";\n    API_TYPE[API_TYPE[\"START_ECHO_TEST_2\"] = 13] = \"START_ECHO_TEST_2\";\n    API_TYPE[API_TYPE[\"STOP_ECHO_TEST\"] = 14] = \"STOP_ECHO_TEST\";\n    API_TYPE[API_TYPE[\"ENABLE_VIDEO\"] = 15] = \"ENABLE_VIDEO\";\n    API_TYPE[API_TYPE[\"DISABLE_VIDEO\"] = 16] = \"DISABLE_VIDEO\";\n    API_TYPE[API_TYPE[\"SET_VIDEO_PROFILE\"] = 17] = \"SET_VIDEO_PROFILE\";\n    API_TYPE[API_TYPE[\"SET_VIDEO_ENCODER_CONFIGURATION\"] = 18] = \"SET_VIDEO_ENCODER_CONFIGURATION\";\n    API_TYPE[API_TYPE[\"SET_CAMERA_CAPTURER_CONFIGURATION\"] = 19] = \"SET_CAMERA_CAPTURER_CONFIGURATION\";\n    API_TYPE[API_TYPE[\"SET_UP_LOCAL_VIDEO\"] = 20] = \"SET_UP_LOCAL_VIDEO\";\n    API_TYPE[API_TYPE[\"SET_UP_REMOTE_VIDEO\"] = 21] = \"SET_UP_REMOTE_VIDEO\";\n    API_TYPE[API_TYPE[\"START_PREVIEW\"] = 22] = \"START_PREVIEW\";\n    API_TYPE[API_TYPE[\"SET_REMOTE_USER_PRIORITY\"] = 23] = \"SET_REMOTE_USER_PRIORITY\";\n    API_TYPE[API_TYPE[\"STOP_PREVIEW\"] = 24] = \"STOP_PREVIEW\";\n    API_TYPE[API_TYPE[\"ENABLE_AUDIO\"] = 25] = \"ENABLE_AUDIO\";\n    API_TYPE[API_TYPE[\"ENABLE_LOCAL_AUDIO\"] = 26] = \"ENABLE_LOCAL_AUDIO\";\n    API_TYPE[API_TYPE[\"DISABLE_AUDIO\"] = 27] = \"DISABLE_AUDIO\";\n    API_TYPE[API_TYPE[\"SET_AUDIO_PROFILE\"] = 28] = \"SET_AUDIO_PROFILE\";\n    API_TYPE[API_TYPE[\"MUTE_LOCAL_AUDIO_STREAM\"] = 29] = \"MUTE_LOCAL_AUDIO_STREAM\";\n    API_TYPE[API_TYPE[\"MUTE_ALL_REMOTE_AUDIO_STREAMS\"] = 30] = \"MUTE_ALL_REMOTE_AUDIO_STREAMS\";\n    API_TYPE[API_TYPE[\"SET_DEFAULT_MUTE_ALL_REMOTE_AUDIO_STREAMS\"] = 31] = \"SET_DEFAULT_MUTE_ALL_REMOTE_AUDIO_STREAMS\";\n    API_TYPE[API_TYPE[\"ADJUST_USER_PLAYBACK_SIGNAL_VOLUME\"] = 32] = \"ADJUST_USER_PLAYBACK_SIGNAL_VOLUME\";\n    API_TYPE[API_TYPE[\"MUTE_REMOTE_AUDIO_STREAM\"] = 33] = \"MUTE_REMOTE_AUDIO_STREAM\";\n    API_TYPE[API_TYPE[\"MUTE_LOCAL_VIDEO_STREAM\"] = 34] = \"MUTE_LOCAL_VIDEO_STREAM\";\n    API_TYPE[API_TYPE[\"ENABLE_LOCAL_VIDEO\"] = 35] = \"ENABLE_LOCAL_VIDEO\";\n    API_TYPE[API_TYPE[\"MUTE_ALL_REMOTE_VIDEO_STREAMS\"] = 36] = \"MUTE_ALL_REMOTE_VIDEO_STREAMS\";\n    API_TYPE[API_TYPE[\"SET_DEFAULT_MUTE_ALL_REMOTE_VIDEO_STREAMS\"] = 37] = \"SET_DEFAULT_MUTE_ALL_REMOTE_VIDEO_STREAMS\";\n    API_TYPE[API_TYPE[\"MUTE_REMOTE_VIDEO_STREAM\"] = 38] = \"MUTE_REMOTE_VIDEO_STREAM\";\n    API_TYPE[API_TYPE[\"SET_REMOTE_VIDEO_STREAM_TYPE\"] = 39] = \"SET_REMOTE_VIDEO_STREAM_TYPE\";\n    API_TYPE[API_TYPE[\"SET_REMOTE_DEFAULT_VIDEO_STREAM_TYPE\"] = 40] = \"SET_REMOTE_DEFAULT_VIDEO_STREAM_TYPE\";\n    API_TYPE[API_TYPE[\"ENABLE_AUDIO_VOLUME_INDICATION\"] = 41] = \"ENABLE_AUDIO_VOLUME_INDICATION\";\n    API_TYPE[API_TYPE[\"START_AUDIO_RECORDING\"] = 42] = \"START_AUDIO_RECORDING\";\n    API_TYPE[API_TYPE[\"START_AUDIO_RECORDING2\"] = 43] = \"START_AUDIO_RECORDING2\";\n    API_TYPE[API_TYPE[\"STOP_AUDIO_RECORDING\"] = 44] = \"STOP_AUDIO_RECORDING\";\n    API_TYPE[API_TYPE[\"ENABLE_FACE_DETECTION\"] = 62] = \"ENABLE_FACE_DETECTION\";\n    API_TYPE[API_TYPE[\"SET_REMOTE_VOICE_POSITIONN\"] = 73] = \"SET_REMOTE_VOICE_POSITIONN\";\n    API_TYPE[API_TYPE[\"SET_LOG_FILE\"] = 79] = \"SET_LOG_FILE\";\n    API_TYPE[API_TYPE[\"SET_LOG_FILTER\"] = 80] = \"SET_LOG_FILTER\";\n    API_TYPE[API_TYPE[\"SET_LOG_FILE_SIZE\"] = 81] = \"SET_LOG_FILE_SIZE\";\n    API_TYPE[API_TYPE[\"SET_LOCAL_RENDER_MODE\"] = 82] = \"SET_LOCAL_RENDER_MODE\";\n    API_TYPE[API_TYPE[\"SET_LOCAL_RENDER_MODE_2\"] = 83] = \"SET_LOCAL_RENDER_MODE_2\";\n    API_TYPE[API_TYPE[\"SET_REMOTE_RENDER_MODE\"] = 84] = \"SET_REMOTE_RENDER_MODE\";\n    API_TYPE[API_TYPE[\"SET_REMOTE_RENDER_MODE_2\"] = 85] = \"SET_REMOTE_RENDER_MODE_2\";\n    API_TYPE[API_TYPE[\"SET_LOCAL_VIDEO_MIRROR_MODE\"] = 86] = \"SET_LOCAL_VIDEO_MIRROR_MODE\";\n    API_TYPE[API_TYPE[\"ENABLE_DUAL_STREAM_MODE\"] = 87] = \"ENABLE_DUAL_STREAM_MODE\";\n    API_TYPE[API_TYPE[\"ADJUST_RECORDING_SIGNAL_VOLUME\"] = 93] = \"ADJUST_RECORDING_SIGNAL_VOLUME\";\n    API_TYPE[API_TYPE[\"ADJUST_PLAYBACK_SIGNAL_VOLUME\"] = 94] = \"ADJUST_PLAYBACK_SIGNAL_VOLUME\";\n    API_TYPE[API_TYPE[\"ENABLE_WEB_SDK_INTEROPER_ABILITY\"] = 95] = \"ENABLE_WEB_SDK_INTEROPER_ABILITY\";\n    API_TYPE[API_TYPE[\"SET_VIDEO_QUALITY_PARAMETERS\"] = 96] = \"SET_VIDEO_QUALITY_PARAMETERS\";\n    API_TYPE[API_TYPE[\"SET_LOCAL_PUBLISH_FALLBACK_OPTION\"] = 97] = \"SET_LOCAL_PUBLISH_FALLBACK_OPTION\";\n    API_TYPE[API_TYPE[\"SET_REMOTE_SUBSCRIBE_FALLBACK_OPTION\"] = 98] = \"SET_REMOTE_SUBSCRIBE_FALLBACK_OPTION\";\n    API_TYPE[API_TYPE[\"SWITCH_CAMERA\"] = 99] = \"SWITCH_CAMERA\";\n    API_TYPE[API_TYPE[\"SWITCH_CAMERA_2\"] = 100] = \"SWITCH_CAMERA_2\";\n    API_TYPE[API_TYPE[\"SET_DEFAULT_AUDIO_ROUTE_SPEAKER_PHONE\"] = 101] = \"SET_DEFAULT_AUDIO_ROUTE_SPEAKER_PHONE\";\n    API_TYPE[API_TYPE[\"SET_ENABLE_SPEAKER_PHONE\"] = 102] = \"SET_ENABLE_SPEAKER_PHONE\";\n    API_TYPE[API_TYPE[\"ENABLE_IN_EAR_MONITORING\"] = 103] = \"ENABLE_IN_EAR_MONITORING\";\n    API_TYPE[API_TYPE[\"SET_IN_EAR_MONITORING_VOLUME\"] = 104] = \"SET_IN_EAR_MONITORING_VOLUME\";\n    API_TYPE[API_TYPE[\"IS_SPEAKER_PHONE_ENABLED\"] = 105] = \"IS_SPEAKER_PHONE_ENABLED\";\n    API_TYPE[API_TYPE[\"SET_AUDIO_SESSION_OPERATION_RESTRICTION\"] = 106] = \"SET_AUDIO_SESSION_OPERATION_RESTRICTION\";\n    API_TYPE[API_TYPE[\"ENABLE_LOOP_BACK_RECORDING\"] = 107] = \"ENABLE_LOOP_BACK_RECORDING\";\n    API_TYPE[API_TYPE[\"START_SCREEN_CAPTURE_BY_DISPLAY_ID\"] = 108] = \"START_SCREEN_CAPTURE_BY_DISPLAY_ID\";\n    API_TYPE[API_TYPE[\"START_SCREEN_CAPTURE_BY_SCREEN_RECT\"] = 109] = \"START_SCREEN_CAPTURE_BY_SCREEN_RECT\";\n    API_TYPE[API_TYPE[\"START_SCREEN_CAPTURE_BY_WINDOW_ID\"] = 110] = \"START_SCREEN_CAPTURE_BY_WINDOW_ID\";\n    API_TYPE[API_TYPE[\"SET_SCREEN_CAPTURE_CONTENT_HINT\"] = 111] = \"SET_SCREEN_CAPTURE_CONTENT_HINT\";\n    API_TYPE[API_TYPE[\"UPDATE_SCREEN_CAPTURE_PARAMETERS\"] = 112] = \"UPDATE_SCREEN_CAPTURE_PARAMETERS\";\n    API_TYPE[API_TYPE[\"UPDATE_SCREEN_CAPTURE_REGION\"] = 113] = \"UPDATE_SCREEN_CAPTURE_REGION\";\n    API_TYPE[API_TYPE[\"STOP_SCREEN_CAPTURE\"] = 114] = \"STOP_SCREEN_CAPTURE\";\n    API_TYPE[API_TYPE[\"GET_CALL_ID\"] = 117] = \"GET_CALL_ID\";\n    API_TYPE[API_TYPE[\"RATE\"] = 118] = \"RATE\";\n    API_TYPE[API_TYPE[\"COMPLAIN\"] = 119] = \"COMPLAIN\";\n    API_TYPE[API_TYPE[\"GET_VERSION\"] = 120] = \"GET_VERSION\";\n    API_TYPE[API_TYPE[\"ENABLE_LAST_MILE_TEST\"] = 121] = \"ENABLE_LAST_MILE_TEST\";\n    API_TYPE[API_TYPE[\"DISABLE_LAST_MILE_TEST\"] = 122] = \"DISABLE_LAST_MILE_TEST\";\n    API_TYPE[API_TYPE[\"START_LAST_MILE_PROBE_TEST\"] = 123] = \"START_LAST_MILE_PROBE_TEST\";\n    API_TYPE[API_TYPE[\"STOP_LAST_MILE_PROBE_TEST\"] = 124] = \"STOP_LAST_MILE_PROBE_TEST\";\n    API_TYPE[API_TYPE[\"GET_ERROR_DESCRIPTION\"] = 125] = \"GET_ERROR_DESCRIPTION\";\n    API_TYPE[API_TYPE[\"SET_ENCRYPTION_SECTRT\"] = 126] = \"SET_ENCRYPTION_SECTRT\";\n    API_TYPE[API_TYPE[\"SET_ENCRYPTION_MODE\"] = 127] = \"SET_ENCRYPTION_MODE\";\n    API_TYPE[API_TYPE[\"REGISTER_PACKET_OBSERVER\"] = 128] = \"REGISTER_PACKET_OBSERVER\";\n    API_TYPE[API_TYPE[\"CREATE_DATA_STREAM\"] = 129] = \"CREATE_DATA_STREAM\";\n    API_TYPE[API_TYPE[\"SEND_STREAM_MESSAGE\"] = 130] = \"SEND_STREAM_MESSAGE\";\n    API_TYPE[API_TYPE[\"ADD_PUBLISH_STREAM_URL\"] = 131] = \"ADD_PUBLISH_STREAM_URL\";\n    API_TYPE[API_TYPE[\"REMOVE_PUBLISH_STREAM_URL\"] = 132] = \"REMOVE_PUBLISH_STREAM_URL\";\n    API_TYPE[API_TYPE[\"SET_LIVE_TRANSCODING\"] = 133] = \"SET_LIVE_TRANSCODING\";\n    API_TYPE[API_TYPE[\"ADD_VIDEO_WATER_MARK\"] = 134] = \"ADD_VIDEO_WATER_MARK\";\n    API_TYPE[API_TYPE[\"ADD_VIDEO_WATER_MARK_2\"] = 135] = \"ADD_VIDEO_WATER_MARK_2\";\n    API_TYPE[API_TYPE[\"CLEAR_VIDEO_WATER_MARKS\"] = 136] = \"CLEAR_VIDEO_WATER_MARKS\";\n    API_TYPE[API_TYPE[\"SET_BEAUTY_EFFECT_OPTIONS\"] = 137] = \"SET_BEAUTY_EFFECT_OPTIONS\";\n    API_TYPE[API_TYPE[\"ADD_INJECT_STREAM_URL\"] = 138] = \"ADD_INJECT_STREAM_URL\";\n    API_TYPE[API_TYPE[\"START_CHANNEL_MEDIA_RELAY\"] = 139] = \"START_CHANNEL_MEDIA_RELAY\";\n    API_TYPE[API_TYPE[\"UPDATE_CHANNEL_MEDIA_RELAY\"] = 140] = \"UPDATE_CHANNEL_MEDIA_RELAY\";\n    API_TYPE[API_TYPE[\"STOP_CHANNEL_MEDIA_RELAY\"] = 141] = \"STOP_CHANNEL_MEDIA_RELAY\";\n    API_TYPE[API_TYPE[\"REMOVE_INJECT_STREAM_URL\"] = 142] = \"REMOVE_INJECT_STREAM_URL\";\n    API_TYPE[API_TYPE[\"GET_CONNECTION_STATE\"] = 143] = \"GET_CONNECTION_STATE\";\n    API_TYPE[API_TYPE[\"REGISTER_MEDIA_META_DATA_OBSERVER\"] = 144] = \"REGISTER_MEDIA_META_DATA_OBSERVER\";\n    API_TYPE[API_TYPE[\"SET_PARAMETERS\"] = 145] = \"SET_PARAMETERS\";\n    API_TYPE[API_TYPE[\"SET_PLAYBACK_DEVICE_VOLUME\"] = 146] = \"SET_PLAYBACK_DEVICE_VOLUME\";\n    API_TYPE[API_TYPE[\"PUBLISH\"] = 147] = \"PUBLISH\";\n    API_TYPE[API_TYPE[\"UNPUBLISH\"] = 148] = \"UNPUBLISH\";\n    API_TYPE[API_TYPE[\"CHANNEL_ID\"] = 149] = \"CHANNEL_ID\";\n    API_TYPE[API_TYPE[\"SEND_METADATA\"] = 150] = \"SEND_METADATA\";\n    API_TYPE[API_TYPE[\"SET_MAX_META_SIZE\"] = 151] = \"SET_MAX_META_SIZE\";\n    API_TYPE[API_TYPE[\"PUSH_AUDIO_FRAME\"] = 152] = \"PUSH_AUDIO_FRAME\";\n    API_TYPE[API_TYPE[\"PUSH_AUDIO_FRAME_2\"] = 153] = \"PUSH_AUDIO_FRAME_2\";\n    API_TYPE[API_TYPE[\"PULL_AUDIO_FRAME\"] = 154] = \"PULL_AUDIO_FRAME\";\n    API_TYPE[API_TYPE[\"SET_EXTERN_VIDEO_SOURCE\"] = 155] = \"SET_EXTERN_VIDEO_SOURCE\";\n    API_TYPE[API_TYPE[\"PUSH_VIDEO_FRAME\"] = 156] = \"PUSH_VIDEO_FRAME\";\n    API_TYPE[API_TYPE[\"ENABLE_ENCRYPTION\"] = 157] = \"ENABLE_ENCRYPTION\";\n    API_TYPE[API_TYPE[\"SEND_CUSTOM_REPORT_MESSAGE\"] = 158] = \"SEND_CUSTOM_REPORT_MESSAGE\";\n    API_TYPE[API_TYPE[\"REGISTER_VIDEO_FRAME_OBSERVER\"] = 159] = \"REGISTER_VIDEO_FRAME_OBSERVER\";\n    API_TYPE[API_TYPE[\"ENABLE_REMOTE_SUPER_RESOLUTION\"] = 160] = \"ENABLE_REMOTE_SUPER_RESOLUTION\";\n})(API_TYPE || (API_TYPE = {}));\n/**\n * @ignore\n */\nvar API_TYPE_AUDIO_EFFECT;\n(function (API_TYPE_AUDIO_EFFECT) {\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"START_AUDIO_MIXING\"] = 45] = \"START_AUDIO_MIXING\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"STOP_AUDIO_MIXING\"] = 46] = \"STOP_AUDIO_MIXING\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"PAUSE_AUDIO_MIXING\"] = 47] = \"PAUSE_AUDIO_MIXING\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"RESUME_AUDIO_MIXING\"] = 48] = \"RESUME_AUDIO_MIXING\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_HIGH_QUALITY_AUDIO_PARAMETERS\"] = 49] = \"SET_HIGH_QUALITY_AUDIO_PARAMETERS\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"ADJUST_AUDIO_MIXING_VOLUME\"] = 50] = \"ADJUST_AUDIO_MIXING_VOLUME\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"ADJUST_AUDIO_MIXING_PLAYOUT_VOLUME\"] = 51] = \"ADJUST_AUDIO_MIXING_PLAYOUT_VOLUME\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"GET_AUDIO_MIXING_PLAYOUT_VOLUME\"] = 52] = \"GET_AUDIO_MIXING_PLAYOUT_VOLUME\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"ADJUST_AUDIO_MIXING_PUBLISH_VOLUME\"] = 53] = \"ADJUST_AUDIO_MIXING_PUBLISH_VOLUME\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"GET_AUDIO_MIXING_PUBLISH_VOLUME\"] = 54] = \"GET_AUDIO_MIXING_PUBLISH_VOLUME\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"GET_AUDIO_MIXING_DURATION\"] = 55] = \"GET_AUDIO_MIXING_DURATION\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"GET_AUDIO_MIXING_CURRENT_POSITION\"] = 56] = \"GET_AUDIO_MIXING_CURRENT_POSITION\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_AUDIO_MIXING_POSITION\"] = 57] = \"SET_AUDIO_MIXING_POSITION\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_AUDIO_MIXING_PITCH\"] = 58] = \"SET_AUDIO_MIXING_PITCH\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"GET_EFFECTS_VOLUME\"] = 59] = \"GET_EFFECTS_VOLUME\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_EFFECTS_VOLUME\"] = 60] = \"SET_EFFECTS_VOLUME\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_VOLUME_OF_EFFECT\"] = 61] = \"SET_VOLUME_OF_EFFECT\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"PLAY_EFFECT\"] = 63] = \"PLAY_EFFECT\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"STOP_EFFECT\"] = 64] = \"STOP_EFFECT\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"STOP_ALL_EFFECTS\"] = 65] = \"STOP_ALL_EFFECTS\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"PRE_LOAD_EFFECT\"] = 66] = \"PRE_LOAD_EFFECT\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"UN_LOAD_EFFECT\"] = 67] = \"UN_LOAD_EFFECT\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"PAUSE_EFFECT\"] = 68] = \"PAUSE_EFFECT\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"PAUSE_ALL_EFFECTS\"] = 69] = \"PAUSE_ALL_EFFECTS\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"RESUME_EFFECT\"] = 70] = \"RESUME_EFFECT\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"RESUME_ALL_EFFECTS\"] = 71] = \"RESUME_ALL_EFFECTS\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"ENABLE_SOUND_POSITION_INDICATION\"] = 72] = \"ENABLE_SOUND_POSITION_INDICATION\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_LOCAL_VOICE_PITCH\"] = 74] = \"SET_LOCAL_VOICE_PITCH\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_LOCAL_VOICE_EQUALIZATION\"] = 75] = \"SET_LOCAL_VOICE_EQUALIZATION\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_LOCAL_VOICE_REVERB\"] = 76] = \"SET_LOCAL_VOICE_REVERB\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_LOCAL_VOICE_CHANGER\"] = 77] = \"SET_LOCAL_VOICE_CHANGER\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_LOCAL_VOICE_REVERB_PRESET\"] = 78] = \"SET_LOCAL_VOICE_REVERB_PRESET\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_EXTERNAL_AUDIO_SOURCE\"] = 88] = \"SET_EXTERNAL_AUDIO_SOURCE\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_EXTERNAL_AUDIO_SINK\"] = 89] = \"SET_EXTERNAL_AUDIO_SINK\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_RECORDING_AUDIO_FRAME_PARAMETERS\"] = 90] = \"SET_RECORDING_AUDIO_FRAME_PARAMETERS\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_PLAYBACK_AUDIO_FRAME_PARAMETERS\"] = 91] = \"SET_PLAYBACK_AUDIO_FRAME_PARAMETERS\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_MIXED_AUDIO_FRAME_PARAMETERS\"] = 92] = \"SET_MIXED_AUDIO_FRAME_PARAMETERS\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_VOICE_BEAUTIFIER_PRESET\"] = 93] = \"SET_VOICE_BEAUTIFIER_PRESET\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_AUDIO_EFFECT_PRESET\"] = 94] = \"SET_AUDIO_EFFECT_PRESET\";\n    API_TYPE_AUDIO_EFFECT[API_TYPE_AUDIO_EFFECT[\"SET_AUDIO_EFFECT_PARAMETERS\"] = 95] = \"SET_AUDIO_EFFECT_PARAMETERS\";\n})(API_TYPE_AUDIO_EFFECT || (API_TYPE_AUDIO_EFFECT = {}));\n/**\n * @ignore\n */\nvar API_TYPE_DEVICE_MANAGER;\n(function (API_TYPE_DEVICE_MANAGER) {\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"GET_COUNT\"] = 151] = \"GET_COUNT\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"GET_DEVICE\"] = 152] = \"GET_DEVICE\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"GET_CURRENT_DEVICE\"] = 153] = \"GET_CURRENT_DEVICE\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"GET_CURRENT_DEVICE_INFO\"] = 154] = \"GET_CURRENT_DEVICE_INFO\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"SET_DEVICE\"] = 155] = \"SET_DEVICE\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"SET_DEVICE_VOLUME\"] = 156] = \"SET_DEVICE_VOLUME\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"GET_DEVICE_VOLUME\"] = 157] = \"GET_DEVICE_VOLUME\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"SET_DEVICE_MUTE\"] = 158] = \"SET_DEVICE_MUTE\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"GET_DEVICE_MUTE\"] = 159] = \"GET_DEVICE_MUTE\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"START_DEVICE_TEST\"] = 160] = \"START_DEVICE_TEST\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"STOP_DEVICE_TEST\"] = 161] = \"STOP_DEVICE_TEST\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"START_AUDIO_DEVICE_LOOP_BACK_TEST\"] = 162] = \"START_AUDIO_DEVICE_LOOP_BACK_TEST\";\n    API_TYPE_DEVICE_MANAGER[API_TYPE_DEVICE_MANAGER[\"STOP_AUDIO_DEVICE_LOOP_BACK_TEST\"] = 163] = \"STOP_AUDIO_DEVICE_LOOP_BACK_TEST\";\n})(API_TYPE_DEVICE_MANAGER || (API_TYPE_DEVICE_MANAGER = {}));\n/**\n * @ignore\n */\nfunction callNativeMethod(apiType, param, extra) {\n    if (param === void 0) { param = {}; }\n    // @ts-ignore\n    return window.agoraBridge.callNativeMethod(apiType, JSON.stringify(param), extra);\n}\n/**\n * @ignore\n */\nfunction callNativeMethodAudioEffect(apiType, param) {\n    if (param === void 0) { param = {}; }\n    // @ts-ignore\n    return window.agoraBridge.callNativeMethodAudioEffect(apiType, JSON.stringify(param));\n}\n/**\n * @ignore\n */\nfunction callNativeMethodPlayback(apiType, param) {\n    if (param === void 0) { param = {}; }\n    // @ts-ignore\n    return window.agoraBridge.callNativeMethodPlayback(apiType, JSON.stringify(param));\n}\n/**\n * @ignore\n */\nfunction callNativeMethodRecording(apiType, param) {\n    if (param === void 0) { param = {}; }\n    // @ts-ignore\n    return window.agoraBridge.callNativeMethodRecording(apiType, JSON.stringify(param));\n}\n/**\n * @ignore\n */\nfunction callNativeMethodVideo(apiType, param) {\n    if (param === void 0) { param = {}; }\n    // @ts-ignore\n    return window.agoraBridge.callNativeMethodVideo(apiType, JSON.stringify(param));\n}\n/**\n * Types in AgoraBase.h\n */\nvar AgoraRtcEngine;\n(function (AgoraRtcEngine) {\n    var INTERFACE_ID_TYPE;\n    (function (INTERFACE_ID_TYPE) {\n        INTERFACE_ID_TYPE[INTERFACE_ID_TYPE[\"AGORA_IID_AUDIO_DEVICE_MANAGER\"] = 1] = \"AGORA_IID_AUDIO_DEVICE_MANAGER\";\n        INTERFACE_ID_TYPE[INTERFACE_ID_TYPE[\"AGORA_IID_VIDEO_DEVICE_MANAGER\"] = 2] = \"AGORA_IID_VIDEO_DEVICE_MANAGER\";\n        INTERFACE_ID_TYPE[INTERFACE_ID_TYPE[\"AGORA_IID_RTC_ENGINE_PARAMETER\"] = 3] = \"AGORA_IID_RTC_ENGINE_PARAMETER\";\n        INTERFACE_ID_TYPE[INTERFACE_ID_TYPE[\"AGORA_IID_MEDIA_ENGINE\"] = 4] = \"AGORA_IID_MEDIA_ENGINE\";\n        INTERFACE_ID_TYPE[INTERFACE_ID_TYPE[\"AGORA_IID_SIGNALING_ENGINE\"] = 8] = \"AGORA_IID_SIGNALING_ENGINE\";\n    })(INTERFACE_ID_TYPE = AgoraRtcEngine.INTERFACE_ID_TYPE || (AgoraRtcEngine.INTERFACE_ID_TYPE = {}));\n    /**\n     * Warning code.\n     */\n    var WARN_CODE_TYPE;\n    (function (WARN_CODE_TYPE) {\n        /**\n         * 8: The specified view is invalid. Specify a view when using the video call function.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_INVALID_VIEW\"] = 8] = \"WARN_INVALID_VIEW\";\n        /**\n         * 16: Failed to initialize the video function, possibly caused by a lack of resources. The users cannot see the video\n         * while the voice communication is not affected.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_INIT_VIDEO\"] = 16] = \"WARN_INIT_VIDEO\";\n        /**\n         * 20: The request is pending, usually due to some module not being ready, and the SDK postponed processing the request.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_PENDING\"] = 20] = \"WARN_PENDING\";\n        /**\n         * 103: No channel resources are available. Maybe because the server cannot allocate any channel resource.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_NO_AVAILABLE_CHANNEL\"] = 103] = \"WARN_NO_AVAILABLE_CHANNEL\";\n        /**\n         * 104: A timeout occurs when looking up the channel. When joining a channel, the SDK looks up the specified channel. This\n         * warning usually occurs when the network condition is too poor for the SDK to connect to the server.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_LOOKUP_CHANNEL_TIMEOUT\"] = 104] = \"WARN_LOOKUP_CHANNEL_TIMEOUT\";\n        /**\n         * @deprecated 105: The server rejects the request to look up the channel. The server cannot process this request or the\n         * request is illegal.\n         *\n         * Use CONNECTION_CHANGED_REJECTED_BY_SERVER(10) in the [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged}\n         * callback instead.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_LOOKUP_CHANNEL_REJECTED\"] = 105] = \"WARN_LOOKUP_CHANNEL_REJECTED\";\n        /**\n         * 106: A timeout occurs when opening the channel. Once the specific channel is found, the SDK opens the channel.\n         * This warning usually occurs when the network condition is too poor for the SDK to connect to the server.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_OPEN_CHANNEL_TIMEOUT\"] = 106] = \"WARN_OPEN_CHANNEL_TIMEOUT\";\n        /**\n         * 107: The server rejects the request to open the channel. The server cannot process this request or the request is illegal.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_OPEN_CHANNEL_REJECTED\"] = 107] = \"WARN_OPEN_CHANNEL_REJECTED\";\n        // sdk: 100~1000\n        /**\n         * 111: A timeout occurs when switching to the live video.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_SWITCH_LIVE_VIDEO_TIMEOUT\"] = 111] = \"WARN_SWITCH_LIVE_VIDEO_TIMEOUT\";\n        /**\n         * 118: A timeout occurs when setting the client role in the live interactive streaming profile.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_SET_CLIENT_ROLE_TIMEOUT\"] = 118] = \"WARN_SET_CLIENT_ROLE_TIMEOUT\";\n        /**\n         * 121: The ticket to open the channel is invalid.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_OPEN_CHANNEL_INVALID_TICKET\"] = 121] = \"WARN_OPEN_CHANNEL_INVALID_TICKET\";\n        /**\n         * 122: Try connecting to another server.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_OPEN_CHANNEL_TRY_NEXT_VOS\"] = 122] = \"WARN_OPEN_CHANNEL_TRY_NEXT_VOS\";\n        /**\n         * 131: The channel connection cannot be recovered.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_CHANNEL_CONNECTION_UNRECOVERABLE\"] = 131] = \"WARN_CHANNEL_CONNECTION_UNRECOVERABLE\";\n        /**\n         * 132: The IP address has changed.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_CHANNEL_CONNECTION_IP_CHANGED\"] = 132] = \"WARN_CHANNEL_CONNECTION_IP_CHANGED\";\n        /**\n         * 133: The port has changed.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_CHANNEL_CONNECTION_PORT_CHANGED\"] = 133] = \"WARN_CHANNEL_CONNECTION_PORT_CHANGED\";\n        /**\n         * 701: An error occurs in opening the audio mixing file.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_AUDIO_MIXING_OPEN_ERROR\"] = 701] = \"WARN_AUDIO_MIXING_OPEN_ERROR\";\n        /**\n         * 1014: Audio Device Module: A warning occurs in the playback device.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_RUNTIME_PLAYOUT_WARNING\"] = 1014] = \"WARN_ADM_RUNTIME_PLAYOUT_WARNING\";\n        /**\n         * 1016: Audio Device Module: a warning occurs in the recording device.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_RUNTIME_RECORDING_WARNING\"] = 1016] = \"WARN_ADM_RUNTIME_RECORDING_WARNING\";\n        /**\n         * 1019: Audio Device Module: no valid audio data is recorded.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_RECORD_AUDIO_SILENCE\"] = 1019] = \"WARN_ADM_RECORD_AUDIO_SILENCE\";\n        /**\n         * 1020: Audio device module: The audio playback frequency is abnormal, which may cause audio freezes. This abnormality\n         * is caused by high CPU usage. Agora recommends stopping other apps.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_PLAYOUT_MALFUNCTION\"] = 1020] = \"WARN_ADM_PLAYOUT_MALFUNCTION\";\n        /**\n         * 1021: Audio device module: the audio recording frequency is abnormal, which may cause audio freezes. This abnormality\n         * is caused by high CPU usage. Agora recommends stopping other apps.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_RECORD_MALFUNCTION\"] = 1021] = \"WARN_ADM_RECORD_MALFUNCTION\";\n        /**\n         * 1025: The audio playback or recording is interrupted by system events (such as a phone call).\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_CALL_INTERRUPTION\"] = 1025] = \"WARN_ADM_CALL_INTERRUPTION\";\n        /**\n         * 1029: During a call, the audio session category should be set to\n         * AVAudioSessionCategoryPlayAndRecord, and agora monitors this value.\n         * If the audio session category is set to other values, this warning code\n         * is triggered and agora will forcefully set it back to\n         * AVAudioSessionCategoryPlayAndRecord.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_IOS_CATEGORY_NOT_PLAYANDRECORD\"] = 1029] = \"WARN_ADM_IOS_CATEGORY_NOT_PLAYANDRECORD\";\n        /**\n         * 1031: Audio Device Module: The recorded audio voice is too low.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_RECORD_AUDIO_LOWLEVEL\"] = 1031] = \"WARN_ADM_RECORD_AUDIO_LOWLEVEL\";\n        /**\n         * 1032: Audio Device Module: The playback audio voice is too low.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_PLAYOUT_AUDIO_LOWLEVEL\"] = 1032] = \"WARN_ADM_PLAYOUT_AUDIO_LOWLEVEL\";\n        /**\n         * 1033: Audio device module: The audio recording device is occupied.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_RECORD_AUDIO_IS_ACTIVE\"] = 1033] = \"WARN_ADM_RECORD_AUDIO_IS_ACTIVE\";\n        /**\n         * 1040: Audio device module: An exception occurs with the audio drive.\n         * Solutions:\n         * - Disable or re-enable the audio device.\n         * - Re-enable your device.\n         * - Update the sound card drive.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_WINDOWS_NO_DATA_READY_EVENT\"] = 1040] = \"WARN_ADM_WINDOWS_NO_DATA_READY_EVENT\";\n        /**\n         * 1042: Audio device module: The audio recording device is different from the audio playback device,\n         * which may cause echoes problem. Agora recommends using the same audio device to record and playback\n         * audio.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_INCONSISTENT_AUDIO_DEVICE\"] = 1042] = \"WARN_ADM_INCONSISTENT_AUDIO_DEVICE\";\n        /**\n         * 1051: (Communication profile only) Audio processing module: A howling sound is detected when recording the audio data.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_APM_HOWLING\"] = 1051] = \"WARN_APM_HOWLING\";\n        /**\n         * 1052: Audio Device Module: The device is in the glitch state.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_GLITCH_STATE\"] = 1052] = \"WARN_ADM_GLITCH_STATE\";\n        /**\n         * 1053: Audio Processing Module: A residual echo is detected, which may be caused by the belated scheduling of system threads\n         * or the signal overflow.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_APM_RESIDUAL_ECHO\"] = 1053] = \"WARN_APM_RESIDUAL_ECHO\";\n        /** @ignore */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_WIN_CORE_NO_RECORDING_DEVICE\"] = 1322] = \"WARN_ADM_WIN_CORE_NO_RECORDING_DEVICE\";\n        /**\n         * 1323: Audio device module: No available playback device.\n         * Solution: Plug in the audio device.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_WIN_CORE_NO_PLAYOUT_DEVICE\"] = 1323] = \"WARN_ADM_WIN_CORE_NO_PLAYOUT_DEVICE\";\n        /**\n         * 1324: Audio device module: The capture device is released improperly.\n         * Solutions:\n         * - Disable or re-enable the audio device.\n         * - Re-enable your device.\n         * - Update the sound card drive.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_ADM_WIN_CORE_IMPROPER_CAPTURE_RELEASE\"] = 1324] = \"WARN_ADM_WIN_CORE_IMPROPER_CAPTURE_RELEASE\";\n        /**\n         * 1610: Super-resolution warning: The original video dimensions of the remote user exceed 640 * 480.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_SUPER_RESOLUTION_STREAM_OVER_LIMITATION\"] = 1610] = \"WARN_SUPER_RESOLUTION_STREAM_OVER_LIMITATION\";\n        /**\n         * 1611: Super-resolution warning: Another user is using super resolution.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_SUPER_RESOLUTION_USER_COUNT_OVER_LIMITATION\"] = 1611] = \"WARN_SUPER_RESOLUTION_USER_COUNT_OVER_LIMITATION\";\n        /**\n         * 1612: The device is not supported.\n         */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_SUPER_RESOLUTION_DEVICE_NOT_SUPPORTED\"] = 1612] = \"WARN_SUPER_RESOLUTION_DEVICE_NOT_SUPPORTED\";\n        /** @ignore */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_RTM_LOGIN_TIMEOUT\"] = 2005] = \"WARN_RTM_LOGIN_TIMEOUT\";\n        /** @ignore */\n        WARN_CODE_TYPE[WARN_CODE_TYPE[\"WARN_RTM_KEEP_ALIVE_TIMEOUT\"] = 2009] = \"WARN_RTM_KEEP_ALIVE_TIMEOUT\";\n    })(WARN_CODE_TYPE = AgoraRtcEngine.WARN_CODE_TYPE || (AgoraRtcEngine.WARN_CODE_TYPE = {}));\n    /**\n     * Error code.\n     */\n    var ERROR_CODE_TYPE;\n    (function (ERROR_CODE_TYPE) {\n        /**\n         * 0: No error occurs.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_OK\"] = 0] = \"ERR_OK\";\n        //1~1000\n        /**\n         * 1: A general error occurs (no specified reason).\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_FAILED\"] = 1] = \"ERR_FAILED\";\n        /**\n         * 2: An invalid parameter is used. For example, the specific channel name includes illegal characters.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVALID_ARGUMENT\"] = 2] = \"ERR_INVALID_ARGUMENT\";\n        /**\n         * 3: The SDK module is not ready. Possible solutions:\n         * - Check the audio device.\n         * - Check the completeness of the application.\n         * - Re-initialize the Agora engine.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_NOT_READY\"] = 3] = \"ERR_NOT_READY\";\n        /**\n         * 4: The SDK does not support this function.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_NOT_SUPPORTED\"] = 4] = \"ERR_NOT_SUPPORTED\";\n        /**\n         * 5: The request is rejected.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_REFUSED\"] = 5] = \"ERR_REFUSED\";\n        /**\n         * 6: The buffer size is not big enough to store the returned data.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_BUFFER_TOO_SMALL\"] = 6] = \"ERR_BUFFER_TOO_SMALL\";\n        /**\n         * 7: The SDK is not initialized before calling this method.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_NOT_INITIALIZED\"] = 7] = \"ERR_NOT_INITIALIZED\";\n        /**\n         * 9: No permission exists. Check if the user has granted access to the audio or video device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_NO_PERMISSION\"] = 9] = \"ERR_NO_PERMISSION\";\n        /**\n         * 10: An API method timeout occurs. Some API methods require the SDK to return the execution result, and this error occurs if\n         * the request takes too long (more than 10 seconds) for the SDK to process.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_TIMEDOUT\"] = 10] = \"ERR_TIMEDOUT\";\n        /**\n         * 11: The request is canceled. This is for internal SDK use only, and it does not return to the application through any method\n         * or callback.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_CANCELED\"] = 11] = \"ERR_CANCELED\";\n        /**\n         * 12: The method is called too often. This is for internal SDK use only, and it does not return to the application through any\n         * method or callback.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_TOO_OFTEN\"] = 12] = \"ERR_TOO_OFTEN\";\n        /**\n         * 13: The SDK fails to bind to the network socket. This is for internal SDK use only, and it does not return to the application\n         * through any method or callback.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_BIND_SOCKET\"] = 13] = \"ERR_BIND_SOCKET\";\n        /**\n         * 14: The network is unavailable. This is for internal SDK use only, and it does not return to the application through any\n         * method or callback.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_NET_DOWN\"] = 14] = \"ERR_NET_DOWN\";\n        /**\n         * 15: No network buffers are available. This is for internal SDK internal use only, and it does not return to the application\n         * through any method or callback.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_NET_NOBUFS\"] = 15] = \"ERR_NET_NOBUFS\";\n        /**\n         * 17: The request to join the channel is rejected.\n         *\n         * - This error usually occurs when the user is already in the channel, and still calls the method to join the channel, for\n         * example, [joinChannel]{@link AgoraRtcEngine.joinChannel} .\n         * - This error usually occurs when the user tries to join a channel during a call test\n         * ([startEchoTest]{@link AgoraRtcEngine.startEchoTest}). Once you call [startEchoTest]{@link AgoraRtcEngine.startEchoTest} , you need to call\n         * [stopEchoTest]{@link AgoraRtcEngine.stopEchoTest} before joining a channel.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_JOIN_CHANNEL_REJECTED\"] = 17] = \"ERR_JOIN_CHANNEL_REJECTED\";\n        /**\n         * 18: The request to leave the channel is rejected.\n         *\n         * This error usually occurs:\n         * - When the user has left the channel and still calls [leaveChannel]{@link AgoraRtcEngine.leaveChannel} to leave the channel.\n         * In this case, stop calling [leaveChannel]{@link AgoraRtcEngine.leaveChannel}.\n         * - When the user has not joined the channel and still calls [leaveChannel]{@link AgoraRtcEngine.leaveChannel} to leave the channel.\n         * In this case, no extra operation is needed.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LEAVE_CHANNEL_REJECTED\"] = 18] = \"ERR_LEAVE_CHANNEL_REJECTED\";\n        /**\n         * 19: Resources are occupied and cannot be reused.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ALREADY_IN_USE\"] = 19] = \"ERR_ALREADY_IN_USE\";\n        /**\n         * 20: The SDK gives up the request due to too many requests.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ABORTED\"] = 20] = \"ERR_ABORTED\";\n        /**\n         * 21: In Windows, specific firewall settings can cause the SDK to fail to initialize and crash.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INIT_NET_ENGINE\"] = 21] = \"ERR_INIT_NET_ENGINE\";\n        /**\n         * 22: The application uses too much of the system resources and the SDK fails to allocate the resources.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_RESOURCE_LIMITED\"] = 22] = \"ERR_RESOURCE_LIMITED\";\n        /**\n         * 101: The specified App ID is invalid. Please try to rejoin the channel with a valid App ID.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVALID_APP_ID\"] = 101] = \"ERR_INVALID_APP_ID\";\n        /**\n         * 102: The specified channel name is invalid. Please try to rejoin the channel with a valid channel name.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVALID_CHANNEL_NAME\"] = 102] = \"ERR_INVALID_CHANNEL_NAME\";\n        /**\n         * 103: Fails to get server resources in the specified region. Please try to specify another region when calling\n         * [init]{@link AgoraRtcEngine.init} .\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_NO_SERVER_RESOURCES\"] = 103] = \"ERR_NO_SERVER_RESOURCES\";\n        /**\n         * @deprecated 109: Use `CONNECTION_CHANGED_TOKEN_EXPIRED(9)` in the\n         * [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged} callback instead.\n         *\n         * The token expired due to one of the following reasons:\n         * - Authorized Timestamp expired: The timestamp is represented by the number of seconds elapsed since 1/1/1970. The user can\n         * use the Token to access the Agora service within 24 hours after the Token is generated. If the user does not access the\n         * Agora service after 24 hours, this Token is no longer valid.\n         * - Call Expiration Timestamp expired: The timestamp is the exact time when a user can no longer use the Agora service\n         * (for example, when a user is forced to leave an ongoing call). When a value is set for the Call Expiration Timestamp,\n         * it does not mean that the token will expire, but that the user will be banned from the channel.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_TOKEN_EXPIRED\"] = 109] = \"ERR_TOKEN_EXPIRED\";\n        /**\n         * @deprecated 110: Use `CONNECTION_CHANGED_INVALID_TOKEN(8)` in the\n         * [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged} callback instead.\n         *\n         * The token is invalid due to one of the following reasons:\n         * - The App Certificate for the project is enabled in Console, but the user is still using the App ID. Once the App\n         * Certificate is enabled, the user must use a token.\n         * - The uid is mandatory, and users must set the same uid as the one set in the [joinChannel]{@link AgoraRtcEngine.joinChannel} method.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVALID_TOKEN\"] = 110] = \"ERR_INVALID_TOKEN\";\n        /**\n         * 111: The internet connection is interrupted. This applies to the Agora Web SDK only.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_CONNECTION_INTERRUPTED\"] = 111] = \"ERR_CONNECTION_INTERRUPTED\";\n        /**\n         * 112: The internet connection is lost. This applies to the Agora Web SDK only.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_CONNECTION_LOST\"] = 112] = \"ERR_CONNECTION_LOST\";\n        /**\n         * 113: The user is not in the channel when calling the method.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_NOT_IN_CHANNEL\"] = 113] = \"ERR_NOT_IN_CHANNEL\";\n        /**\n         * 114: The size of the sent data is over 1024 bytes when the user calls the\n         * [sendStreamMessage]{@link AgoraRtcEngine.sendStreamMessage} method.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_SIZE_TOO_LARGE\"] = 114] = \"ERR_SIZE_TOO_LARGE\";\n        /**\n         * 115: The bitrate of the sent data exceeds the limit of 6 Kbps when the user calls the\n         * [sendStreamMessage]{@link AgoraRtcEngine.sendStreamMessage} method.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_BITRATE_LIMIT\"] = 115] = \"ERR_BITRATE_LIMIT\";\n        /**\n         * 116: Too many data streams (over 5 streams) are created when the user calls the\n         * [createDataStream]{@link AgoraRtcEngine.createDataStream} method.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_TOO_MANY_DATA_STREAMS\"] = 116] = \"ERR_TOO_MANY_DATA_STREAMS\";\n        /**\n         * 117: The data stream transmission timed out.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_STREAM_MESSAGE_TIMEOUT\"] = 117] = \"ERR_STREAM_MESSAGE_TIMEOUT\";\n        /**\n         * 119: Switching roles fail. Please try to rejoin the channel.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_SET_CLIENT_ROLE_NOT_AUTHORIZED\"] = 119] = \"ERR_SET_CLIENT_ROLE_NOT_AUTHORIZED\";\n        /** 120: Decryption fails. The user may have used a different encryption password to join the channel. Check your settings\n         * or try rejoining the channel.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_DECRYPTION_FAILED\"] = 120] = \"ERR_DECRYPTION_FAILED\";\n        /**\n         * 123: The client is banned by the server.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_CLIENT_IS_BANNED_BY_SERVER\"] = 123] = \"ERR_CLIENT_IS_BANNED_BY_SERVER\";\n        /**\n         * 124: Incorrect watermark file parameter.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_WATERMARK_PARAM\"] = 124] = \"ERR_WATERMARK_PARAM\";\n        /**\n         * 125: Incorrect watermark file path.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_WATERMARK_PATH\"] = 125] = \"ERR_WATERMARK_PATH\";\n        /**\n         * 126: Incorrect watermark file format.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_WATERMARK_PNG\"] = 126] = \"ERR_WATERMARK_PNG\";\n        /**\n         * 127: Incorrect watermark file information.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_WATERMARKR_INFO\"] = 127] = \"ERR_WATERMARKR_INFO\";\n        /**\n         * 128: Incorrect watermark file data format.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_WATERMARK_ARGB\"] = 128] = \"ERR_WATERMARK_ARGB\";\n        /**\n         * 129: An error occurs in reading the watermark file.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_WATERMARK_READ\"] = 129] = \"ERR_WATERMARK_READ\";\n        /**\n         * 130: Encryption is enabled when the user calls the [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl} method\n         * (CDN live streaming does not support encrypted streams).\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ENCRYPTED_STREAM_NOT_ALLOWED_PUBLISH\"] = 130] = \"ERR_ENCRYPTED_STREAM_NOT_ALLOWED_PUBLISH\";\n        /**\n         * 134: The user account is invalid.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVALID_USER_ACCOUNT\"] = 134] = \"ERR_INVALID_USER_ACCOUNT\";\n        /**\n         * 151: CDN related errors. Remove the original URL address and add a new one by calling the\n         * [removePublishStreamUrl]{@link AgoraRtcEngine.removePublishStreamUrl} and [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl} methods.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_PUBLISH_STREAM_CDN_ERROR\"] = 151] = \"ERR_PUBLISH_STREAM_CDN_ERROR\";\n        /**\n         * 152: The host publishes more than 10 URLs. Delete the unnecessary URLs before adding new ones.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_PUBLISH_STREAM_NUM_REACH_LIMIT\"] = 152] = \"ERR_PUBLISH_STREAM_NUM_REACH_LIMIT\";\n        /**\n         * 153: The host manipulates other hosts' URLs. Check your app logic.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_PUBLISH_STREAM_NOT_AUTHORIZED\"] = 153] = \"ERR_PUBLISH_STREAM_NOT_AUTHORIZED\";\n        /**\n         * 154: An error occurs in Agora's streaming server. Call the addPublishStreamUrl method to publish the streaming again.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_PUBLISH_STREAM_INTERNAL_SERVER_ERROR\"] = 154] = \"ERR_PUBLISH_STREAM_INTERNAL_SERVER_ERROR\";\n        /**\n         * 155: The server fails to find the stream.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_PUBLISH_STREAM_NOT_FOUND\"] = 155] = \"ERR_PUBLISH_STREAM_NOT_FOUND\";\n        /**\n         * 156: The format of the RTMP stream URL is not supported. Check whether the URL format is correct.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_PUBLISH_STREAM_FORMAT_NOT_SUPPORTED\"] = 156] = \"ERR_PUBLISH_STREAM_FORMAT_NOT_SUPPORTED\";\n        //signaling: 400~600\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_OTHER\"] = 400] = \"ERR_LOGOUT_OTHER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_USER\"] = 401] = \"ERR_LOGOUT_USER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_NET\"] = 402] = \"ERR_LOGOUT_NET\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_KICKED\"] = 403] = \"ERR_LOGOUT_KICKED\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_PACKET\"] = 404] = \"ERR_LOGOUT_PACKET\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_TOKEN_EXPIRED\"] = 405] = \"ERR_LOGOUT_TOKEN_EXPIRED\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_OLDVERSION\"] = 406] = \"ERR_LOGOUT_OLDVERSION\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_TOKEN_WRONG\"] = 407] = \"ERR_LOGOUT_TOKEN_WRONG\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGOUT_ALREADY_LOGOUT\"] = 408] = \"ERR_LOGOUT_ALREADY_LOGOUT\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_OTHER\"] = 420] = \"ERR_LOGIN_OTHER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_NET\"] = 421] = \"ERR_LOGIN_NET\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_FAILED\"] = 422] = \"ERR_LOGIN_FAILED\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_CANCELED\"] = 423] = \"ERR_LOGIN_CANCELED\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_TOKEN_EXPIRED\"] = 424] = \"ERR_LOGIN_TOKEN_EXPIRED\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_OLD_VERSION\"] = 425] = \"ERR_LOGIN_OLD_VERSION\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_TOKEN_WRONG\"] = 426] = \"ERR_LOGIN_TOKEN_WRONG\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_TOKEN_KICKED\"] = 427] = \"ERR_LOGIN_TOKEN_KICKED\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOGIN_ALREADY_LOGIN\"] = 428] = \"ERR_LOGIN_ALREADY_LOGIN\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_JOIN_CHANNEL_OTHER\"] = 440] = \"ERR_JOIN_CHANNEL_OTHER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_SEND_MESSAGE_OTHER\"] = 440] = \"ERR_SEND_MESSAGE_OTHER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_SEND_MESSAGE_TIMEOUT\"] = 441] = \"ERR_SEND_MESSAGE_TIMEOUT\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_QUERY_USERNUM_OTHER\"] = 450] = \"ERR_QUERY_USERNUM_OTHER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_QUERY_USERNUM_TIMEOUT\"] = 451] = \"ERR_QUERY_USERNUM_TIMEOUT\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_QUERY_USERNUM_BYUSER\"] = 452] = \"ERR_QUERY_USERNUM_BYUSER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LEAVE_CHANNEL_OTHER\"] = 460] = \"ERR_LEAVE_CHANNEL_OTHER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LEAVE_CHANNEL_KICKED\"] = 461] = \"ERR_LEAVE_CHANNEL_KICKED\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LEAVE_CHANNEL_BYUSER\"] = 462] = \"ERR_LEAVE_CHANNEL_BYUSER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LEAVE_CHANNEL_LOGOUT\"] = 463] = \"ERR_LEAVE_CHANNEL_LOGOUT\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LEAVE_CHANNEL_DISCONNECTED\"] = 464] = \"ERR_LEAVE_CHANNEL_DISCONNECTED\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVITE_OTHER\"] = 470] = \"ERR_INVITE_OTHER\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVITE_REINVITE\"] = 471] = \"ERR_INVITE_REINVITE\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVITE_NET\"] = 472] = \"ERR_INVITE_NET\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVITE_PEER_OFFLINE\"] = 473] = \"ERR_INVITE_PEER_OFFLINE\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVITE_TIMEOUT\"] = 474] = \"ERR_INVITE_TIMEOUT\";\n        /**\n         * @ignore\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_INVITE_CANT_RECV\"] = 475] = \"ERR_INVITE_CANT_RECV\";\n        //1001~2000\n        /**\n         * 1001: Fails to load the media engine.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_LOAD_MEDIA_ENGINE\"] = 1001] = \"ERR_LOAD_MEDIA_ENGINE\";\n        /**\n         * 1002: Fails to start the call after enabling the media engine.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_START_CALL\"] = 1002] = \"ERR_START_CALL\";\n        /**\n         * @deprecated 1003: Fails to start the camera.\n         * Use `LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE(4)` in the\n         * [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged} callback instead.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_START_CAMERA\"] = 1003] = \"ERR_START_CAMERA\";\n        /**\n         * 1004: Fails to start the video rendering module.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_START_VIDEO_RENDER\"] = 1004] = \"ERR_START_VIDEO_RENDER\";\n        /**\n         * 1005: A general error occurs in the Audio Device Module (no specified reason). Check if the audio device is used by\n         * another application, or try rejoining the channel.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_GENERAL_ERROR\"] = 1005] = \"ERR_ADM_GENERAL_ERROR\";\n        /**\n         * 1006: Audio Device Module: An error occurs in using the Java resources.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_JAVA_RESOURCE\"] = 1006] = \"ERR_ADM_JAVA_RESOURCE\";\n        /**\n         * 1007: Audio Device Module: An error occurs in setting the sampling frequency.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_SAMPLE_RATE\"] = 1007] = \"ERR_ADM_SAMPLE_RATE\";\n        /**\n         * 1008: Audio Device Module: An error occurs in initializing the playback device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_INIT_PLAYOUT\"] = 1008] = \"ERR_ADM_INIT_PLAYOUT\";\n        /**\n         * 1009: Audio Device Module: An error occurs in starting the playback device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_START_PLAYOUT\"] = 1009] = \"ERR_ADM_START_PLAYOUT\";\n        /**\n         * 1010: Audio Device Module: An error occurs in stopping the playback device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_STOP_PLAYOUT\"] = 1010] = \"ERR_ADM_STOP_PLAYOUT\";\n        /**\n         * 1011: Audio Device Module: An error occurs in initializing the recording device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_INIT_RECORDING\"] = 1011] = \"ERR_ADM_INIT_RECORDING\";\n        /**\n         * 1012: Audio Device Module: An error occurs in starting the recording device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_START_RECORDING\"] = 1012] = \"ERR_ADM_START_RECORDING\";\n        /**\n         * 1013: Audio Device Module: An error occurs in stopping the recording device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_STOP_RECORDING\"] = 1013] = \"ERR_ADM_STOP_RECORDING\";\n        /**\n         * 1015: Audio Device Module: A playback error occurs. Check your playback device and try rejoining the channel.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_RUNTIME_PLAYOUT_ERROR\"] = 1015] = \"ERR_ADM_RUNTIME_PLAYOUT_ERROR\";\n        /**\n         * 1017: Audio Device Module: A recording error occurs.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_RUNTIME_RECORDING_ERROR\"] = 1017] = \"ERR_ADM_RUNTIME_RECORDING_ERROR\";\n        /**\n         * 1018: Audio Device Module: Fails to record.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_RECORD_AUDIO_FAILED\"] = 1018] = \"ERR_ADM_RECORD_AUDIO_FAILED\";\n        /**\n         * 1022: Audio Device Module: An error occurs in initializing the\n         * loopback device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_INIT_LOOPBACK\"] = 1022] = \"ERR_ADM_INIT_LOOPBACK\";\n        /**\n         * 1023: Audio Device Module: An error occurs in starting the loopback\n         * device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_START_LOOPBACK\"] = 1023] = \"ERR_ADM_START_LOOPBACK\";\n        /**\n         * 1027: Audio Device Module: No recording permission exists. Check if the\n         *  recording permission is granted.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_NO_PERMISSION\"] = 1027] = \"ERR_ADM_NO_PERMISSION\";\n        /**\n         * 1033: Audio device module: The device is occupied.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_RECORD_AUDIO_IS_ACTIVE\"] = 1033] = \"ERR_ADM_RECORD_AUDIO_IS_ACTIVE\";\n        /**\n         * 1101: Audio device module: A fatal exception occurs.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_JNI_JAVA_RESOURCE\"] = 1101] = \"ERR_ADM_ANDROID_JNI_JAVA_RESOURCE\";\n        /**\n         * 1108: Audio device module: The recording frequency is lower than 50.\n         * 0 indicates that the recording is not yet started. We recommend\n         * checking your recording permission.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_JNI_NO_RECORD_FREQUENCY\"] = 1108] = \"ERR_ADM_ANDROID_JNI_NO_RECORD_FREQUENCY\";\n        /**\n         * 1109: The playback frequency is lower than 50. 0 indicates that the\n         * playback is not yet started. We recommend checking if you have created\n         * too many AudioTrack instances.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_JNI_NO_PLAYBACK_FREQUENCY\"] = 1109] = \"ERR_ADM_ANDROID_JNI_NO_PLAYBACK_FREQUENCY\";\n        /**\n         * 1111: Audio device module: AudioRecord fails to start up. A ROM system\n         * error occurs. We recommend the following options to debug:\n         * - Restart your App.\n         * - Restart your cellphone.\n         * - Check your recording permission.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_JNI_JAVA_START_RECORD\"] = 1111] = \"ERR_ADM_ANDROID_JNI_JAVA_START_RECORD\";\n        /**\n         * 1112: Audio device module: AudioTrack fails to start up. A ROM system\n         * error occurs. We recommend the following options to debug:\n         * - Restart your App.\n         * - Restart your cellphone.\n         * - Check your playback permission.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_JNI_JAVA_START_PLAYBACK\"] = 1112] = \"ERR_ADM_ANDROID_JNI_JAVA_START_PLAYBACK\";\n        /**\n         * 1115: Audio device module: AudioRecord returns error. The SDK will\n         * automatically restart AudioRecord.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_JNI_JAVA_RECORD_ERROR\"] = 1115] = \"ERR_ADM_ANDROID_JNI_JAVA_RECORD_ERROR\";\n        /** @deprecated */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_OPENSL_CREATE_ENGINE\"] = 1151] = \"ERR_ADM_ANDROID_OPENSL_CREATE_ENGINE\";\n        /** @deprecated */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_OPENSL_CREATE_AUDIO_RECORDER\"] = 1153] = \"ERR_ADM_ANDROID_OPENSL_CREATE_AUDIO_RECORDER\";\n        /** @deprecated */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_OPENSL_START_RECORDER_THREAD\"] = 1156] = \"ERR_ADM_ANDROID_OPENSL_START_RECORDER_THREAD\";\n        /** @deprecated */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_OPENSL_CREATE_AUDIO_PLAYER\"] = 1157] = \"ERR_ADM_ANDROID_OPENSL_CREATE_AUDIO_PLAYER\";\n        /** @deprecated */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_ANDROID_OPENSL_START_PLAYER_THREAD\"] = 1160] = \"ERR_ADM_ANDROID_OPENSL_START_PLAYER_THREAD\";\n        /**\n         * 1201: Audio device module: The current device does not support audio\n         * input, possibly because you have mistakenly configured the audio session\n         *  category, or because some other app is occupying the input device. We\n         * recommend terminating all background apps and re-joining the channel.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_IOS_INPUT_NOT_AVAILABLE\"] = 1201] = \"ERR_ADM_IOS_INPUT_NOT_AVAILABLE\";\n        /**\n         * 1206: Audio device module: Cannot activate the Audio Session.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_IOS_ACTIVATE_SESSION_FAIL\"] = 1206] = \"ERR_ADM_IOS_ACTIVATE_SESSION_FAIL\";\n        /**\n         * 1210: Audio device module: Fails to initialize the audio device,\n         * normally because the audio device parameters are wrongly set.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_IOS_VPIO_INIT_FAIL\"] = 1210] = \"ERR_ADM_IOS_VPIO_INIT_FAIL\";\n        /**\n         * 1213: Audio device module: Fails to re-initialize the audio device,\n         * normally because the audio device parameters are wrongly set.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_IOS_VPIO_REINIT_FAIL\"] = 1213] = \"ERR_ADM_IOS_VPIO_REINIT_FAIL\";\n        /**\n         * 1214: Fails to re-start up the Audio Unit, possibly because the audio session category is not compatible\n         * with the settings of the Audio Unit.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_IOS_VPIO_RESTART_FAIL\"] = 1214] = \"ERR_ADM_IOS_VPIO_RESTART_FAIL\";\n        /** @ignore */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_IOS_SET_RENDER_CALLBACK_FAIL\"] = 1219] = \"ERR_ADM_IOS_SET_RENDER_CALLBACK_FAIL\";\n        /** @deprecated */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_IOS_SESSION_SAMPLERATR_ZERO\"] = 1221] = \"ERR_ADM_IOS_SESSION_SAMPLERATR_ZERO\";\n        /**\n         * 1301: Audio device module: An audio driver abnomality or a\n         * compatibility issue occurs. Solutions: Disable and restart the audio\n         * device, or reboot the system\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_INIT\"] = 1301] = \"ERR_ADM_WIN_CORE_INIT\";\n        /**\n         * 1303: Audio device module: A recording driver abnomality or a\n         * compatibility issue occurs. Solutions: Disable and restart the audio\n         * device, or reboot the system.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_INIT_RECORDING\"] = 1303] = \"ERR_ADM_WIN_CORE_INIT_RECORDING\";\n        /**\n         * 1306: Audio device module: A playout driver abnomality or a\n         * compatibility issue occurs. Solutions: Disable and restart the audio\n         * device, or reboot the system.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_INIT_PLAYOUT\"] = 1306] = \"ERR_ADM_WIN_CORE_INIT_PLAYOUT\";\n        /**\n         * 1307: Audio device module: No audio device is available. Solutions:\n         * Plug in a proper audio device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_INIT_PLAYOUT_NULL\"] = 1307] = \"ERR_ADM_WIN_CORE_INIT_PLAYOUT_NULL\";\n        /**\n         * 1309: Audio device module: An audio driver abnomality or a\n         * compatibility issue occurs. Solutions: Disable and restart the audio\n         * device, or reboot the system.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_START_RECORDING\"] = 1309] = \"ERR_ADM_WIN_CORE_START_RECORDING\";\n        /**\n         * 1311: Audio device module: Insufficient system memory or poor device\n         * performance. Solutions: Reboot the system or replace the device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_CREATE_REC_THREAD\"] = 1311] = \"ERR_ADM_WIN_CORE_CREATE_REC_THREAD\";\n        /**\n         * 1314: Audio device module: An audio driver abnormality occurs.\n         * Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Upgrade your audio card driver.*/\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_CAPTURE_NOT_STARTUP\"] = 1314] = \"ERR_ADM_WIN_CORE_CAPTURE_NOT_STARTUP\";\n        /**\n         * 1319: Audio device module: Insufficient system memory or poor device\n         * performance. Solutions: Reboot the system or replace the device. */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_CREATE_RENDER_THREAD\"] = 1319] = \"ERR_ADM_WIN_CORE_CREATE_RENDER_THREAD\";\n        /**\n         * 1320: Audio device module: An audio driver abnormality occurs.\n         * Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Replace the device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_RENDER_NOT_STARTUP\"] = 1320] = \"ERR_ADM_WIN_CORE_RENDER_NOT_STARTUP\";\n        /**\n         * 1322: Audio device module: No audio sampling device is available.\n         * Solutions: Plug in a proper recording device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_NO_RECORDING_DEVICE\"] = 1322] = \"ERR_ADM_WIN_CORE_NO_RECORDING_DEVICE\";\n        /**\n         * 1323: Audio device module: No audio playout device is available.\n         * Solutions: Plug in a proper playback device.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_CORE_NO_PLAYOUT_DEVICE\"] = 1323] = \"ERR_ADM_WIN_CORE_NO_PLAYOUT_DEVICE\";\n        /**\n         * 1351: Audio device module: An audio driver abnormality or a\n         * compatibility issue occurs. Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Upgrade your audio card driver.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_WAVE_INIT\"] = 1351] = \"ERR_ADM_WIN_WAVE_INIT\";\n        /**\n         * 1353: Audio device module: An audio driver abnormality occurs.\n         * Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Upgrade your audio card driver.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_WAVE_INIT_RECORDING\"] = 1353] = \"ERR_ADM_WIN_WAVE_INIT_RECORDING\";\n        /**\n         * 1354: Audio device module: An audio driver abnormality occurs.\n         * Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Upgrade your audio card driver.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_WAVE_INIT_MICROPHONE\"] = 1354] = \"ERR_ADM_WIN_WAVE_INIT_MICROPHONE\";\n        /**\n         * 1355: Audio device module: An audio driver abnormality occurs.\n         * Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Upgrade your audio card driver. */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_WAVE_INIT_PLAYOUT\"] = 1355] = \"ERR_ADM_WIN_WAVE_INIT_PLAYOUT\";\n        /**\n         * 1356: Audio device module: An audio driver abnormality occurs.\n         * Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Upgrade your audio card driver.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_WAVE_INIT_SPEAKER\"] = 1356] = \"ERR_ADM_WIN_WAVE_INIT_SPEAKER\";\n        /**\n         * 1357: Audio device module: An audio driver abnormality occurs.\n         * Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Upgrade your audio card driver. */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_WAVE_START_RECORDING\"] = 1357] = \"ERR_ADM_WIN_WAVE_START_RECORDING\";\n        /**\n         * 1358: Audio device module: An audio driver abnormality occurs.\n         * Solutions:\n         * - Disable and then re-enable the audio device.\n         * - Reboot the system.\n         * - Upgrade your audio card driver.*/\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_WIN_WAVE_START_PLAYOUT\"] = 1358] = \"ERR_ADM_WIN_WAVE_START_PLAYOUT\";\n        /**\n         * 1359: Audio Device Module: No recording device exists.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_NO_RECORDING_DEVICE\"] = 1359] = \"ERR_ADM_NO_RECORDING_DEVICE\";\n        /**\n         * 1360: Audio Device Module: No playback device exists.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_ADM_NO_PLAYOUT_DEVICE\"] = 1360] = \"ERR_ADM_NO_PLAYOUT_DEVICE\";\n        // VDM error code starts from 1500\n        /**\n         * 1501: Video Device Module: The camera is unauthorized.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_VDM_CAMERA_NOT_AUTHORIZED\"] = 1501] = \"ERR_VDM_CAMERA_NOT_AUTHORIZED\";\n        // VDM error code starts from 1500\n        /**\n         * @deprecated 1502: Video Device Module: The camera in use.\n         *\n         * Use `LOCAL_VIDEO_STREAM_ERROR_DEVICE_BUSY(3)` in the\n         * [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged} callback instead.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_VDM_WIN_DEVICE_IN_USE\"] = 1502] = \"ERR_VDM_WIN_DEVICE_IN_USE\";\n        // VCM error code starts from 1600\n        /**\n         * 1600: Video Device Module: An unknown error occurs.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_VCM_UNKNOWN_ERROR\"] = 1600] = \"ERR_VCM_UNKNOWN_ERROR\";\n        /**\n         * 1601: Video Device Module: An error occurs in initializing the video encoder.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_VCM_ENCODER_INIT_ERROR\"] = 1601] = \"ERR_VCM_ENCODER_INIT_ERROR\";\n        /**\n         * 1602: Video Device Module: An error occurs in encoding.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_VCM_ENCODER_ENCODE_ERROR\"] = 1602] = \"ERR_VCM_ENCODER_ENCODE_ERROR\";\n        /**\n         * 1603: Video Device Module: An error occurs in setting the video encoder.\n         */\n        ERROR_CODE_TYPE[ERROR_CODE_TYPE[\"ERR_VCM_ENCODER_SET_ERROR\"] = 1603] = \"ERR_VCM_ENCODER_SET_ERROR\";\n    })(ERROR_CODE_TYPE = AgoraRtcEngine.ERROR_CODE_TYPE || (AgoraRtcEngine.ERROR_CODE_TYPE = {}));\n    /**\n     * Output log filter level.\n     */\n    var LOG_FILTER_TYPE;\n    (function (LOG_FILTER_TYPE) {\n        /**\n         * 0: Do not output any log information.\n         */\n        LOG_FILTER_TYPE[LOG_FILTER_TYPE[\"LOG_FILTER_OFF\"] = 0] = \"LOG_FILTER_OFF\";\n        /**\n         * 0x080f: Output all log information.\n         * Set your log filter as debug if you want to get the most complete log file.\n         */\n        LOG_FILTER_TYPE[LOG_FILTER_TYPE[\"LOG_FILTER_DEBUG\"] = 2063] = \"LOG_FILTER_DEBUG\";\n        /**\n         * 0x000f: Output CRITICAL, ERROR, WARNING, and INFO level log information.\n         * We recommend setting your log filter as this level.\n         */\n        LOG_FILTER_TYPE[LOG_FILTER_TYPE[\"LOG_FILTER_INFO\"] = 15] = \"LOG_FILTER_INFO\";\n        /**\n         * 0x000e: Outputs CRITICAL, ERROR, and WARNING level log information.\n         */\n        LOG_FILTER_TYPE[LOG_FILTER_TYPE[\"LOG_FILTER_WARN\"] = 14] = \"LOG_FILTER_WARN\";\n        /**\n         * 0x000c: Outputs CRITICAL and ERROR level log information.\n         */\n        LOG_FILTER_TYPE[LOG_FILTER_TYPE[\"LOG_FILTER_ERROR\"] = 12] = \"LOG_FILTER_ERROR\";\n        /**\n         * 0x0008: Outputs CRITICAL level log information.\n         */\n        LOG_FILTER_TYPE[LOG_FILTER_TYPE[\"LOG_FILTER_CRITICAL\"] = 8] = \"LOG_FILTER_CRITICAL\";\n        /** @ignore */\n        LOG_FILTER_TYPE[LOG_FILTER_TYPE[\"LOG_FILTER_MASK\"] = 2063] = \"LOG_FILTER_MASK\";\n    })(LOG_FILTER_TYPE = AgoraRtcEngine.LOG_FILTER_TYPE || (AgoraRtcEngine.LOG_FILTER_TYPE = {}));\n})(AgoraRtcEngine || (AgoraRtcEngine = {}));\n/**\n * Types in IAgoraMediaEngine.h\n */\n(function (AgoraRtcEngine) {\n    /**\n     * @deprecated Type of audio device.\n     */\n    var MEDIA_SOURCE_TYPE;\n    (function (MEDIA_SOURCE_TYPE) {\n        /**\n         * Audio playback device.\n         */\n        MEDIA_SOURCE_TYPE[MEDIA_SOURCE_TYPE[\"AUDIO_PLAYOUT_SOURCE\"] = 0] = \"AUDIO_PLAYOUT_SOURCE\";\n        /**\n         * Microphone.\n         */\n        MEDIA_SOURCE_TYPE[MEDIA_SOURCE_TYPE[\"AUDIO_RECORDING_SOURCE\"] = 1] = \"AUDIO_RECORDING_SOURCE\";\n    })(MEDIA_SOURCE_TYPE = AgoraRtcEngine.MEDIA_SOURCE_TYPE || (AgoraRtcEngine.MEDIA_SOURCE_TYPE = {}));\n    /**\n     * The frame type.\n     */\n    var AUDIO_FRAME_TYPE;\n    (function (AUDIO_FRAME_TYPE) {\n        /**\n         * 0: PCM16.\n         */\n        AUDIO_FRAME_TYPE[AUDIO_FRAME_TYPE[\"FRAME_TYPE_PCM16\"] = 0] = \"FRAME_TYPE_PCM16\";\n    })(AUDIO_FRAME_TYPE = AgoraRtcEngine.AUDIO_FRAME_TYPE || (AgoraRtcEngine.AUDIO_FRAME_TYPE = {}));\n    /**\n     * The video frame type.\n     */\n    var VIDEO_FRAME_TYPE;\n    (function (VIDEO_FRAME_TYPE) {\n        /**\n         * 0: YUV420\n         */\n        VIDEO_FRAME_TYPE[VIDEO_FRAME_TYPE[\"FRAME_TYPE_YUV420\"] = 0] = \"FRAME_TYPE_YUV420\";\n        /**\n         * 1: YUV422\n         */\n        VIDEO_FRAME_TYPE[VIDEO_FRAME_TYPE[\"FRAME_TYPE_YUV422\"] = 1] = \"FRAME_TYPE_YUV422\";\n        /**\n         * 2: RGBA\n         */\n        VIDEO_FRAME_TYPE[VIDEO_FRAME_TYPE[\"FRAME_TYPE_RGBA\"] = 2] = \"FRAME_TYPE_RGBA\";\n    })(VIDEO_FRAME_TYPE = AgoraRtcEngine.VIDEO_FRAME_TYPE || (AgoraRtcEngine.VIDEO_FRAME_TYPE = {}));\n    /**\n     * The frame position of the video observer.\n     */\n    var VIDEO_OBSERVER_POSITION;\n    (function (VIDEO_OBSERVER_POSITION) {\n        /**\n         * 1: The post-capturer position, which corresponds to the video data in the onCaptureVideoFrame callback.\n         */\n        VIDEO_OBSERVER_POSITION[VIDEO_OBSERVER_POSITION[\"POSITION_POST_CAPTURER\"] = 1] = \"POSITION_POST_CAPTURER\";\n        /**\n         * 2: The pre-renderer position, which corresponds to the video data in the onRenderVideoFrame callback.\n         */\n        VIDEO_OBSERVER_POSITION[VIDEO_OBSERVER_POSITION[\"POSITION_PRE_RENDERER\"] = 2] = \"POSITION_PRE_RENDERER\";\n        /**\n         * 4: The pre-encoder position, which corresponds to the video data in the onPreEncodeVideoFrame callback.\n         */\n        VIDEO_OBSERVER_POSITION[VIDEO_OBSERVER_POSITION[\"POSITION_PRE_ENCODER\"] = 4] = \"POSITION_PRE_ENCODER\";\n    })(VIDEO_OBSERVER_POSITION = AgoraRtcEngine.VIDEO_OBSERVER_POSITION || (AgoraRtcEngine.VIDEO_OBSERVER_POSITION = {}));\n    var PLANE_TYPE;\n    (function (PLANE_TYPE) {\n        PLANE_TYPE[PLANE_TYPE[\"Y_PLANE\"] = 0] = \"Y_PLANE\";\n        PLANE_TYPE[PLANE_TYPE[\"U_PLANE\"] = 1] = \"U_PLANE\";\n        PLANE_TYPE[PLANE_TYPE[\"V_PLANE\"] = 2] = \"V_PLANE\";\n        PLANE_TYPE[PLANE_TYPE[\"NUM_OF_PLANES\"] = 3] = \"NUM_OF_PLANES\";\n    })(PLANE_TYPE = AgoraRtcEngine.PLANE_TYPE || (AgoraRtcEngine.PLANE_TYPE = {}));\n    var VIDEO_TYPE;\n    (function (VIDEO_TYPE) {\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_UNKNOWN\"] = 0] = \"VIDEO_TYPE_UNKNOWN\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_I420\"] = 1] = \"VIDEO_TYPE_I420\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_IYUV\"] = 2] = \"VIDEO_TYPE_IYUV\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_RGB24\"] = 3] = \"VIDEO_TYPE_RGB24\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_ABGR\"] = 4] = \"VIDEO_TYPE_ABGR\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_ARGB\"] = 5] = \"VIDEO_TYPE_ARGB\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_ARGB4444\"] = 6] = \"VIDEO_TYPE_ARGB4444\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_RGB565\"] = 7] = \"VIDEO_TYPE_RGB565\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_ARGB1555\"] = 8] = \"VIDEO_TYPE_ARGB1555\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_YUY2\"] = 9] = \"VIDEO_TYPE_YUY2\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_YV12\"] = 10] = \"VIDEO_TYPE_YV12\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_UYVY\"] = 11] = \"VIDEO_TYPE_UYVY\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_MJPG\"] = 12] = \"VIDEO_TYPE_MJPG\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_NV21\"] = 13] = \"VIDEO_TYPE_NV21\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_NV12\"] = 14] = \"VIDEO_TYPE_NV12\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_BGRA\"] = 15] = \"VIDEO_TYPE_BGRA\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_RGBA\"] = 16] = \"VIDEO_TYPE_RGBA\";\n        VIDEO_TYPE[VIDEO_TYPE[\"VIDEO_TYPE_I422\"] = 17] = \"VIDEO_TYPE_I422\";\n    })(VIDEO_TYPE = AgoraRtcEngine.VIDEO_TYPE || (AgoraRtcEngine.VIDEO_TYPE = {}));\n    /**\n     * The video buffer type.\n     */\n    var VIDEO_BUFFER_TYPE;\n    (function (VIDEO_BUFFER_TYPE) {\n        /**\n         * 1: The video buffer in the format of raw data.\n         */\n        VIDEO_BUFFER_TYPE[VIDEO_BUFFER_TYPE[\"VIDEO_BUFFER_RAW_DATA\"] = 1] = \"VIDEO_BUFFER_RAW_DATA\";\n    })(VIDEO_BUFFER_TYPE = AgoraRtcEngine.VIDEO_BUFFER_TYPE || (AgoraRtcEngine.VIDEO_BUFFER_TYPE = {}));\n    /**\n     * The video pixel format.\n     *\n     * @note The SDK does not support the alpha channel, and discards any alpha value passed to the SDK.\n     */\n    var VIDEO_PIXEL_FORMAT;\n    (function (VIDEO_PIXEL_FORMAT) {\n        /**\n         * 0: The video pixel format is unknown.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_UNKNOWN\"] = 0] = \"VIDEO_PIXEL_UNKNOWN\";\n        /**\n         * 1: The video pixel format is I420.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_I420\"] = 1] = \"VIDEO_PIXEL_I420\";\n        /**\n         * 2: The video pixel format is BGRA.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_BGRA\"] = 2] = \"VIDEO_PIXEL_BGRA\";\n        /**\n         * 3: The video pixel format is NV21.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_NV21\"] = 3] = \"VIDEO_PIXEL_NV21\";\n        /**\n         * 4: The video pixel format is RGBA.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_RGBA\"] = 4] = \"VIDEO_PIXEL_RGBA\";\n        /**\n         * 5: The video pixel format is IMC2.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_IMC2\"] = 5] = \"VIDEO_PIXEL_IMC2\";\n        /**\n         * 7: The video pixel format is ARGB.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_ARGB\"] = 7] = \"VIDEO_PIXEL_ARGB\";\n        /**\n         * 8: The video pixel format is NV12.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_NV12\"] = 8] = \"VIDEO_PIXEL_NV12\";\n        /**\n         * 16: The video pixel format is I422.\n         */\n        VIDEO_PIXEL_FORMAT[VIDEO_PIXEL_FORMAT[\"VIDEO_PIXEL_I422\"] = 16] = \"VIDEO_PIXEL_I422\";\n    })(VIDEO_PIXEL_FORMAT = AgoraRtcEngine.VIDEO_PIXEL_FORMAT || (AgoraRtcEngine.VIDEO_PIXEL_FORMAT = {}));\n})(AgoraRtcEngine || (AgoraRtcEngine = {}));\n/**\n * Types in IAgoraRtcEngine.h\n */\n(function (AgoraRtcEngine) {\n    /**\n     * Maximum length of the device ID.\n     */\n    var MAX_DEVICE_ID_LENGTH_TYPE;\n    (function (MAX_DEVICE_ID_LENGTH_TYPE) {\n        /**\n         * The maximum length of the device ID is 512 bytes.\n         */\n        MAX_DEVICE_ID_LENGTH_TYPE[MAX_DEVICE_ID_LENGTH_TYPE[\"MAX_DEVICE_ID_LENGTH\"] = 512] = \"MAX_DEVICE_ID_LENGTH\";\n    })(MAX_DEVICE_ID_LENGTH_TYPE = AgoraRtcEngine.MAX_DEVICE_ID_LENGTH_TYPE || (AgoraRtcEngine.MAX_DEVICE_ID_LENGTH_TYPE = {}));\n    /**\n     * Maximum length of user account.\n     */\n    var MAX_USER_ACCOUNT_LENGTH_TYPE;\n    (function (MAX_USER_ACCOUNT_LENGTH_TYPE) {\n        /**\n         * The maximum length of user account is 255 bytes.\n         */\n        MAX_USER_ACCOUNT_LENGTH_TYPE[MAX_USER_ACCOUNT_LENGTH_TYPE[\"MAX_USER_ACCOUNT_LENGTH\"] = 256] = \"MAX_USER_ACCOUNT_LENGTH\";\n    })(MAX_USER_ACCOUNT_LENGTH_TYPE = AgoraRtcEngine.MAX_USER_ACCOUNT_LENGTH_TYPE || (AgoraRtcEngine.MAX_USER_ACCOUNT_LENGTH_TYPE = {}));\n    /**\n     * Maximum length of channel ID.\n     */\n    var MAX_CHANNEL_ID_LENGTH_TYPE;\n    (function (MAX_CHANNEL_ID_LENGTH_TYPE) {\n        /**\n         * The maximum length of channel id is 64 bytes.\n         */\n        MAX_CHANNEL_ID_LENGTH_TYPE[MAX_CHANNEL_ID_LENGTH_TYPE[\"MAX_CHANNEL_ID_LENGTH\"] = 65] = \"MAX_CHANNEL_ID_LENGTH\";\n    })(MAX_CHANNEL_ID_LENGTH_TYPE = AgoraRtcEngine.MAX_CHANNEL_ID_LENGTH_TYPE || (AgoraRtcEngine.MAX_CHANNEL_ID_LENGTH_TYPE = {}));\n    /**\n     * Formats of the quality report.\n     */\n    var QUALITY_REPORT_FORMAT_TYPE;\n    (function (QUALITY_REPORT_FORMAT_TYPE) {\n        /**\n         * 0: The quality report in JSON format,\n         */\n        QUALITY_REPORT_FORMAT_TYPE[QUALITY_REPORT_FORMAT_TYPE[\"QUALITY_REPORT_JSON\"] = 0] = \"QUALITY_REPORT_JSON\";\n        /**\n         * 1: The quality report in HTML format.\n         */\n        QUALITY_REPORT_FORMAT_TYPE[QUALITY_REPORT_FORMAT_TYPE[\"QUALITY_REPORT_HTML\"] = 1] = \"QUALITY_REPORT_HTML\";\n    })(QUALITY_REPORT_FORMAT_TYPE = AgoraRtcEngine.QUALITY_REPORT_FORMAT_TYPE || (AgoraRtcEngine.QUALITY_REPORT_FORMAT_TYPE = {}));\n    var MEDIA_ENGINE_EVENT_CODE_TYPE;\n    (function (MEDIA_ENGINE_EVENT_CODE_TYPE) {\n        /**\n         * 0: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_RECORDING_ERROR\"] = 0] = \"MEDIA_ENGINE_RECORDING_ERROR\";\n        /**\n         * 1: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_PLAYOUT_ERROR\"] = 1] = \"MEDIA_ENGINE_PLAYOUT_ERROR\";\n        /**\n         * 2: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_RECORDING_WARNING\"] = 2] = \"MEDIA_ENGINE_RECORDING_WARNING\";\n        /**\n         * 3: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_PLAYOUT_WARNING\"] = 3] = \"MEDIA_ENGINE_PLAYOUT_WARNING\";\n        /**\n         * 10: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_FILE_MIX_FINISH\"] = 10] = \"MEDIA_ENGINE_AUDIO_FILE_MIX_FINISH\";\n        /**\n         * 12: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_FAREND_MUSIC_BEGINS\"] = 12] = \"MEDIA_ENGINE_AUDIO_FAREND_MUSIC_BEGINS\";\n        /**\n         * 13: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_FAREND_MUSIC_ENDS\"] = 13] = \"MEDIA_ENGINE_AUDIO_FAREND_MUSIC_ENDS\";\n        /**\n         * 14: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_LOCAL_AUDIO_RECORD_ENABLED\"] = 14] = \"MEDIA_ENGINE_LOCAL_AUDIO_RECORD_ENABLED\";\n        /**\n         * 15: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_LOCAL_AUDIO_RECORD_DISABLED\"] = 15] = \"MEDIA_ENGINE_LOCAL_AUDIO_RECORD_DISABLED\";\n        // media engine role changed\n        /**\n         * 20: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_ROLE_BROADCASTER_SOLO\"] = 20] = \"MEDIA_ENGINE_ROLE_BROADCASTER_SOLO\";\n        /**\n         * 21: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_ROLE_BROADCASTER_INTERACTIVE\"] = 21] = \"MEDIA_ENGINE_ROLE_BROADCASTER_INTERACTIVE\";\n        /**\n         * 22: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_ROLE_AUDIENCE\"] = 22] = \"MEDIA_ENGINE_ROLE_AUDIENCE\";\n        /**\n         * 23: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_ROLE_COMM_PEER\"] = 23] = \"MEDIA_ENGINE_ROLE_COMM_PEER\";\n        /**\n         * 24: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_ROLE_GAME_PEER\"] = 24] = \"MEDIA_ENGINE_ROLE_GAME_PEER\";\n        // iOS adm sample rate changed\n        /**\n         * 110: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_ADM_REQUIRE_RESTART\"] = 110] = \"MEDIA_ENGINE_AUDIO_ADM_REQUIRE_RESTART\";\n        /**\n         * 111: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_ADM_SPECIAL_RESTART\"] = 111] = \"MEDIA_ENGINE_AUDIO_ADM_SPECIAL_RESTART\";\n        /**\n         * 112: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_ADM_USING_COMM_PARAMS\"] = 112] = \"MEDIA_ENGINE_AUDIO_ADM_USING_COMM_PARAMS\";\n        /**\n         * 113: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_ADM_USING_NORM_PARAMS\"] = 113] = \"MEDIA_ENGINE_AUDIO_ADM_USING_NORM_PARAMS\";\n        // audio mix state\n        /**\n         * 710: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_EVENT_MIXING_PLAY\"] = 710] = \"MEDIA_ENGINE_AUDIO_EVENT_MIXING_PLAY\";\n        /**\n         * 711: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_EVENT_MIXING_PAUSED\"] = 711] = \"MEDIA_ENGINE_AUDIO_EVENT_MIXING_PAUSED\";\n        /**\n         * 712: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_EVENT_MIXING_RESTART\"] = 712] = \"MEDIA_ENGINE_AUDIO_EVENT_MIXING_RESTART\";\n        /**\n         * 713: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_EVENT_MIXING_STOPPED\"] = 713] = \"MEDIA_ENGINE_AUDIO_EVENT_MIXING_STOPPED\";\n        /**\n         * 714: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_EVENT_MIXING_ERROR\"] = 714] = \"MEDIA_ENGINE_AUDIO_EVENT_MIXING_ERROR\";\n        //Mixing error codes\n        /**\n         * 701: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_ERROR_MIXING_OPEN\"] = 701] = \"MEDIA_ENGINE_AUDIO_ERROR_MIXING_OPEN\";\n        /**\n         * 702: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_ERROR_MIXING_TOO_FREQUENT\"] = 702] = \"MEDIA_ENGINE_AUDIO_ERROR_MIXING_TOO_FREQUENT\";\n        /**\n         * 703: The audio mixing file playback is interrupted. For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_ERROR_MIXING_INTERRUPTED_EOF\"] = 703] = \"MEDIA_ENGINE_AUDIO_ERROR_MIXING_INTERRUPTED_EOF\";\n        /**\n         * 0: For internal use only.\n         */\n        MEDIA_ENGINE_EVENT_CODE_TYPE[MEDIA_ENGINE_EVENT_CODE_TYPE[\"MEDIA_ENGINE_AUDIO_ERROR_MIXING_NO_ERROR\"] = 0] = \"MEDIA_ENGINE_AUDIO_ERROR_MIXING_NO_ERROR\";\n    })(MEDIA_ENGINE_EVENT_CODE_TYPE = AgoraRtcEngine.MEDIA_ENGINE_EVENT_CODE_TYPE || (AgoraRtcEngine.MEDIA_ENGINE_EVENT_CODE_TYPE = {}));\n    /**\n     * The states of the local user's audio mixing file.\n     */\n    var AUDIO_MIXING_STATE_TYPE;\n    (function (AUDIO_MIXING_STATE_TYPE) {\n        /**\n         * 710: The audio mixing file is playing after the method call of [startAudioMixing]{@link AgoraRtcEngine.startAudioMixing} or\n         * [resumeAudioMixing]{@link AgoraRtcEngine.resumeAudioMixing} succeeds.\n         */\n        AUDIO_MIXING_STATE_TYPE[AUDIO_MIXING_STATE_TYPE[\"AUDIO_MIXING_STATE_PLAYING\"] = 710] = \"AUDIO_MIXING_STATE_PLAYING\";\n        /**\n         * 711: The audio mixing file pauses playing after the method call of [pauseAudioMixing]{@link AgoraRtcEngine.pauseAudioMixing} succeeds.\n         */\n        AUDIO_MIXING_STATE_TYPE[AUDIO_MIXING_STATE_TYPE[\"AUDIO_MIXING_STATE_PAUSED\"] = 711] = \"AUDIO_MIXING_STATE_PAUSED\";\n        /**\n         * 713: The audio mixing file stops playing after the method call of [stopAudioMixing]{@link AgoraRtcEngine.stopAudioMixing} succeeds.\n         */\n        AUDIO_MIXING_STATE_TYPE[AUDIO_MIXING_STATE_TYPE[\"AUDIO_MIXING_STATE_STOPPED\"] = 713] = \"AUDIO_MIXING_STATE_STOPPED\";\n        /**\n         * 714: An exception occurs when playing the audio mixing file. See\n         * [AUDIO_MIXING_ERROR_TYPE]{@link AgoraRtcEngine.AUDIO_MIXING_ERROR_TYPE}.\n         */\n        AUDIO_MIXING_STATE_TYPE[AUDIO_MIXING_STATE_TYPE[\"AUDIO_MIXING_STATE_FAILED\"] = 714] = \"AUDIO_MIXING_STATE_FAILED\";\n    })(AUDIO_MIXING_STATE_TYPE = AgoraRtcEngine.AUDIO_MIXING_STATE_TYPE || (AgoraRtcEngine.AUDIO_MIXING_STATE_TYPE = {}));\n    /**\n     * The error codes of the local user's audio mixing file.\n     */\n    var AUDIO_MIXING_ERROR_TYPE;\n    (function (AUDIO_MIXING_ERROR_TYPE) {\n        /**\n         * 701: The SDK cannot open the audio mixing file.\n         */\n        AUDIO_MIXING_ERROR_TYPE[AUDIO_MIXING_ERROR_TYPE[\"AUDIO_MIXING_ERROR_CAN_NOT_OPEN\"] = 701] = \"AUDIO_MIXING_ERROR_CAN_NOT_OPEN\";\n        /**\n         * 702: The SDK opens the audio mixing file too frequently.\n         */\n        AUDIO_MIXING_ERROR_TYPE[AUDIO_MIXING_ERROR_TYPE[\"AUDIO_MIXING_ERROR_TOO_FREQUENT_CALL\"] = 702] = \"AUDIO_MIXING_ERROR_TOO_FREQUENT_CALL\";\n        /**\n         * 703: The audio mixing file playback is interrupted.\n         */\n        AUDIO_MIXING_ERROR_TYPE[AUDIO_MIXING_ERROR_TYPE[\"AUDIO_MIXING_ERROR_INTERRUPTED_EOF\"] = 703] = \"AUDIO_MIXING_ERROR_INTERRUPTED_EOF\";\n        /**\n         * 0: The SDK can open the audio mixing file.\n         */\n        AUDIO_MIXING_ERROR_TYPE[AUDIO_MIXING_ERROR_TYPE[\"AUDIO_MIXING_ERROR_OK\"] = 0] = \"AUDIO_MIXING_ERROR_OK\";\n    })(AUDIO_MIXING_ERROR_TYPE = AgoraRtcEngine.AUDIO_MIXING_ERROR_TYPE || (AgoraRtcEngine.AUDIO_MIXING_ERROR_TYPE = {}));\n    /**\n     * Media device states.\n     */\n    var MEDIA_DEVICE_STATE_TYPE;\n    (function (MEDIA_DEVICE_STATE_TYPE) {\n        /**\n         * 1: The device is active.\n         */\n        MEDIA_DEVICE_STATE_TYPE[MEDIA_DEVICE_STATE_TYPE[\"MEDIA_DEVICE_STATE_ACTIVE\"] = 1] = \"MEDIA_DEVICE_STATE_ACTIVE\";\n        /**\n         * 2: The device is disabled.\n         */\n        MEDIA_DEVICE_STATE_TYPE[MEDIA_DEVICE_STATE_TYPE[\"MEDIA_DEVICE_STATE_DISABLED\"] = 2] = \"MEDIA_DEVICE_STATE_DISABLED\";\n        /**\n         * 4: The device is not present.\n         */\n        MEDIA_DEVICE_STATE_TYPE[MEDIA_DEVICE_STATE_TYPE[\"MEDIA_DEVICE_STATE_NOT_PRESENT\"] = 4] = \"MEDIA_DEVICE_STATE_NOT_PRESENT\";\n        /**\n         * 8: The device is unplugged.\n         */\n        MEDIA_DEVICE_STATE_TYPE[MEDIA_DEVICE_STATE_TYPE[\"MEDIA_DEVICE_STATE_UNPLUGGED\"] = 8] = \"MEDIA_DEVICE_STATE_UNPLUGGED\";\n    })(MEDIA_DEVICE_STATE_TYPE = AgoraRtcEngine.MEDIA_DEVICE_STATE_TYPE || (AgoraRtcEngine.MEDIA_DEVICE_STATE_TYPE = {}));\n    /**\n     * Media device types.\n     */\n    var MEDIA_DEVICE_TYPE;\n    (function (MEDIA_DEVICE_TYPE) {\n        /**\n         * -1: Unknown device type.\n         */\n        MEDIA_DEVICE_TYPE[MEDIA_DEVICE_TYPE[\"UNKNOWN_AUDIO_DEVICE\"] = -1] = \"UNKNOWN_AUDIO_DEVICE\";\n        /**\n         * 0: Audio playback device.\n         */\n        MEDIA_DEVICE_TYPE[MEDIA_DEVICE_TYPE[\"AUDIO_PLAYOUT_DEVICE\"] = 0] = \"AUDIO_PLAYOUT_DEVICE\";\n        /**\n         * 1: Audio recording device.\n         */\n        MEDIA_DEVICE_TYPE[MEDIA_DEVICE_TYPE[\"AUDIO_RECORDING_DEVICE\"] = 1] = \"AUDIO_RECORDING_DEVICE\";\n        /**\n         * 2: Video renderer.\n         */\n        MEDIA_DEVICE_TYPE[MEDIA_DEVICE_TYPE[\"VIDEO_RENDER_DEVICE\"] = 2] = \"VIDEO_RENDER_DEVICE\";\n        /**\n         * 3: Video capturer.\n         */\n        MEDIA_DEVICE_TYPE[MEDIA_DEVICE_TYPE[\"VIDEO_CAPTURE_DEVICE\"] = 3] = \"VIDEO_CAPTURE_DEVICE\";\n        /**\n         * 4: Application audio playback device.\n         */\n        MEDIA_DEVICE_TYPE[MEDIA_DEVICE_TYPE[\"AUDIO_APPLICATION_PLAYOUT_DEVICE\"] = 4] = \"AUDIO_APPLICATION_PLAYOUT_DEVICE\";\n    })(MEDIA_DEVICE_TYPE = AgoraRtcEngine.MEDIA_DEVICE_TYPE || (AgoraRtcEngine.MEDIA_DEVICE_TYPE = {}));\n    /**\n     * Local video state types\n     */\n    var LOCAL_VIDEO_STREAM_STATE;\n    (function (LOCAL_VIDEO_STREAM_STATE) {\n        /**\n         * 0: Initial state\n         */\n        LOCAL_VIDEO_STREAM_STATE[LOCAL_VIDEO_STREAM_STATE[\"LOCAL_VIDEO_STREAM_STATE_STOPPED\"] = 0] = \"LOCAL_VIDEO_STREAM_STATE_STOPPED\";\n        /**\n         * 1: The local video capturing device starts successfully.\n         *\n         * The SDK also reports this state when you share a maximized window by calling\n         * [startScreenCaptureByWindowId]{@link AgoraRtcEngine.startScreenCaptureByWindowId}.\n         */\n        LOCAL_VIDEO_STREAM_STATE[LOCAL_VIDEO_STREAM_STATE[\"LOCAL_VIDEO_STREAM_STATE_CAPTURING\"] = 1] = \"LOCAL_VIDEO_STREAM_STATE_CAPTURING\";\n        /**\n         * 2: The first video frame is successfully encoded.\n         */\n        LOCAL_VIDEO_STREAM_STATE[LOCAL_VIDEO_STREAM_STATE[\"LOCAL_VIDEO_STREAM_STATE_ENCODING\"] = 2] = \"LOCAL_VIDEO_STREAM_STATE_ENCODING\";\n        /**\n         * 3: The local video fails to start.\n         */\n        LOCAL_VIDEO_STREAM_STATE[LOCAL_VIDEO_STREAM_STATE[\"LOCAL_VIDEO_STREAM_STATE_FAILED\"] = 3] = \"LOCAL_VIDEO_STREAM_STATE_FAILED\";\n    })(LOCAL_VIDEO_STREAM_STATE = AgoraRtcEngine.LOCAL_VIDEO_STREAM_STATE || (AgoraRtcEngine.LOCAL_VIDEO_STREAM_STATE = {}));\n    /**\n     * Local video state error codes\n     */\n    var LOCAL_VIDEO_STREAM_ERROR;\n    (function (LOCAL_VIDEO_STREAM_ERROR) {\n        /**\n         * 0: The local video is normal.\n         */\n        LOCAL_VIDEO_STREAM_ERROR[LOCAL_VIDEO_STREAM_ERROR[\"LOCAL_VIDEO_STREAM_ERROR_OK\"] = 0] = \"LOCAL_VIDEO_STREAM_ERROR_OK\";\n        /**\n         * 1: No specified reason for the local video failure.\n         */\n        LOCAL_VIDEO_STREAM_ERROR[LOCAL_VIDEO_STREAM_ERROR[\"LOCAL_VIDEO_STREAM_ERROR_FAILURE\"] = 1] = \"LOCAL_VIDEO_STREAM_ERROR_FAILURE\";\n        /**\n         * 2: No permission to use the local video capturing device.\n         */\n        LOCAL_VIDEO_STREAM_ERROR[LOCAL_VIDEO_STREAM_ERROR[\"LOCAL_VIDEO_STREAM_ERROR_DEVICE_NO_PERMISSION\"] = 2] = \"LOCAL_VIDEO_STREAM_ERROR_DEVICE_NO_PERMISSION\";\n        /**\n         * 3: The local video capturing device is in use.\n         */\n        LOCAL_VIDEO_STREAM_ERROR[LOCAL_VIDEO_STREAM_ERROR[\"LOCAL_VIDEO_STREAM_ERROR_DEVICE_BUSY\"] = 3] = \"LOCAL_VIDEO_STREAM_ERROR_DEVICE_BUSY\";\n        /**\n         * 4: The local video capture fails. Check whether the capturing device is working properly.\n         */\n        LOCAL_VIDEO_STREAM_ERROR[LOCAL_VIDEO_STREAM_ERROR[\"LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE\"] = 4] = \"LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE\";\n        /**\n         * 5: The local video encoding fails.\n         */\n        LOCAL_VIDEO_STREAM_ERROR[LOCAL_VIDEO_STREAM_ERROR[\"LOCAL_VIDEO_STREAM_ERROR_ENCODE_FAILURE\"] = 5] = \"LOCAL_VIDEO_STREAM_ERROR_ENCODE_FAILURE\";\n        /**\n         * 11: The shared window is minimized when you call\n         * [startScreenCaptureByWindowId]{@link AgoraRtcEngine.startScreenCaptureByWindowId} to share a window.\n         */\n        LOCAL_VIDEO_STREAM_ERROR[LOCAL_VIDEO_STREAM_ERROR[\"LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_MINIMIZED\"] = 11] = \"LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_MINIMIZED\";\n    })(LOCAL_VIDEO_STREAM_ERROR = AgoraRtcEngine.LOCAL_VIDEO_STREAM_ERROR || (AgoraRtcEngine.LOCAL_VIDEO_STREAM_ERROR = {}));\n    /**\n     * Local audio state types.\n     */\n    var LOCAL_AUDIO_STREAM_STATE;\n    (function (LOCAL_AUDIO_STREAM_STATE) {\n        /**\n         * 0: The local audio is in the initial state.\n         */\n        LOCAL_AUDIO_STREAM_STATE[LOCAL_AUDIO_STREAM_STATE[\"LOCAL_AUDIO_STREAM_STATE_STOPPED\"] = 0] = \"LOCAL_AUDIO_STREAM_STATE_STOPPED\";\n        /**\n         * 1: The recording device starts successfully.\n         */\n        LOCAL_AUDIO_STREAM_STATE[LOCAL_AUDIO_STREAM_STATE[\"LOCAL_AUDIO_STREAM_STATE_RECORDING\"] = 1] = \"LOCAL_AUDIO_STREAM_STATE_RECORDING\";\n        /**\n         * 2: The first audio frame encodes successfully.\n         */\n        LOCAL_AUDIO_STREAM_STATE[LOCAL_AUDIO_STREAM_STATE[\"LOCAL_AUDIO_STREAM_STATE_ENCODING\"] = 2] = \"LOCAL_AUDIO_STREAM_STATE_ENCODING\";\n        /**\n         * 3: The local audio fails to start.\n         */\n        LOCAL_AUDIO_STREAM_STATE[LOCAL_AUDIO_STREAM_STATE[\"LOCAL_AUDIO_STREAM_STATE_FAILED\"] = 3] = \"LOCAL_AUDIO_STREAM_STATE_FAILED\";\n    })(LOCAL_AUDIO_STREAM_STATE = AgoraRtcEngine.LOCAL_AUDIO_STREAM_STATE || (AgoraRtcEngine.LOCAL_AUDIO_STREAM_STATE = {}));\n    /**\n     * Local audio state error codes.\n     */\n    var LOCAL_AUDIO_STREAM_ERROR;\n    (function (LOCAL_AUDIO_STREAM_ERROR) {\n        /**\n         * 0: The local audio is normal.\n         */\n        LOCAL_AUDIO_STREAM_ERROR[LOCAL_AUDIO_STREAM_ERROR[\"LOCAL_AUDIO_STREAM_ERROR_OK\"] = 0] = \"LOCAL_AUDIO_STREAM_ERROR_OK\";\n        /**\n         * 1: No specified reason for the local audio failure.\n         */\n        LOCAL_AUDIO_STREAM_ERROR[LOCAL_AUDIO_STREAM_ERROR[\"LOCAL_AUDIO_STREAM_ERROR_FAILURE\"] = 1] = \"LOCAL_AUDIO_STREAM_ERROR_FAILURE\";\n        /**\n         * 2: No permission to use the local audio device.\n         */\n        LOCAL_AUDIO_STREAM_ERROR[LOCAL_AUDIO_STREAM_ERROR[\"LOCAL_AUDIO_STREAM_ERROR_DEVICE_NO_PERMISSION\"] = 2] = \"LOCAL_AUDIO_STREAM_ERROR_DEVICE_NO_PERMISSION\";\n        /**\n         * 3: The microphone is in use.\n         */\n        LOCAL_AUDIO_STREAM_ERROR[LOCAL_AUDIO_STREAM_ERROR[\"LOCAL_AUDIO_STREAM_ERROR_DEVICE_BUSY\"] = 3] = \"LOCAL_AUDIO_STREAM_ERROR_DEVICE_BUSY\";\n        /**\n         * 4: The local audio recording fails. Check whether the recording device\n         * is working properly.\n         */\n        LOCAL_AUDIO_STREAM_ERROR[LOCAL_AUDIO_STREAM_ERROR[\"LOCAL_AUDIO_STREAM_ERROR_RECORD_FAILURE\"] = 4] = \"LOCAL_AUDIO_STREAM_ERROR_RECORD_FAILURE\";\n        /**\n         * 5: The local audio encoding fails.\n         */\n        LOCAL_AUDIO_STREAM_ERROR[LOCAL_AUDIO_STREAM_ERROR[\"LOCAL_AUDIO_STREAM_ERROR_ENCODE_FAILURE\"] = 5] = \"LOCAL_AUDIO_STREAM_ERROR_ENCODE_FAILURE\";\n    })(LOCAL_AUDIO_STREAM_ERROR = AgoraRtcEngine.LOCAL_AUDIO_STREAM_ERROR || (AgoraRtcEngine.LOCAL_AUDIO_STREAM_ERROR = {}));\n    /**\n     * Audio recording qualities.\n     */\n    var AUDIO_RECORDING_QUALITY_TYPE;\n    (function (AUDIO_RECORDING_QUALITY_TYPE) {\n        /**\n         * 0: Low quality. The sample rate is 32 kHz, and the file size is around\n         * 1.2 MB after 10 minutes of recording.\n         */\n        AUDIO_RECORDING_QUALITY_TYPE[AUDIO_RECORDING_QUALITY_TYPE[\"AUDIO_RECORDING_QUALITY_LOW\"] = 0] = \"AUDIO_RECORDING_QUALITY_LOW\";\n        /**\n         * 1: Medium quality. The sample rate is 32 kHz, and the file size is\n         * around 2 MB after 10 minutes of recording.\n         */\n        AUDIO_RECORDING_QUALITY_TYPE[AUDIO_RECORDING_QUALITY_TYPE[\"AUDIO_RECORDING_QUALITY_MEDIUM\"] = 1] = \"AUDIO_RECORDING_QUALITY_MEDIUM\";\n        /**\n         * 2: High quality. The sample rate is 32 kHz, and the file size is\n         * around 3.75 MB after 10 minutes of recording.\n         */\n        AUDIO_RECORDING_QUALITY_TYPE[AUDIO_RECORDING_QUALITY_TYPE[\"AUDIO_RECORDING_QUALITY_HIGH\"] = 2] = \"AUDIO_RECORDING_QUALITY_HIGH\";\n    })(AUDIO_RECORDING_QUALITY_TYPE = AgoraRtcEngine.AUDIO_RECORDING_QUALITY_TYPE || (AgoraRtcEngine.AUDIO_RECORDING_QUALITY_TYPE = {}));\n    /**\n     * Network quality types.\n     */\n    var QUALITY_TYPE;\n    (function (QUALITY_TYPE) {\n        /**\n         * 0: The network quality is unknown.\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_UNKNOWN\"] = 0] = \"QUALITY_UNKNOWN\";\n        /**\n         * 1: The network quality is excellent.\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_EXCELLENT\"] = 1] = \"QUALITY_EXCELLENT\";\n        /**\n         * 2: The network quality is quite good, but the bitrate may be slightly lower than excellent.\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_GOOD\"] = 2] = \"QUALITY_GOOD\";\n        /**\n         * 3: Users can feel the communication slightly impaired.\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_POOR\"] = 3] = \"QUALITY_POOR\";\n        /**\n         * 4: Users cannot communicate smoothly.\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_BAD\"] = 4] = \"QUALITY_BAD\";\n        /**\n         * 5: The network is so bad that users can barely communicate.\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_VBAD\"] = 5] = \"QUALITY_VBAD\";\n        /**\n         * 6: The network is down and users cannot communicate at all.\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_DOWN\"] = 6] = \"QUALITY_DOWN\";\n        /**\n         * 7: Users cannot detect the network quality. (Not in use.)\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_UNSUPPORTED\"] = 7] = \"QUALITY_UNSUPPORTED\";\n        /**\n         * 8: Detecting the network quality.\n         */\n        QUALITY_TYPE[QUALITY_TYPE[\"QUALITY_DETECTING\"] = 8] = \"QUALITY_DETECTING\";\n    })(QUALITY_TYPE = AgoraRtcEngine.QUALITY_TYPE || (AgoraRtcEngine.QUALITY_TYPE = {}));\n    /**\n     * Video display modes.\n     */\n    var RENDER_MODE_TYPE;\n    (function (RENDER_MODE_TYPE) {\n        /**\n         * 1: Uniformly scale the video until it fills the visible boundaries (cropped). One dimension of the video may have\n         * clipped contents.\n         */\n        RENDER_MODE_TYPE[RENDER_MODE_TYPE[\"RENDER_MODE_HIDDEN\"] = 1] = \"RENDER_MODE_HIDDEN\";\n        /**\n         * 2: Uniformly scale the video until one of its dimension fits the boundary (zoomed to fit). Areas that are not filled due\n         * to disparity in the aspect ratio are filled with black.\n         */\n        RENDER_MODE_TYPE[RENDER_MODE_TYPE[\"RENDER_MODE_FIT\"] = 2] = \"RENDER_MODE_FIT\";\n        /**\n         * @deprecated 3: This mode is deprecated.\n         */\n        RENDER_MODE_TYPE[RENDER_MODE_TYPE[\"RENDER_MODE_ADAPTIVE\"] = 3] = \"RENDER_MODE_ADAPTIVE\";\n        /**\n         4: The fill mode. In this mode, the SDK stretches or zooms the video to fill the display window.\n         */\n        RENDER_MODE_TYPE[RENDER_MODE_TYPE[\"RENDER_MODE_FILL\"] = 4] = \"RENDER_MODE_FILL\";\n    })(RENDER_MODE_TYPE = AgoraRtcEngine.RENDER_MODE_TYPE || (AgoraRtcEngine.RENDER_MODE_TYPE = {}));\n    /**\n     * Video mirror modes.\n     */\n    var VIDEO_MIRROR_MODE_TYPE;\n    (function (VIDEO_MIRROR_MODE_TYPE) {\n        /**\n         * 0: (Default) The SDK enables the mirror mode.\n         */\n        VIDEO_MIRROR_MODE_TYPE[VIDEO_MIRROR_MODE_TYPE[\"VIDEO_MIRROR_MODE_AUTO\"] = 0] = \"VIDEO_MIRROR_MODE_AUTO\";\n        /**\n         * 1: Enable mirror mode.\n         */\n        VIDEO_MIRROR_MODE_TYPE[VIDEO_MIRROR_MODE_TYPE[\"VIDEO_MIRROR_MODE_ENABLED\"] = 1] = \"VIDEO_MIRROR_MODE_ENABLED\";\n        /**\n         * 2: Disable mirror mode.\n         */\n        VIDEO_MIRROR_MODE_TYPE[VIDEO_MIRROR_MODE_TYPE[\"VIDEO_MIRROR_MODE_DISABLED\"] = 2] = \"VIDEO_MIRROR_MODE_DISABLED\";\n    })(VIDEO_MIRROR_MODE_TYPE = AgoraRtcEngine.VIDEO_MIRROR_MODE_TYPE || (AgoraRtcEngine.VIDEO_MIRROR_MODE_TYPE = {}));\n    /**\n     * @deprecated Video profiles.\n     */\n    var VIDEO_PROFILE_TYPE;\n    (function (VIDEO_PROFILE_TYPE) {\n        /**\n         * 0: 160 * 120, frame rate 15 fps, bitrate 65 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_120P\"] = 0] = \"VIDEO_PROFILE_LANDSCAPE_120P\";\n        /**\n         * 2: 120 * 120, frame rate 15 fps, bitrate 50 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_120P_3\"] = 2] = \"VIDEO_PROFILE_LANDSCAPE_120P_3\";\n        /**\n         * 10: 320*180, frame rate 15 fps, bitrate 140 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_180P\"] = 10] = \"VIDEO_PROFILE_LANDSCAPE_180P\";\n        /**\n         * 12: 180 * 180, frame rate 15 fps, bitrate 100 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_180P_3\"] = 12] = \"VIDEO_PROFILE_LANDSCAPE_180P_3\";\n        /**\n         * 13: 240 * 180, frame rate 15 fps, bitrate 120 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_180P_4\"] = 13] = \"VIDEO_PROFILE_LANDSCAPE_180P_4\";\n        /**\n         * 20: 320 * 240, frame rate 15 fps, bitrate 200 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_240P\"] = 20] = \"VIDEO_PROFILE_LANDSCAPE_240P\";\n        /**\n         * 22: 240 * 240, frame rate 15 fps, bitrate 140 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_240P_3\"] = 22] = \"VIDEO_PROFILE_LANDSCAPE_240P_3\";\n        /**\n         * 23: 424 * 240, frame rate 15 fps, bitrate 220 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_240P_4\"] = 23] = \"VIDEO_PROFILE_LANDSCAPE_240P_4\";\n        /**\n         * 30: 640 * 360, frame rate 15 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P\"] = 30] = \"VIDEO_PROFILE_LANDSCAPE_360P\";\n        /**\n         * 32: 360 * 360, frame rate 15 fps, bitrate 260 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P_3\"] = 32] = \"VIDEO_PROFILE_LANDSCAPE_360P_3\";\n        /**\n         * 33: 640 * 360, frame rate 30 fps, bitrate 600 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P_4\"] = 33] = \"VIDEO_PROFILE_LANDSCAPE_360P_4\";\n        /**\n         * 35: 360 * 360, frame rate 30 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P_6\"] = 35] = \"VIDEO_PROFILE_LANDSCAPE_360P_6\";\n        /**\n         * 36: 480 * 360, frame rate 15 fps, bitrate 320 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P_7\"] = 36] = \"VIDEO_PROFILE_LANDSCAPE_360P_7\";\n        /**\n         * 37: 480 * 360, frame rate 30 fps, bitrate 490 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P_8\"] = 37] = \"VIDEO_PROFILE_LANDSCAPE_360P_8\";\n        /**\n         * 38: 640 * 360, frame rate 15 fps, bitrate 800 Kbps.\n         * @note `LIVE_BROADCASTING` profile only.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P_9\"] = 38] = \"VIDEO_PROFILE_LANDSCAPE_360P_9\";\n        /**\n         * 39: 640 * 360, frame rate 24 fps, bitrate 800 Kbps.\n         * @note `LIVE_BROADCASTING` profile only.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P_10\"] = 39] = \"VIDEO_PROFILE_LANDSCAPE_360P_10\";\n        /**\n         * 100: 640 * 360, frame rate 24 fps, bitrate 1000 Kbps.\n         * @note `LIVE_BROADCASTING` profile only.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_360P_11\"] = 100] = \"VIDEO_PROFILE_LANDSCAPE_360P_11\";\n        /**\n         * 40: 640 * 480, frame rate 15 fps, bitrate 500 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_480P\"] = 40] = \"VIDEO_PROFILE_LANDSCAPE_480P\";\n        /**\n         * 42: 480 * 480, frame rate 15 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_480P_3\"] = 42] = \"VIDEO_PROFILE_LANDSCAPE_480P_3\";\n        /**\n         * 43: 640 * 480, frame rate 30 fps, bitrate 750 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_480P_4\"] = 43] = \"VIDEO_PROFILE_LANDSCAPE_480P_4\";\n        /**\n         * 45: 480 * 480, frame rate 30 fps, bitrate 600 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_480P_6\"] = 45] = \"VIDEO_PROFILE_LANDSCAPE_480P_6\";\n        /**\n         * 47: 848 * 480, frame rate 15 fps, bitrate 610 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_480P_8\"] = 47] = \"VIDEO_PROFILE_LANDSCAPE_480P_8\";\n        /**\n         * 48: 848 * 480, frame rate 30 fps, bitrate 930 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_480P_9\"] = 48] = \"VIDEO_PROFILE_LANDSCAPE_480P_9\";\n        /**\n         * 49: 640 * 480, frame rate 10 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_480P_10\"] = 49] = \"VIDEO_PROFILE_LANDSCAPE_480P_10\";\n        /**\n         * 50: 1280 * 720, frame rate 15 fps, bitrate 1130 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_720P\"] = 50] = \"VIDEO_PROFILE_LANDSCAPE_720P\";\n        /**\n         * 52: 1280 * 720, frame rate 30 fps, bitrate 1710 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_720P_3\"] = 52] = \"VIDEO_PROFILE_LANDSCAPE_720P_3\";\n        /**\n         * 54: 960 * 720, frame rate 15 fps, bitrate 910 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_720P_5\"] = 54] = \"VIDEO_PROFILE_LANDSCAPE_720P_5\";\n        /**\n         * 55: 960 * 720, frame rate 30 fps, bitrate 1380 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_720P_6\"] = 55] = \"VIDEO_PROFILE_LANDSCAPE_720P_6\";\n        /**\n         * 60: 1920 * 1080, frame rate 15 fps, bitrate 2080 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_1080P\"] = 60] = \"VIDEO_PROFILE_LANDSCAPE_1080P\";\n        /**\n         * 62: 1920 * 1080, frame rate 30 fps, bitrate 3150 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_1080P_3\"] = 62] = \"VIDEO_PROFILE_LANDSCAPE_1080P_3\";\n        /**\n         * 64: 1920 * 1080, frame rate 60 fps, bitrate 4780 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_1080P_5\"] = 64] = \"VIDEO_PROFILE_LANDSCAPE_1080P_5\";\n        /**\n         * 66: 2560 * 1440, frame rate 30 fps, bitrate 4850 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_1440P\"] = 66] = \"VIDEO_PROFILE_LANDSCAPE_1440P\";\n        /**\n         * 67: 2560 * 1440, frame rate 60 fps, bitrate 6500 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_1440P_2\"] = 67] = \"VIDEO_PROFILE_LANDSCAPE_1440P_2\";\n        /**\n         * 70: 3840 * 2160, frame rate 30 fps, bitrate 6500 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_4K\"] = 70] = \"VIDEO_PROFILE_LANDSCAPE_4K\";\n        /**\n         * 72: 3840 * 2160, frame rate 60 fps, bitrate 6500 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_LANDSCAPE_4K_3\"] = 72] = \"VIDEO_PROFILE_LANDSCAPE_4K_3\";\n        /**\n         * 1000: 120 * 160, frame rate 15 fps, bitrate 65 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_120P\"] = 1000] = \"VIDEO_PROFILE_PORTRAIT_120P\";\n        /**\n         * 1002: 120 * 120, frame rate 15 fps, bitrate 50 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_120P_3\"] = 1002] = \"VIDEO_PROFILE_PORTRAIT_120P_3\";\n        /**\n         * 1010: 180 * 320, frame rate 15 fps, bitrate 140 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_180P\"] = 1010] = \"VIDEO_PROFILE_PORTRAIT_180P\";\n        /**\n         * 1012: 180 * 180, frame rate 15 fps, bitrate 100 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_180P_3\"] = 1012] = \"VIDEO_PROFILE_PORTRAIT_180P_3\";\n        /**\n         * 1013: 180 * 240, frame rate 15 fps, bitrate 120 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_180P_4\"] = 1013] = \"VIDEO_PROFILE_PORTRAIT_180P_4\";\n        /**\n         * 1020: 240 * 320, frame rate 15 fps, bitrate 200 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_240P\"] = 1020] = \"VIDEO_PROFILE_PORTRAIT_240P\";\n        /**\n         * 1022: 240 * 240, frame rate 15 fps, bitrate 140 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_240P_3\"] = 1022] = \"VIDEO_PROFILE_PORTRAIT_240P_3\";\n        /**\n         * 1023: 240 * 424, frame rate 15 fps, bitrate 220 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_240P_4\"] = 1023] = \"VIDEO_PROFILE_PORTRAIT_240P_4\";\n        /**\n         * 1030: 360 * 640, frame rate 15 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P\"] = 1030] = \"VIDEO_PROFILE_PORTRAIT_360P\";\n        /**\n         * 1032: 360 * 360, frame rate 15 fps, bitrate 260 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P_3\"] = 1032] = \"VIDEO_PROFILE_PORTRAIT_360P_3\";\n        /**\n         * 1033: 360 * 640, frame rate 30 fps, bitrate 600 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P_4\"] = 1033] = \"VIDEO_PROFILE_PORTRAIT_360P_4\";\n        /**\n         * 1035: 360 * 360, frame rate 30 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P_6\"] = 1035] = \"VIDEO_PROFILE_PORTRAIT_360P_6\";\n        /**\n         * 1036: 360 * 480, frame rate 15 fps, bitrate 320 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P_7\"] = 1036] = \"VIDEO_PROFILE_PORTRAIT_360P_7\";\n        /**\n         * 1037: 360 * 480, frame rate 30 fps, bitrate 490 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P_8\"] = 1037] = \"VIDEO_PROFILE_PORTRAIT_360P_8\";\n        /**\n         * 1038: 360 * 640, frame rate 15 fps, bitrate 800 Kbps.\n         * @note `LIVE_BROADCASTING` profile only.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P_9\"] = 1038] = \"VIDEO_PROFILE_PORTRAIT_360P_9\";\n        /**\n         * 1039: 360 * 640, frame rate 24 fps, bitrate 800 Kbps.\n         * @note `LIVE_BROADCASTING` profile only.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P_10\"] = 1039] = \"VIDEO_PROFILE_PORTRAIT_360P_10\";\n        /**\n         * 1100: 360 * 640, frame rate 24 fps, bitrate 1000 Kbps.\n         * @note `LIVE_BROADCASTING` profile only.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_360P_11\"] = 1100] = \"VIDEO_PROFILE_PORTRAIT_360P_11\";\n        /**\n         * 1040: 480 * 640, frame rate 15 fps, bitrate 500 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_480P\"] = 1040] = \"VIDEO_PROFILE_PORTRAIT_480P\";\n        /**\n         * 1042: 480 * 480, frame rate 15 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_480P_3\"] = 1042] = \"VIDEO_PROFILE_PORTRAIT_480P_3\";\n        /**\n         * 1043: 480 * 640, frame rate 30 fps, bitrate 750 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_480P_4\"] = 1043] = \"VIDEO_PROFILE_PORTRAIT_480P_4\";\n        /**\n         * 1045: 480 * 480, frame rate 30 fps, bitrate 600 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_480P_6\"] = 1045] = \"VIDEO_PROFILE_PORTRAIT_480P_6\";\n        /**\n         * 1047: 480 * 848, frame rate 15 fps, bitrate 610 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_480P_8\"] = 1047] = \"VIDEO_PROFILE_PORTRAIT_480P_8\";\n        /**\n         * 1048: 480 * 848, frame rate 30 fps, bitrate 930 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_480P_9\"] = 1048] = \"VIDEO_PROFILE_PORTRAIT_480P_9\";\n        /**\n         * 1049: 480 * 640, frame rate 10 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_480P_10\"] = 1049] = \"VIDEO_PROFILE_PORTRAIT_480P_10\";\n        /**\n         * 1050: 720 * 1280, frame rate 15 fps, bitrate 1130 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_720P\"] = 1050] = \"VIDEO_PROFILE_PORTRAIT_720P\";\n        /**\n         * 1052: 720 * 1280, frame rate 30 fps, bitrate 1710 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_720P_3\"] = 1052] = \"VIDEO_PROFILE_PORTRAIT_720P_3\";\n        /**\n         * 1054: 720 * 960, frame rate 15 fps, bitrate 910 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_720P_5\"] = 1054] = \"VIDEO_PROFILE_PORTRAIT_720P_5\";\n        /**\n         * 1055: 720 * 960, frame rate 30 fps, bitrate 1380 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_720P_6\"] = 1055] = \"VIDEO_PROFILE_PORTRAIT_720P_6\";\n        /**\n         * 1060: 1080 * 1920, frame rate 15 fps, bitrate 2080 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_1080P\"] = 1060] = \"VIDEO_PROFILE_PORTRAIT_1080P\";\n        /**\n         * 1062: 1080 * 1920, frame rate 30 fps, bitrate 3150 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_1080P_3\"] = 1062] = \"VIDEO_PROFILE_PORTRAIT_1080P_3\";\n        /**\n         * 1064: 1080 * 1920, frame rate 60 fps, bitrate 4780 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_1080P_5\"] = 1064] = \"VIDEO_PROFILE_PORTRAIT_1080P_5\";\n        /**\n         * 1066: 1440 * 2560, frame rate 30 fps, bitrate 4850 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_1440P\"] = 1066] = \"VIDEO_PROFILE_PORTRAIT_1440P\";\n        /**\n         * 1067: 1440 * 2560, frame rate 60 fps, bitrate 6500 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_1440P_2\"] = 1067] = \"VIDEO_PROFILE_PORTRAIT_1440P_2\";\n        /**\n         * 1070: 2160 * 3840, frame rate 30 fps, bitrate 6500 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_4K\"] = 1070] = \"VIDEO_PROFILE_PORTRAIT_4K\";\n        /**\n         * 1072: 2160 * 3840, frame rate 60 fps, bitrate 6500 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_PORTRAIT_4K_3\"] = 1072] = \"VIDEO_PROFILE_PORTRAIT_4K_3\";\n        /**\n         * Default 640 * 360, frame rate 15 fps, bitrate 400 Kbps.\n         */\n        VIDEO_PROFILE_TYPE[VIDEO_PROFILE_TYPE[\"VIDEO_PROFILE_DEFAULT\"] = 30] = \"VIDEO_PROFILE_DEFAULT\";\n    })(VIDEO_PROFILE_TYPE = AgoraRtcEngine.VIDEO_PROFILE_TYPE || (AgoraRtcEngine.VIDEO_PROFILE_TYPE = {}));\n    /**\n     * Audio profiles. Sets the sample rate, bitrate, encoding mode, and the number of channels.\n     */\n    var AUDIO_PROFILE_TYPE;\n    (function (AUDIO_PROFILE_TYPE) {\n        /**\n         * 0: Default audio profile:\n         * - For the interactive streaming profile: A sample rate of 48 KHz, music encoding, mono, and a bitrate of up to 64 Kbps.\n         * - For the `COMMUNICATION` profile: A sample rate of 32 KHz, music encoding, mono, and a bitrate of up to 18 Kbps.\n         */\n        AUDIO_PROFILE_TYPE[AUDIO_PROFILE_TYPE[\"AUDIO_PROFILE_DEFAULT\"] = 0] = \"AUDIO_PROFILE_DEFAULT\";\n        /**\n         * 1: A sample rate of 32 KHz, audio encoding, mono, and a bitrate of up to 18 Kbps.\n         */\n        AUDIO_PROFILE_TYPE[AUDIO_PROFILE_TYPE[\"AUDIO_PROFILE_SPEECH_STANDARD\"] = 1] = \"AUDIO_PROFILE_SPEECH_STANDARD\";\n        /**\n         * 2: A sample rate of 48 KHz, music encoding, mono, and a bitrate of up to 64 Kbps.\n         */\n        AUDIO_PROFILE_TYPE[AUDIO_PROFILE_TYPE[\"AUDIO_PROFILE_MUSIC_STANDARD\"] = 2] = \"AUDIO_PROFILE_MUSIC_STANDARD\";\n        /**\n         * 3: A sample rate of 48 KHz, music encoding, stereo, and a bitrate of up to 80 Kbps.\n         */\n        AUDIO_PROFILE_TYPE[AUDIO_PROFILE_TYPE[\"AUDIO_PROFILE_MUSIC_STANDARD_STEREO\"] = 3] = \"AUDIO_PROFILE_MUSIC_STANDARD_STEREO\";\n        /**\n         * 4: A sample rate of 48 KHz, music encoding, mono, and a bitrate of up to 96 Kbps.\n         */\n        AUDIO_PROFILE_TYPE[AUDIO_PROFILE_TYPE[\"AUDIO_PROFILE_MUSIC_HIGH_QUALITY\"] = 4] = \"AUDIO_PROFILE_MUSIC_HIGH_QUALITY\";\n        /**\n         * 5: A sample rate of 48 KHz, music encoding, stereo, and a bitrate of up to 128 Kbps.\n         */\n        AUDIO_PROFILE_TYPE[AUDIO_PROFILE_TYPE[\"AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO\"] = 5] = \"AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO\";\n        /**\n         * 6: A sample rate of 16 KHz, audio encoding, mono, and Acoustic Echo Cancellation (AES) enabled.\n         */\n        AUDIO_PROFILE_TYPE[AUDIO_PROFILE_TYPE[\"AUDIO_PROFILE_IOT\"] = 6] = \"AUDIO_PROFILE_IOT\";\n        /**\n         * The number of elements in the enumeration.\n         */\n        AUDIO_PROFILE_TYPE[AUDIO_PROFILE_TYPE[\"AUDIO_PROFILE_NUM\"] = 7] = \"AUDIO_PROFILE_NUM\";\n    })(AUDIO_PROFILE_TYPE = AgoraRtcEngine.AUDIO_PROFILE_TYPE || (AgoraRtcEngine.AUDIO_PROFILE_TYPE = {}));\n    /**\n     * Audio application scenarios.\n     */\n    var AUDIO_SCENARIO_TYPE;\n    (function (AUDIO_SCENARIO_TYPE) {\n        /**\n         * 0: Default audio scenario..\n         */\n        AUDIO_SCENARIO_TYPE[AUDIO_SCENARIO_TYPE[\"AUDIO_SCENARIO_DEFAULT\"] = 0] = \"AUDIO_SCENARIO_DEFAULT\";\n        /**\n         * 1: Entertainment scenario where users need to frequently switch the user role.\n         */\n        AUDIO_SCENARIO_TYPE[AUDIO_SCENARIO_TYPE[\"AUDIO_SCENARIO_CHATROOM_ENTERTAINMENT\"] = 1] = \"AUDIO_SCENARIO_CHATROOM_ENTERTAINMENT\";\n        /**\n         * 2: Education scenario where users want smoothness and stability.\n         */\n        AUDIO_SCENARIO_TYPE[AUDIO_SCENARIO_TYPE[\"AUDIO_SCENARIO_EDUCATION\"] = 2] = \"AUDIO_SCENARIO_EDUCATION\";\n        /**\n         * 3: High-quality audio chatroom scenario where hosts mainly play music.\n         */\n        AUDIO_SCENARIO_TYPE[AUDIO_SCENARIO_TYPE[\"AUDIO_SCENARIO_GAME_STREAMING\"] = 3] = \"AUDIO_SCENARIO_GAME_STREAMING\";\n        /**\n         * 4: Showroom scenario where a single host wants high-quality audio.\n         */\n        AUDIO_SCENARIO_TYPE[AUDIO_SCENARIO_TYPE[\"AUDIO_SCENARIO_SHOWROOM\"] = 4] = \"AUDIO_SCENARIO_SHOWROOM\";\n        /**\n         * 5: Gaming scenario for group chat that only contains the human voice.\n         */\n        AUDIO_SCENARIO_TYPE[AUDIO_SCENARIO_TYPE[\"AUDIO_SCENARIO_CHATROOM_GAMING\"] = 5] = \"AUDIO_SCENARIO_CHATROOM_GAMING\";\n        /**\n         * 6: IoT (Internet of Things) scenario where users use IoT devices with low power consumption.\n         */\n        AUDIO_SCENARIO_TYPE[AUDIO_SCENARIO_TYPE[\"AUDIO_SCENARIO_IOT\"] = 6] = \"AUDIO_SCENARIO_IOT\";\n        /**\n         * The number of elements in the enumeration.\n         */\n        AUDIO_SCENARIO_TYPE[AUDIO_SCENARIO_TYPE[\"AUDIO_SCENARIO_NUM\"] = 7] = \"AUDIO_SCENARIO_NUM\";\n    })(AUDIO_SCENARIO_TYPE = AgoraRtcEngine.AUDIO_SCENARIO_TYPE || (AgoraRtcEngine.AUDIO_SCENARIO_TYPE = {}));\n    /**\n     * The channel profile.\n     */\n    var CHANNEL_PROFILE_TYPE;\n    (function (CHANNEL_PROFILE_TYPE) {\n        /**\n         * (Default) Communication. This profile applies to scenarios such as an audio call or video call,\n         * where all users can publish and subscribe to streams.\n         */\n        CHANNEL_PROFILE_TYPE[CHANNEL_PROFILE_TYPE[\"CHANNEL_PROFILE_COMMUNICATION\"] = 0] = \"CHANNEL_PROFILE_COMMUNICATION\";\n        /**\n         * Live streaming. In this profile, uses have roles, namely, host and audience (default).\n         *\n         * A host both publishes and subscribes to streams, while an audience subscribes to streams only.\n         * This profile applies to scenarios such as a chat room or interactive video streaming.\n         */\n        CHANNEL_PROFILE_TYPE[CHANNEL_PROFILE_TYPE[\"CHANNEL_PROFILE_LIVE_BROADCASTING\"] = 1] = \"CHANNEL_PROFILE_LIVE_BROADCASTING\";\n        /**\n         * 2: Agora recommends not using this profile.\n         */\n        CHANNEL_PROFILE_TYPE[CHANNEL_PROFILE_TYPE[\"CHANNEL_PROFILE_GAME\"] = 2] = \"CHANNEL_PROFILE_GAME\";\n    })(CHANNEL_PROFILE_TYPE = AgoraRtcEngine.CHANNEL_PROFILE_TYPE || (AgoraRtcEngine.CHANNEL_PROFILE_TYPE = {}));\n    /**\n     * Client roles in the live interactive streaming.\n     */\n    var CLIENT_ROLE_TYPE;\n    (function (CLIENT_ROLE_TYPE) {\n        /**\n         * 1: Host. A host can both send and receive streams.\n         */\n        CLIENT_ROLE_TYPE[CLIENT_ROLE_TYPE[\"CLIENT_ROLE_BROADCASTER\"] = 1] = \"CLIENT_ROLE_BROADCASTER\";\n        /**\n         * 2: Audience, the default role. An audience can only receive streams.\n         */\n        CLIENT_ROLE_TYPE[CLIENT_ROLE_TYPE[\"CLIENT_ROLE_AUDIENCE\"] = 2] = \"CLIENT_ROLE_AUDIENCE\";\n    })(CLIENT_ROLE_TYPE = AgoraRtcEngine.CLIENT_ROLE_TYPE || (AgoraRtcEngine.CLIENT_ROLE_TYPE = {}));\n    /**\n     * The latency level of an audience member in a live interactive streaming.\n     *\n     * @note Takes effect only when the user role is `CLIENT_ROLE_BROADCASTER`.\n     */\n    var AUDIENCE_LATENCY_LEVEL_TYPE;\n    (function (AUDIENCE_LATENCY_LEVEL_TYPE) {\n        /**\n         * 1: Low latency.\n         */\n        AUDIENCE_LATENCY_LEVEL_TYPE[AUDIENCE_LATENCY_LEVEL_TYPE[\"AUDIENCE_LATENCY_LEVEL_LOW_LATENCY\"] = 1] = \"AUDIENCE_LATENCY_LEVEL_LOW_LATENCY\";\n        /**\n         * 2: (Default) Ultra low latency.\n         */\n        AUDIENCE_LATENCY_LEVEL_TYPE[AUDIENCE_LATENCY_LEVEL_TYPE[\"AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY\"] = 2] = \"AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY\";\n    })(AUDIENCE_LATENCY_LEVEL_TYPE = AgoraRtcEngine.AUDIENCE_LATENCY_LEVEL_TYPE || (AgoraRtcEngine.AUDIENCE_LATENCY_LEVEL_TYPE = {}));\n    /**\n     * The reason why the super-resolution algorithm is not successfully enabled.\n     */\n    var SUPER_RESOLUTION_STATE_REASON;\n    (function (SUPER_RESOLUTION_STATE_REASON) {\n        /**\n         * 0: The super-resolution algorithm is successfully enabled.\n         */\n        SUPER_RESOLUTION_STATE_REASON[SUPER_RESOLUTION_STATE_REASON[\"SR_STATE_REASON_SUCCESS\"] = 0] = \"SR_STATE_REASON_SUCCESS\";\n        /**\n         * 1: The origin resolution of the remote video is beyond the range where\n         * the super-resolution algorithm can be applied.\n         */\n        SUPER_RESOLUTION_STATE_REASON[SUPER_RESOLUTION_STATE_REASON[\"SR_STATE_REASON_STREAM_OVER_LIMITATION\"] = 1] = \"SR_STATE_REASON_STREAM_OVER_LIMITATION\";\n        /**\n         * 2: Another user is already using the super-resolution algorithm.\n         */\n        SUPER_RESOLUTION_STATE_REASON[SUPER_RESOLUTION_STATE_REASON[\"SR_STATE_REASON_USER_COUNT_OVER_LIMITATION\"] = 2] = \"SR_STATE_REASON_USER_COUNT_OVER_LIMITATION\";\n        /**\n         * 3: The device does not support the super-resolution algorithm.\n         */\n        SUPER_RESOLUTION_STATE_REASON[SUPER_RESOLUTION_STATE_REASON[\"SR_STATE_REASON_DEVICE_NOT_SUPPORTED\"] = 3] = \"SR_STATE_REASON_DEVICE_NOT_SUPPORTED\";\n    })(SUPER_RESOLUTION_STATE_REASON = AgoraRtcEngine.SUPER_RESOLUTION_STATE_REASON || (AgoraRtcEngine.SUPER_RESOLUTION_STATE_REASON = {}));\n    /**\n     * Reasons for a user being offline.\n     */\n    var USER_OFFLINE_REASON_TYPE;\n    (function (USER_OFFLINE_REASON_TYPE) {\n        /**\n         * 0: The user quits the call.\n         */\n        USER_OFFLINE_REASON_TYPE[USER_OFFLINE_REASON_TYPE[\"USER_OFFLINE_QUIT\"] = 0] = \"USER_OFFLINE_QUIT\";\n        /**\n         * 1: The SDK times out and the user drops offline because no data packet is received within a certain period of time. If\n         * the user quits the call and the message is not passed to the SDK (due to an unreliable channel), the SDK assumes the user\n         * dropped offline.\n         */\n        USER_OFFLINE_REASON_TYPE[USER_OFFLINE_REASON_TYPE[\"USER_OFFLINE_DROPPED\"] = 1] = \"USER_OFFLINE_DROPPED\";\n        /**\n         * 2: (`LIVE_BROADCASTING` only.) The client role switched from the host to the audience. */\n        USER_OFFLINE_REASON_TYPE[USER_OFFLINE_REASON_TYPE[\"USER_OFFLINE_BECOME_AUDIENCE\"] = 2] = \"USER_OFFLINE_BECOME_AUDIENCE\";\n    })(USER_OFFLINE_REASON_TYPE = AgoraRtcEngine.USER_OFFLINE_REASON_TYPE || (AgoraRtcEngine.USER_OFFLINE_REASON_TYPE = {}));\n    /**\n     * States of the RTMP streaming.\n     */\n    var RTMP_STREAM_PUBLISH_STATE;\n    (function (RTMP_STREAM_PUBLISH_STATE) {\n        /**\n         * The RTMP streaming has not started or has ended. This state is also triggered after you remove an RTMP address from\n         * the CDN by calling [removePublishStreamUrl]{@link AgoraRtcEngine.removePublishStreamUrl}.\n         */\n        RTMP_STREAM_PUBLISH_STATE[RTMP_STREAM_PUBLISH_STATE[\"RTMP_STREAM_PUBLISH_STATE_IDLE\"] = 0] = \"RTMP_STREAM_PUBLISH_STATE_IDLE\";\n        /**\n         * The SDK is connecting to Agora streaming server and the RTMP server. This state is triggered after you call the\n         * [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl} method.\n         */\n        RTMP_STREAM_PUBLISH_STATE[RTMP_STREAM_PUBLISH_STATE[\"RTMP_STREAM_PUBLISH_STATE_CONNECTING\"] = 1] = \"RTMP_STREAM_PUBLISH_STATE_CONNECTING\";\n        /**\n         * The RTMP streaming publishes. The SDK successfully publishes the RTMP streaming and returns this state.\n         */\n        RTMP_STREAM_PUBLISH_STATE[RTMP_STREAM_PUBLISH_STATE[\"RTMP_STREAM_PUBLISH_STATE_RUNNING\"] = 2] = \"RTMP_STREAM_PUBLISH_STATE_RUNNING\";\n        /**\n         * The RTMP streaming is recovering. When exceptions occur to the CDN, or the streaming is interrupted, the SDK tries to resume\n         * RTMP streaming and returns this state.\n         * - If the SDK successfully resumes the streaming, `RTMP_STREAM_PUBLISH_STATE_RUNNING(2)` returns.\n         * - If the streaming does not resume within 60 seconds or server errors occur,\n         * [RTMP_STREAM_PUBLISH_STATE_FAILURE]{@link AgoraRtcEngine.RTMP_STREAM_PUBLISH_STATE.RTMP_STREAM_PUBLISH_STATE_FAILURE}(4) returns.\n         * You can also reconnect to the server by calling the [removePublishStreamUrl]{@link AgoraRtcEngine.removePublishStreamUrl} and\n         * [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl} methods.\n         */\n        RTMP_STREAM_PUBLISH_STATE[RTMP_STREAM_PUBLISH_STATE[\"RTMP_STREAM_PUBLISH_STATE_RECOVERING\"] = 3] = \"RTMP_STREAM_PUBLISH_STATE_RECOVERING\";\n        /**\n         * The RTMP streaming fails. See the `errCode` parameter for the detailed error information. You can also call the\n         * [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl} method to publish the RTMP streaming again.\n         */\n        RTMP_STREAM_PUBLISH_STATE[RTMP_STREAM_PUBLISH_STATE[\"RTMP_STREAM_PUBLISH_STATE_FAILURE\"] = 4] = \"RTMP_STREAM_PUBLISH_STATE_FAILURE\";\n    })(RTMP_STREAM_PUBLISH_STATE = AgoraRtcEngine.RTMP_STREAM_PUBLISH_STATE || (AgoraRtcEngine.RTMP_STREAM_PUBLISH_STATE = {}));\n    /**\n     * Error codes of the RTMP streaming.\n     */\n    var RTMP_STREAM_PUBLISH_ERROR;\n    (function (RTMP_STREAM_PUBLISH_ERROR) {\n        /**\n         * The RTMP streaming publishes successfully.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_OK\"] = 0] = \"RTMP_STREAM_PUBLISH_ERROR_OK\";\n        /**\n         * Invalid argument used. If, for example, you do not call the [setLiveTranscoding]{@link AgoraRtcEngine.setLiveTranscoding} method to\n         * configure the [LiveTranscoding]{@link AgoraRtcEngine.LiveTranscoding} parameters before calling the\n         * [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl} method, the SDK returns this error. Check whether you set the\n         * parameters in the *setLiveTranscoding* method properly.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_INVALID_ARGUMENT\"] = 1] = \"RTMP_STREAM_PUBLISH_ERROR_INVALID_ARGUMENT\";\n        /**\n         * The RTMP streaming is encrypted and cannot be published.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_ENCRYPTED_STREAM_NOT_ALLOWED\"] = 2] = \"RTMP_STREAM_PUBLISH_ERROR_ENCRYPTED_STREAM_NOT_ALLOWED\";\n        /**\n         * Timeout for the RTMP streaming. Call the [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl} method to publish\n         * the streaming again.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_CONNECTION_TIMEOUT\"] = 3] = \"RTMP_STREAM_PUBLISH_ERROR_CONNECTION_TIMEOUT\";\n        /**\n         * An error occurs in Agora's streaming server. Call the [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl} method to\n         * publish the streaming again.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_INTERNAL_SERVER_ERROR\"] = 4] = \"RTMP_STREAM_PUBLISH_ERROR_INTERNAL_SERVER_ERROR\";\n        /**\n         * An error occurs in the RTMP server.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_RTMP_SERVER_ERROR\"] = 5] = \"RTMP_STREAM_PUBLISH_ERROR_RTMP_SERVER_ERROR\";\n        /**\n         * The RTMP streaming publishes too frequently.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_TOO_OFTEN\"] = 6] = \"RTMP_STREAM_PUBLISH_ERROR_TOO_OFTEN\";\n        /**\n         * The host publishes more than 10 URLs. Delete the unnecessary URLs before adding new ones.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_REACH_LIMIT\"] = 7] = \"RTMP_STREAM_PUBLISH_ERROR_REACH_LIMIT\";\n        /**\n         * The host manipulates other hosts' URLs. Check your app logic.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_NOT_AUTHORIZED\"] = 8] = \"RTMP_STREAM_PUBLISH_ERROR_NOT_AUTHORIZED\";\n        /**\n         * Agora's server fails to find the RTMP streaming.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_STREAM_NOT_FOUND\"] = 9] = \"RTMP_STREAM_PUBLISH_ERROR_STREAM_NOT_FOUND\";\n        /**\n         * The format of the RTMP streaming URL is not supported. Check whether the URL format is correct.\n         */\n        RTMP_STREAM_PUBLISH_ERROR[RTMP_STREAM_PUBLISH_ERROR[\"RTMP_STREAM_PUBLISH_ERROR_FORMAT_NOT_SUPPORTED\"] = 10] = \"RTMP_STREAM_PUBLISH_ERROR_FORMAT_NOT_SUPPORTED\";\n    })(RTMP_STREAM_PUBLISH_ERROR = AgoraRtcEngine.RTMP_STREAM_PUBLISH_ERROR || (AgoraRtcEngine.RTMP_STREAM_PUBLISH_ERROR = {}));\n    /**\n     * Events during the RTMP streaming.\n     */\n    var RTMP_STREAMING_EVENT;\n    (function (RTMP_STREAMING_EVENT) {\n        /**\n         * An error occurs when you add a background image or a watermark image to the RTMP stream.\n         */\n        RTMP_STREAMING_EVENT[RTMP_STREAMING_EVENT[\"RTMP_STREAMING_EVENT_FAILED_LOAD_IMAGE\"] = 1] = \"RTMP_STREAMING_EVENT_FAILED_LOAD_IMAGE\";\n    })(RTMP_STREAMING_EVENT = AgoraRtcEngine.RTMP_STREAMING_EVENT || (AgoraRtcEngine.RTMP_STREAMING_EVENT = {}));\n    /**\n     * States of importing an external media stream in the live interactive streaming.\n     */\n    var INJECT_STREAM_STATUS;\n    (function (INJECT_STREAM_STATUS) {\n        /**\n         * 0: The external media stream imported successfully.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_START_SUCCESS\"] = 0] = \"INJECT_STREAM_STATUS_START_SUCCESS\";\n        /**\n         * 1: The external media stream already exists.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_START_ALREADY_EXISTS\"] = 1] = \"INJECT_STREAM_STATUS_START_ALREADY_EXISTS\";\n        /**\n         * 2: The external media stream to be imported is unauthorized.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_START_UNAUTHORIZED\"] = 2] = \"INJECT_STREAM_STATUS_START_UNAUTHORIZED\";\n        /**\n         * 3: Import external media stream timeout.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_START_TIMEDOUT\"] = 3] = \"INJECT_STREAM_STATUS_START_TIMEDOUT\";\n        /**\n         * 4: Import external media stream failed.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_START_FAILED\"] = 4] = \"INJECT_STREAM_STATUS_START_FAILED\";\n        /**\n         * 5: The external media stream stopped importing successfully.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_STOP_SUCCESS\"] = 5] = \"INJECT_STREAM_STATUS_STOP_SUCCESS\";\n        /**\n         * 6: No external media stream is found.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_STOP_NOT_FOUND\"] = 6] = \"INJECT_STREAM_STATUS_STOP_NOT_FOUND\";\n        /**\n         * 7: The external media stream to be stopped importing is unauthorized.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_STOP_UNAUTHORIZED\"] = 7] = \"INJECT_STREAM_STATUS_STOP_UNAUTHORIZED\";\n        /**\n         * 8: Stop importing external media stream timeout.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_STOP_TIMEDOUT\"] = 8] = \"INJECT_STREAM_STATUS_STOP_TIMEDOUT\";\n        /**\n         * 9: Stop importing external media stream failed.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_STOP_FAILED\"] = 9] = \"INJECT_STREAM_STATUS_STOP_FAILED\";\n        /**\n         * 10: The external media stream is corrupted.\n         */\n        INJECT_STREAM_STATUS[INJECT_STREAM_STATUS[\"INJECT_STREAM_STATUS_BROKEN\"] = 10] = \"INJECT_STREAM_STATUS_BROKEN\";\n    })(INJECT_STREAM_STATUS = AgoraRtcEngine.INJECT_STREAM_STATUS || (AgoraRtcEngine.INJECT_STREAM_STATUS = {}));\n    /**\n     * Remote video stream types.\n     */\n    var REMOTE_VIDEO_STREAM_TYPE;\n    (function (REMOTE_VIDEO_STREAM_TYPE) {\n        /**\n         * 0: High-stream video.\n         */\n        REMOTE_VIDEO_STREAM_TYPE[REMOTE_VIDEO_STREAM_TYPE[\"REMOTE_VIDEO_STREAM_HIGH\"] = 0] = \"REMOTE_VIDEO_STREAM_HIGH\";\n        /**\n         * 1: Low-stream video.\n         */\n        REMOTE_VIDEO_STREAM_TYPE[REMOTE_VIDEO_STREAM_TYPE[\"REMOTE_VIDEO_STREAM_LOW\"] = 1] = \"REMOTE_VIDEO_STREAM_LOW\";\n    })(REMOTE_VIDEO_STREAM_TYPE = AgoraRtcEngine.REMOTE_VIDEO_STREAM_TYPE || (AgoraRtcEngine.REMOTE_VIDEO_STREAM_TYPE = {}));\n    /**\n     * The use mode of the audio data in the [onRecordAudioFrame]{@link AgoraRtcEngine.onRecordAudioFrame} or\n     * [onPlaybackAudioFrame]{@link AgoraRtcEngine.onPlaybackAudioFrame} callback.\n     */\n    var RAW_AUDIO_FRAME_OP_MODE_TYPE;\n    (function (RAW_AUDIO_FRAME_OP_MODE_TYPE) {\n        /**\n         * 0: Read-only mode: Users only read the [AudioFrame]{@link AgoraRtcEngine.AudioFrame} data without modifying anything. For example,\n         * when users acquire the data with the Agora SDK, then push the RTMP streams.\n         */\n        RAW_AUDIO_FRAME_OP_MODE_TYPE[RAW_AUDIO_FRAME_OP_MODE_TYPE[\"RAW_AUDIO_FRAME_OP_MODE_READ_ONLY\"] = 0] = \"RAW_AUDIO_FRAME_OP_MODE_READ_ONLY\";\n        /**\n         * 1: Write-only mode: Users replace the [AudioFrame]{@link AgoraRtcEngine.AudioFrame} data with their own data and pass the data to\n         * the SDK for encoding. For example, when users acquire the data.\n         */\n        RAW_AUDIO_FRAME_OP_MODE_TYPE[RAW_AUDIO_FRAME_OP_MODE_TYPE[\"RAW_AUDIO_FRAME_OP_MODE_WRITE_ONLY\"] = 1] = \"RAW_AUDIO_FRAME_OP_MODE_WRITE_ONLY\";\n        /**\n         * 2: Read and write mode: Users read the data from [AudioFrame]{@link AgoraRtcEngine.AudioFrame} , modify it, and then play it.\n         * For example, when users have their own sound-effect processing module and perform some voice pre-processing, such as\n         * a voice change.\n         */\n        RAW_AUDIO_FRAME_OP_MODE_TYPE[RAW_AUDIO_FRAME_OP_MODE_TYPE[\"RAW_AUDIO_FRAME_OP_MODE_READ_WRITE\"] = 2] = \"RAW_AUDIO_FRAME_OP_MODE_READ_WRITE\";\n    })(RAW_AUDIO_FRAME_OP_MODE_TYPE = AgoraRtcEngine.RAW_AUDIO_FRAME_OP_MODE_TYPE || (AgoraRtcEngine.RAW_AUDIO_FRAME_OP_MODE_TYPE = {}));\n    /**\n     * Audio-sample rates.\n     */\n    var AUDIO_SAMPLE_RATE_TYPE;\n    (function (AUDIO_SAMPLE_RATE_TYPE) {\n        /**\n         * 32000: 32 kHz\n         */\n        AUDIO_SAMPLE_RATE_TYPE[AUDIO_SAMPLE_RATE_TYPE[\"AUDIO_SAMPLE_RATE_32000\"] = 32000] = \"AUDIO_SAMPLE_RATE_32000\";\n        /**\n         * 44100: 44.1 kHz\n         */\n        AUDIO_SAMPLE_RATE_TYPE[AUDIO_SAMPLE_RATE_TYPE[\"AUDIO_SAMPLE_RATE_44100\"] = 44100] = \"AUDIO_SAMPLE_RATE_44100\";\n        /**\n         * 48000: 48 kHz\n         */\n        AUDIO_SAMPLE_RATE_TYPE[AUDIO_SAMPLE_RATE_TYPE[\"AUDIO_SAMPLE_RATE_48000\"] = 48000] = \"AUDIO_SAMPLE_RATE_48000\";\n    })(AUDIO_SAMPLE_RATE_TYPE = AgoraRtcEngine.AUDIO_SAMPLE_RATE_TYPE || (AgoraRtcEngine.AUDIO_SAMPLE_RATE_TYPE = {}));\n    /**\n     * Video codec profile types.\n     */\n    var VIDEO_CODEC_PROFILE_TYPE;\n    (function (VIDEO_CODEC_PROFILE_TYPE) {\n        /**\n         * 66: Baseline video codec profile. Generally used in video calls on mobile phones.\n         */\n        VIDEO_CODEC_PROFILE_TYPE[VIDEO_CODEC_PROFILE_TYPE[\"VIDEO_CODEC_PROFILE_BASELINE\"] = 66] = \"VIDEO_CODEC_PROFILE_BASELINE\";\n        /**\n         * 77: Main video codec profile. Generally used in mainstream electronics such as MP4 players, portable video players,\n         * PSP, and iPads.\n         */\n        VIDEO_CODEC_PROFILE_TYPE[VIDEO_CODEC_PROFILE_TYPE[\"VIDEO_CODEC_PROFILE_MAIN\"] = 77] = \"VIDEO_CODEC_PROFILE_MAIN\";\n        /**\n         * 100: (Default) High video codec profile. Generally used in high-resolution live streaming or television.\n         */\n        VIDEO_CODEC_PROFILE_TYPE[VIDEO_CODEC_PROFILE_TYPE[\"VIDEO_CODEC_PROFILE_HIGH\"] = 100] = \"VIDEO_CODEC_PROFILE_HIGH\";\n    })(VIDEO_CODEC_PROFILE_TYPE = AgoraRtcEngine.VIDEO_CODEC_PROFILE_TYPE || (AgoraRtcEngine.VIDEO_CODEC_PROFILE_TYPE = {}));\n    /**\n     * Video codec types\n     */\n    var VIDEO_CODEC_TYPE;\n    (function (VIDEO_CODEC_TYPE) {\n        /**\n         * Standard VP8\n         */\n        VIDEO_CODEC_TYPE[VIDEO_CODEC_TYPE[\"VIDEO_CODEC_VP8\"] = 1] = \"VIDEO_CODEC_VP8\";\n        /**\n         * Standard H264\n         */\n        VIDEO_CODEC_TYPE[VIDEO_CODEC_TYPE[\"VIDEO_CODEC_H264\"] = 2] = \"VIDEO_CODEC_H264\";\n        /**\n         * Enhanced VP8\n         */\n        VIDEO_CODEC_TYPE[VIDEO_CODEC_TYPE[\"VIDEO_CODEC_EVP\"] = 3] = \"VIDEO_CODEC_EVP\";\n        /**\n         * Enhanced H264\n         */\n        VIDEO_CODEC_TYPE[VIDEO_CODEC_TYPE[\"VIDEO_CODEC_E264\"] = 4] = \"VIDEO_CODEC_E264\";\n    })(VIDEO_CODEC_TYPE = AgoraRtcEngine.VIDEO_CODEC_TYPE || (AgoraRtcEngine.VIDEO_CODEC_TYPE = {}));\n    /**\n     * Video Codec types for publishing streams.\n     */\n    var VIDEO_CODEC_TYPE_FOR_STREAM;\n    (function (VIDEO_CODEC_TYPE_FOR_STREAM) {\n        VIDEO_CODEC_TYPE_FOR_STREAM[VIDEO_CODEC_TYPE_FOR_STREAM[\"VIDEO_CODEC_H264_FOR_STREAM\"] = 1] = \"VIDEO_CODEC_H264_FOR_STREAM\";\n        VIDEO_CODEC_TYPE_FOR_STREAM[VIDEO_CODEC_TYPE_FOR_STREAM[\"VIDEO_CODEC_H265_FOR_STREAM\"] = 2] = \"VIDEO_CODEC_H265_FOR_STREAM\";\n    })(VIDEO_CODEC_TYPE_FOR_STREAM = AgoraRtcEngine.VIDEO_CODEC_TYPE_FOR_STREAM || (AgoraRtcEngine.VIDEO_CODEC_TYPE_FOR_STREAM = {}));\n    /**\n     * Audio equalization band frequencies.\n     */\n    var AUDIO_EQUALIZATION_BAND_FREQUENCY;\n    (function (AUDIO_EQUALIZATION_BAND_FREQUENCY) {\n        /**\n         * 0: 31 Hz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_31\"] = 0] = \"AUDIO_EQUALIZATION_BAND_31\";\n        /**\n         * 1: 62 Hz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_62\"] = 1] = \"AUDIO_EQUALIZATION_BAND_62\";\n        /**\n         * 2: 125 Hz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_125\"] = 2] = \"AUDIO_EQUALIZATION_BAND_125\";\n        /**\n         * 3: 250 Hz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_250\"] = 3] = \"AUDIO_EQUALIZATION_BAND_250\";\n        /**\n         * 4: 500 Hz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_500\"] = 4] = \"AUDIO_EQUALIZATION_BAND_500\";\n        /**\n         * 5: 1 kHz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_1K\"] = 5] = \"AUDIO_EQUALIZATION_BAND_1K\";\n        /**\n         * 6: 2 kHz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_2K\"] = 6] = \"AUDIO_EQUALIZATION_BAND_2K\";\n        /**\n         * 7: 4 kHz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_4K\"] = 7] = \"AUDIO_EQUALIZATION_BAND_4K\";\n        /**\n         * 8: 8 kHz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_8K\"] = 8] = \"AUDIO_EQUALIZATION_BAND_8K\";\n        /**\n         * 9: 16 kHz\n         */\n        AUDIO_EQUALIZATION_BAND_FREQUENCY[AUDIO_EQUALIZATION_BAND_FREQUENCY[\"AUDIO_EQUALIZATION_BAND_16K\"] = 9] = \"AUDIO_EQUALIZATION_BAND_16K\";\n    })(AUDIO_EQUALIZATION_BAND_FREQUENCY = AgoraRtcEngine.AUDIO_EQUALIZATION_BAND_FREQUENCY || (AgoraRtcEngine.AUDIO_EQUALIZATION_BAND_FREQUENCY = {}));\n    /**\n     * Audio reverberation types.\n     */\n    var AUDIO_REVERB_TYPE;\n    (function (AUDIO_REVERB_TYPE) {\n        /**\n         * 0: The level of the dry signal (db). The value is between -20 and 10.\n         */\n        AUDIO_REVERB_TYPE[AUDIO_REVERB_TYPE[\"AUDIO_REVERB_DRY_LEVEL\"] = 0] = \"AUDIO_REVERB_DRY_LEVEL\";\n        /**\n         * 1: The level of the early reflection signal (wet signal) (dB). The value is between -20 and 10.\n         */\n        AUDIO_REVERB_TYPE[AUDIO_REVERB_TYPE[\"AUDIO_REVERB_WET_LEVEL\"] = 1] = \"AUDIO_REVERB_WET_LEVEL\";\n        /**\n         * 2: The room size of the reflection. The value is between 0 and 100.\n         */\n        AUDIO_REVERB_TYPE[AUDIO_REVERB_TYPE[\"AUDIO_REVERB_ROOM_SIZE\"] = 2] = \"AUDIO_REVERB_ROOM_SIZE\";\n        /**\n         * 3: The length of the initial delay of the wet signal (ms). The value is between 0 and 200.\n         */\n        AUDIO_REVERB_TYPE[AUDIO_REVERB_TYPE[\"AUDIO_REVERB_WET_DELAY\"] = 3] = \"AUDIO_REVERB_WET_DELAY\";\n        /**\n         * 4: The reverberation strength. The value is between 0 and 100.\n         */\n        AUDIO_REVERB_TYPE[AUDIO_REVERB_TYPE[\"AUDIO_REVERB_STRENGTH\"] = 4] = \"AUDIO_REVERB_STRENGTH\";\n    })(AUDIO_REVERB_TYPE = AgoraRtcEngine.AUDIO_REVERB_TYPE || (AgoraRtcEngine.AUDIO_REVERB_TYPE = {}));\n    /**\n     * Local voice changer options.\n     */\n    var VOICE_CHANGER_PRESET;\n    (function (VOICE_CHANGER_PRESET) {\n        /**\n         * The original voice (no local voice change).\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_CHANGER_OFF\"] = 0] = \"VOICE_CHANGER_OFF\";\n        /**\n         * The voice of an old man.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_CHANGER_OLDMAN\"] = 1] = \"VOICE_CHANGER_OLDMAN\";\n        /**\n         * The voice of a little boy.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_CHANGER_BABYBOY\"] = 2] = \"VOICE_CHANGER_BABYBOY\";\n        /**\n         * The voice of a little girl.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_CHANGER_BABYGIRL\"] = 3] = \"VOICE_CHANGER_BABYGIRL\";\n        /**\n         * The voice of Zhu Bajie, a character in Journey to the West who has a voice like that of a growling bear.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_CHANGER_ZHUBAJIE\"] = 4] = \"VOICE_CHANGER_ZHUBAJIE\";\n        /**\n         * The ethereal voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_CHANGER_ETHEREAL\"] = 5] = \"VOICE_CHANGER_ETHEREAL\";\n        /**\n         * The voice of Hulk.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_CHANGER_HULK\"] = 6] = \"VOICE_CHANGER_HULK\";\n        /**\n         * A more vigorous voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_VIGOROUS\"] = 1048577] = \"VOICE_BEAUTY_VIGOROUS\";\n        /**\n         * A deeper voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_DEEP\"] = 1048578] = \"VOICE_BEAUTY_DEEP\";\n        /**\n         * A mellower voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_MELLOW\"] = 1048579] = \"VOICE_BEAUTY_MELLOW\";\n        /**\n         * Falsetto.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_FALSETTO\"] = 1048580] = \"VOICE_BEAUTY_FALSETTO\";\n        /**\n         * A fuller voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_FULL\"] = 1048581] = \"VOICE_BEAUTY_FULL\";\n        /**\n         * A clearer voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_CLEAR\"] = 1048582] = \"VOICE_BEAUTY_CLEAR\";\n        /**\n         * A more resounding voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_RESOUNDING\"] = 1048583] = \"VOICE_BEAUTY_RESOUNDING\";\n        /**\n         * A more ringing voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_RINGING\"] = 1048584] = \"VOICE_BEAUTY_RINGING\";\n        /**\n         * A more spatially resonant voice.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"VOICE_BEAUTY_SPACIAL\"] = 1048585] = \"VOICE_BEAUTY_SPACIAL\";\n        /**\n         * (For male only) A more magnetic voice. Do not use it when the speaker is a female; otherwise, voice distortion occurs.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"GENERAL_BEAUTY_VOICE_MALE_MAGNETIC\"] = 2097153] = \"GENERAL_BEAUTY_VOICE_MALE_MAGNETIC\";\n        /**\n         * (For female only) A fresher voice. Do not use it when the speaker is a male; otherwise, voice distortion occurs.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"GENERAL_BEAUTY_VOICE_FEMALE_FRESH\"] = 2097154] = \"GENERAL_BEAUTY_VOICE_FEMALE_FRESH\";\n        /**\n         * (For female only) A more vital voice. Do not use it when the speaker is a male; otherwise, voice distortion occurs.\n         */\n        VOICE_CHANGER_PRESET[VOICE_CHANGER_PRESET[\"GENERAL_BEAUTY_VOICE_FEMALE_VITALITY\"] = 2097155] = \"GENERAL_BEAUTY_VOICE_FEMALE_VITALITY\";\n    })(VOICE_CHANGER_PRESET = AgoraRtcEngine.VOICE_CHANGER_PRESET || (AgoraRtcEngine.VOICE_CHANGER_PRESET = {}));\n    /**\n     * Local voice reverberation presets.\n     */\n    var AUDIO_REVERB_PRESET;\n    (function (AUDIO_REVERB_PRESET) {\n        /**\n         * Turn off local voice reverberation, that is, to use the original voice.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_OFF\"] = 0] = \"AUDIO_REVERB_OFF\";\n        /**\n         * The reverberation style typical of a KTV venue (enhanced).\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_FX_KTV\"] = 1048577] = \"AUDIO_REVERB_FX_KTV\";\n        /**\n         * The reverberation style typical of a concert hall (enhanced).\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_FX_VOCAL_CONCERT\"] = 1048578] = \"AUDIO_REVERB_FX_VOCAL_CONCERT\";\n        /**\n         * The reverberation style typical of an uncle's voice.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_FX_UNCLE\"] = 1048579] = \"AUDIO_REVERB_FX_UNCLE\";\n        /**\n         * The reverberation style typical of a little sister's voice.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_FX_SISTER\"] = 1048580] = \"AUDIO_REVERB_FX_SISTER\";\n        /**\n         * The reverberation style typical of a recording studio (enhanced).\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_FX_STUDIO\"] = 1048581] = \"AUDIO_REVERB_FX_STUDIO\";\n        /**\n         * The reverberation style typical of popular music (enhanced).\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_FX_POPULAR\"] = 1048582] = \"AUDIO_REVERB_FX_POPULAR\";\n        /**\n         * The reverberation style typical of R&B music (enhanced).\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_FX_RNB\"] = 1048583] = \"AUDIO_REVERB_FX_RNB\";\n        /**\n         * The reverberation style typical of the vintage phonograph.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_FX_PHONOGRAPH\"] = 1048584] = \"AUDIO_REVERB_FX_PHONOGRAPH\";\n        /**\n         * The reverberation style typical of popular music.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_POPULAR\"] = 1] = \"AUDIO_REVERB_POPULAR\";\n        /**\n         * The reverberation style typical of R&B music.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_RNB\"] = 2] = \"AUDIO_REVERB_RNB\";\n        /**\n         * The reverberation style typical of rock music.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_ROCK\"] = 3] = \"AUDIO_REVERB_ROCK\";\n        /**\n         * The reverberation style typical of hip-hop music.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_HIPHOP\"] = 4] = \"AUDIO_REVERB_HIPHOP\";\n        /**\n         * The reverberation style typical of a concert hall.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_VOCAL_CONCERT\"] = 5] = \"AUDIO_REVERB_VOCAL_CONCERT\";\n        /**\n         * The reverberation style typical of a KTV venue.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_KTV\"] = 6] = \"AUDIO_REVERB_KTV\";\n        /**\n         * The reverberation style typical of a recording studio.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_REVERB_STUDIO\"] = 7] = \"AUDIO_REVERB_STUDIO\";\n        /**\n         * The reverberation of the virtual stereo. The virtual stereo is an effect that renders the monophonic\n         * audio as the stereo audio, so that all users in the channel can hear the stereo voice effect.\n         * To achieve better virtual stereo reverberation, Agora recommends setting `profile` in\n         * [setAudioProfile]{@link AgoraRtcEngine.setAudioProfile} as `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`.\n         */\n        AUDIO_REVERB_PRESET[AUDIO_REVERB_PRESET[\"AUDIO_VIRTUAL_STEREO\"] = 2097153] = \"AUDIO_VIRTUAL_STEREO\";\n    })(AUDIO_REVERB_PRESET = AgoraRtcEngine.AUDIO_REVERB_PRESET || (AgoraRtcEngine.AUDIO_REVERB_PRESET = {}));\n    /**\n     * The options for SDK preset voice beautifier effects.\n     */\n    var VOICE_BEAUTIFIER_PRESET;\n    (function (VOICE_BEAUTIFIER_PRESET) {\n        /**\n         * Turn off voice beautifier effects and use the original voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"VOICE_BEAUTIFIER_OFF\"] = 0] = \"VOICE_BEAUTIFIER_OFF\";\n        /**\n         * A more magnetic voice.\n         *\n         * @note Agora recommends using this enumerator to process a male-sounding voice; otherwise, you may experience vocal distortion.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"CHAT_BEAUTIFIER_MAGNETIC\"] = 16843008] = \"CHAT_BEAUTIFIER_MAGNETIC\";\n        /**\n         * A fresher voice.\n         *\n         * @note Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may experience vocal distortion.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"CHAT_BEAUTIFIER_FRESH\"] = 16843264] = \"CHAT_BEAUTIFIER_FRESH\";\n        /**\n         * A more vital voice.\n         *\n         * @note Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may experience vocal distortion.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"CHAT_BEAUTIFIER_VITALITY\"] = 16843520] = \"CHAT_BEAUTIFIER_VITALITY\";\n        /**\n         * A more vigorous voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"TIMBRE_TRANSFORMATION_VIGOROUS\"] = 16974080] = \"TIMBRE_TRANSFORMATION_VIGOROUS\";\n        /**\n         * A deeper voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"TIMBRE_TRANSFORMATION_DEEP\"] = 16974336] = \"TIMBRE_TRANSFORMATION_DEEP\";\n        /**\n         * A mellower voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"TIMBRE_TRANSFORMATION_MELLOW\"] = 16974592] = \"TIMBRE_TRANSFORMATION_MELLOW\";\n        /**\n         * A falsetto voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"TIMBRE_TRANSFORMATION_FALSETTO\"] = 16974848] = \"TIMBRE_TRANSFORMATION_FALSETTO\";\n        /**\n         * A falsetto voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"TIMBRE_TRANSFORMATION_FULL\"] = 16975104] = \"TIMBRE_TRANSFORMATION_FULL\";\n        /**\n         * A clearer voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"TIMBRE_TRANSFORMATION_CLEAR\"] = 16975360] = \"TIMBRE_TRANSFORMATION_CLEAR\";\n        /**\n         * A more resounding voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"TIMBRE_TRANSFORMATION_RESOUNDING\"] = 16975616] = \"TIMBRE_TRANSFORMATION_RESOUNDING\";\n        /**\n         * A more ringing voice.\n         */\n        VOICE_BEAUTIFIER_PRESET[VOICE_BEAUTIFIER_PRESET[\"TIMBRE_TRANSFORMATION_RINGING\"] = 16975872] = \"TIMBRE_TRANSFORMATION_RINGING\";\n    })(VOICE_BEAUTIFIER_PRESET = AgoraRtcEngine.VOICE_BEAUTIFIER_PRESET || (AgoraRtcEngine.VOICE_BEAUTIFIER_PRESET = {}));\n    /**\n     * The options for SDK preset audio effects.\n     */\n    var AUDIO_EFFECT_PRESET;\n    (function (AUDIO_EFFECT_PRESET) {\n        /**\n         * Turn off audio effects and use the original voice.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"AUDIO_EFFECT_OFF\"] = 0] = \"AUDIO_EFFECT_OFF\";\n        /**\n         * An audio effect typical of a KTV venue.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\"\n         * and setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`\n         * before setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"ROOM_ACOUSTICS_KTV\"] = 33620224] = \"ROOM_ACOUSTICS_KTV\";\n        /**\n         * An audio effect typical of a concert hall.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\"\n         * and setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`\n         * before setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"ROOM_ACOUSTICS_VOCAL_CONCERT\"] = 33620480] = \"ROOM_ACOUSTICS_VOCAL_CONCERT\";\n        /**\n         * An audio effect typical of a recording studio.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\"\n         * and setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`\n         * before setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"ROOM_ACOUSTICS_STUDIO\"] = 33620736] = \"ROOM_ACOUSTICS_STUDIO\";\n        /**\n         * An audio effect typical of a vintage phonograph.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\"\n         * and setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`\n         * before setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"ROOM_ACOUSTICS_PHONOGRAPH\"] = 33620992] = \"ROOM_ACOUSTICS_PHONOGRAPH\";\n        /**\n         * A virtual stereo effect that renders monophonic audio as stereo audio.\n         *\n         * @note Call \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and set the `profile` parameter to\n         * `AUDIO_PROFILE_MUSIC_STANDARD_STEREO(3)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before setting this\n         * enumerator; otherwise, the enumerator setting does not take effect.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"ROOM_ACOUSTICS_VIRTUAL_STEREO\"] = 33621248] = \"ROOM_ACOUSTICS_VIRTUAL_STEREO\";\n        /**\n         * A more spatial audio effect.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\"\n         * and setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`\n         * before setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"ROOM_ACOUSTICS_SPACIAL\"] = 33621504] = \"ROOM_ACOUSTICS_SPACIAL\";\n        /**\n         * A more ethereal audio effect.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\"\n         * and setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`\n         * before setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"ROOM_ACOUSTICS_ETHEREAL\"] = 33621760] = \"ROOM_ACOUSTICS_ETHEREAL\";\n        /**\n         * A 3D voice effect that makes the voice appear to be moving around the user. The default cycle period of the 3D\n         * voice effect is 10 seconds. To change the cycle period, call \\ref IRtcEngine::setAudioEffectParameters \"setAudioEffectParameters\"\n         * after this method.\n         *\n         * @note\n         * - Call \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and set the `profile` parameter to `AUDIO_PROFILE_MUSIC_STANDARD_STEREO(3)`\n         * or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before setting this enumerator; otherwise, the enumerator setting does not take effect.\n         * - If the 3D voice effect is enabled, users need to use stereo audio playback devices to hear the anticipated voice effect.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"ROOM_ACOUSTICS_3D_VOICE\"] = 33622016] = \"ROOM_ACOUSTICS_3D_VOICE\";\n        /**\n         * The voice of an uncle.\n         *\n         * @note\n         * - Agora recommends using this enumerator to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n         * - To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and\n         * setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"VOICE_CHANGER_EFFECT_UNCLE\"] = 33685760] = \"VOICE_CHANGER_EFFECT_UNCLE\";\n        /**\n         * The voice of an old man.\n         *\n         * @note\n         * - Agora recommends using this enumerator to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n         * - To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and setting\n         * the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before setting\n         * this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"VOICE_CHANGER_EFFECT_OLDMAN\"] = 33686016] = \"VOICE_CHANGER_EFFECT_OLDMAN\";\n        /**\n         * The voice of a boy.\n         *\n         * @note\n         * - Agora recommends using this enumerator to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n         * - To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and setting\n         * the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"VOICE_CHANGER_EFFECT_BOY\"] = 33686272] = \"VOICE_CHANGER_EFFECT_BOY\";\n        /**\n         * The voice of a young woman.\n         *\n         * @note\n         * - Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may not hear the anticipated voice effect.\n         * - To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and setting\n         * the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"VOICE_CHANGER_EFFECT_SISTER\"] = 33686528] = \"VOICE_CHANGER_EFFECT_SISTER\";\n        /**\n         * The voice of a girl.\n         *\n         * @note\n         * - Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may not hear the anticipated voice effect.\n         * - To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and setting\n         * the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"VOICE_CHANGER_EFFECT_GIRL\"] = 33686784] = \"VOICE_CHANGER_EFFECT_GIRL\";\n        /**\n         * The voice of Pig King, a character in Journey to the West who has a voice like a growling bear.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and\n         * setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"VOICE_CHANGER_EFFECT_PIGKING\"] = 33687040] = \"VOICE_CHANGER_EFFECT_PIGKING\";\n        /**\n         * The voice of Hulk.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and\n         * setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"VOICE_CHANGER_EFFECT_HULK\"] = 33687296] = \"VOICE_CHANGER_EFFECT_HULK\";\n        /**\n         * An audio effect typical of R&B music.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and\n         * setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"STYLE_TRANSFORMATION_RNB\"] = 33751296] = \"STYLE_TRANSFORMATION_RNB\";\n        /**\n         * An audio effect typical of popular music.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and\n         * setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"STYLE_TRANSFORMATION_POPULAR\"] = 33751552] = \"STYLE_TRANSFORMATION_POPULAR\";\n        /**\n         * A pitch correction effect that corrects the user's pitch based on the pitch of the natural C major scale.\n         * To change the basic mode and tonic pitch, call \\ref IRtcEngine::setAudioEffectParameters \"setAudioEffectParameters\" after this method.\n         *\n         * @note To achieve better audio effect quality, Agora recommends calling \\ref IRtcEngine::setAudioProfile \"setAudioProfile\" and\n         * setting the `profile` parameter to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` before\n         * setting this enumerator.\n         */\n        AUDIO_EFFECT_PRESET[AUDIO_EFFECT_PRESET[\"PITCH_CORRECTION\"] = 33816832] = \"PITCH_CORRECTION\";\n    })(AUDIO_EFFECT_PRESET = AgoraRtcEngine.AUDIO_EFFECT_PRESET || (AgoraRtcEngine.AUDIO_EFFECT_PRESET = {}));\n    /**\n     * Audio codec profile types. The default value is LC_ACC.\n     */\n    var AUDIO_CODEC_PROFILE_TYPE;\n    (function (AUDIO_CODEC_PROFILE_TYPE) {\n        /**\n         * 0: LC-AAC, which is the low-complexity audio codec type.\n         */\n        AUDIO_CODEC_PROFILE_TYPE[AUDIO_CODEC_PROFILE_TYPE[\"AUDIO_CODEC_PROFILE_LC_AAC\"] = 0] = \"AUDIO_CODEC_PROFILE_LC_AAC\";\n        /**\n         * 1: HE-AAC, which is the high-efficiency audio codec type.\n         */\n        AUDIO_CODEC_PROFILE_TYPE[AUDIO_CODEC_PROFILE_TYPE[\"AUDIO_CODEC_PROFILE_HE_AAC\"] = 1] = \"AUDIO_CODEC_PROFILE_HE_AAC\";\n    })(AUDIO_CODEC_PROFILE_TYPE = AgoraRtcEngine.AUDIO_CODEC_PROFILE_TYPE || (AgoraRtcEngine.AUDIO_CODEC_PROFILE_TYPE = {}));\n    /**\n     * Remote audio states.\n     */\n    var REMOTE_AUDIO_STATE;\n    (function (REMOTE_AUDIO_STATE) {\n        /**\n         * 0: The remote audio is in the default state, probably due to\n         * [REMOTE_AUDIO_REASON_LOCAL_MUTED]{@link AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON.REMOTE_AUDIO_REASON_LOCAL_MUTED}(3),\n         * [REMOTE_AUDIO_REASON_REMOTE_MUTED]{@link AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON.REMOTE_AUDIO_REASON_REMOTE_MUTED} (5), or\n         * [REMOTE_AUDIO_REASON_REMOTE_OFFLINE]{@link AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON.REMOTE_AUDIO_REASON_REMOTE_OFFLINE} (7).\n         */\n        REMOTE_AUDIO_STATE[REMOTE_AUDIO_STATE[\"REMOTE_AUDIO_STATE_STOPPED\"] = 0] = \"REMOTE_AUDIO_STATE_STOPPED\";\n        /**\n         * 1: The first remote audio packet is received.\n         */\n        REMOTE_AUDIO_STATE[REMOTE_AUDIO_STATE[\"REMOTE_AUDIO_STATE_STARTING\"] = 1] = \"REMOTE_AUDIO_STATE_STARTING\";\n        /**\n         * 2: The remote audio stream is decoded and plays normally, probably\n         * due to [REMOTE_AUDIO_REASON_NETWORK_RECOVERY]{@link AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON.REMOTE_AUDIO_REASON_NETWORK_RECOVERY}(2),\n         * [REMOTE_AUDIO_REASON_LOCAL_UNMUTED]{@link AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON.REMOTE_AUDIO_REASON_LOCAL_UNMUTED}(4), or\n         * [REMOTE_AUDIO_REASON_REMOTE_UNMUTED]{@link AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON.REMOTE_AUDIO_REASON_REMOTE_UNMUTED}(6).\n         */\n        REMOTE_AUDIO_STATE[REMOTE_AUDIO_STATE[\"REMOTE_AUDIO_STATE_DECODING\"] = 2] = \"REMOTE_AUDIO_STATE_DECODING\";\n        /**\n         * 3: The remote audio is frozen, probably due to\n         * [REMOTE_AUDIO_REASON_NETWORK_CONGESTION]{@link AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON.REMOTE_AUDIO_REASON_NETWORK_CONGESTION}(1).\n         */\n        REMOTE_AUDIO_STATE[REMOTE_AUDIO_STATE[\"REMOTE_AUDIO_STATE_FROZEN\"] = 3] = \"REMOTE_AUDIO_STATE_FROZEN\";\n        /**\n         * 4: The remote audio fails to start, probably due to\n         * [REMOTE_AUDIO_REASON_INTERNAL]{@link AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON.REMOTE_AUDIO_REASON_INTERNAL}(0).\n         */\n        REMOTE_AUDIO_STATE[REMOTE_AUDIO_STATE[\"REMOTE_AUDIO_STATE_FAILED\"] = 4] = \"REMOTE_AUDIO_STATE_FAILED\";\n    })(REMOTE_AUDIO_STATE = AgoraRtcEngine.REMOTE_AUDIO_STATE || (AgoraRtcEngine.REMOTE_AUDIO_STATE = {}));\n    /**\n     * Remote audio state reasons.\n     */\n    var REMOTE_AUDIO_STATE_REASON;\n    (function (REMOTE_AUDIO_STATE_REASON) {\n        /**\n         * 0: Internal reasons.\n         */\n        REMOTE_AUDIO_STATE_REASON[REMOTE_AUDIO_STATE_REASON[\"REMOTE_AUDIO_REASON_INTERNAL\"] = 0] = \"REMOTE_AUDIO_REASON_INTERNAL\";\n        /**\n         * 1: Network congestion.\n         */\n        REMOTE_AUDIO_STATE_REASON[REMOTE_AUDIO_STATE_REASON[\"REMOTE_AUDIO_REASON_NETWORK_CONGESTION\"] = 1] = \"REMOTE_AUDIO_REASON_NETWORK_CONGESTION\";\n        /**\n         * 2: Network recovery.\n         */\n        REMOTE_AUDIO_STATE_REASON[REMOTE_AUDIO_STATE_REASON[\"REMOTE_AUDIO_REASON_NETWORK_RECOVERY\"] = 2] = \"REMOTE_AUDIO_REASON_NETWORK_RECOVERY\";\n        /**\n         * 3: The local user stops receiving the remote audio stream or\n         * disables the audio module.\n         */\n        REMOTE_AUDIO_STATE_REASON[REMOTE_AUDIO_STATE_REASON[\"REMOTE_AUDIO_REASON_LOCAL_MUTED\"] = 3] = \"REMOTE_AUDIO_REASON_LOCAL_MUTED\";\n        /**\n         * 4: The local user resumes receiving the remote audio stream or\n         * enables the audio module.\n         */\n        REMOTE_AUDIO_STATE_REASON[REMOTE_AUDIO_STATE_REASON[\"REMOTE_AUDIO_REASON_LOCAL_UNMUTED\"] = 4] = \"REMOTE_AUDIO_REASON_LOCAL_UNMUTED\";\n        /**\n         * 5: The remote user stops sending the audio stream or disables the\n         * audio module.\n         */\n        REMOTE_AUDIO_STATE_REASON[REMOTE_AUDIO_STATE_REASON[\"REMOTE_AUDIO_REASON_REMOTE_MUTED\"] = 5] = \"REMOTE_AUDIO_REASON_REMOTE_MUTED\";\n        /**\n         * 6: The remote user resumes sending the audio stream or enables the\n         * audio module.\n         */\n        REMOTE_AUDIO_STATE_REASON[REMOTE_AUDIO_STATE_REASON[\"REMOTE_AUDIO_REASON_REMOTE_UNMUTED\"] = 6] = \"REMOTE_AUDIO_REASON_REMOTE_UNMUTED\";\n        /**\n         * 7: The remote user leaves the channel.\n         */\n        REMOTE_AUDIO_STATE_REASON[REMOTE_AUDIO_STATE_REASON[\"REMOTE_AUDIO_REASON_REMOTE_OFFLINE\"] = 7] = \"REMOTE_AUDIO_REASON_REMOTE_OFFLINE\";\n    })(REMOTE_AUDIO_STATE_REASON = AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON || (AgoraRtcEngine.REMOTE_AUDIO_STATE_REASON = {}));\n    /**\n     * The state of the remote video.\n     */\n    var REMOTE_VIDEO_STATE;\n    (function (REMOTE_VIDEO_STATE) {\n        /**\n         * 0: The remote video is in the default state, probably due to\n         * [REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED}(3),\n         * [REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED}(5),\n         * or [REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE}(7).\n         */\n        REMOTE_VIDEO_STATE[REMOTE_VIDEO_STATE[\"REMOTE_VIDEO_STATE_STOPPED\"] = 0] = \"REMOTE_VIDEO_STATE_STOPPED\";\n        /**\n         * 1: The first remote video packet is received.\n         */\n        REMOTE_VIDEO_STATE[REMOTE_VIDEO_STATE[\"REMOTE_VIDEO_STATE_STARTING\"] = 1] = \"REMOTE_VIDEO_STATE_STARTING\";\n        /**\n         * 2: The remote video stream is decoded and plays normally, probably due to\n         * [REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY}(2),\n         * [REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED}(4),\n         * [REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED}(6),\n         * or [REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY} (9).\n         */\n        REMOTE_VIDEO_STATE[REMOTE_VIDEO_STATE[\"REMOTE_VIDEO_STATE_DECODING\"] = 2] = \"REMOTE_VIDEO_STATE_DECODING\";\n        /**\n         * 3: The remote video is frozen, probably due to\n         * [REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION}(1)\n         * or [REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK}(8).\n         */\n        REMOTE_VIDEO_STATE[REMOTE_VIDEO_STATE[\"REMOTE_VIDEO_STATE_FROZEN\"] = 3] = \"REMOTE_VIDEO_STATE_FROZEN\";\n        /**\n         * 4: The remote video fails to start, probably due to\n         * [REMOTE_VIDEO_STATE_REASON_INTERNAL]{@link AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON.REMOTE_VIDEO_STATE_REASON_INTERNAL}(0).\n         */\n        REMOTE_VIDEO_STATE[REMOTE_VIDEO_STATE[\"REMOTE_VIDEO_STATE_FAILED\"] = 4] = \"REMOTE_VIDEO_STATE_FAILED\";\n    })(REMOTE_VIDEO_STATE = AgoraRtcEngine.REMOTE_VIDEO_STATE || (AgoraRtcEngine.REMOTE_VIDEO_STATE = {}));\n    /**\n     * The publishing state.\n     */\n    var STREAM_PUBLISH_STATE;\n    (function (STREAM_PUBLISH_STATE) {\n        /**\n         * 0: The initial publishing state after joining the channel.\n         */\n        STREAM_PUBLISH_STATE[STREAM_PUBLISH_STATE[\"PUB_STATE_IDLE\"] = 0] = \"PUB_STATE_IDLE\";\n        /**\n         * 1: Fails to publish the local stream. Possible reasons:\n         * - The local user calls [muteLocalAudioStream(true)]{@link AgoraRtcEngine.muteLocalAudioStream} or\n         * [muteLocalVideoStream(true)]{@link AgoraRtcEngine.muteLocalVideoStream} to stop sending local streams.\n         * - The local user calls [disableAudio]{@link AgoraRtcEngine.disableAudio} or [disableVideo]{@link AgoraRtcEngine.disableVideo} to\n         * disable the entire audio or video module.\n         * - The local user calls [enableLocalAudio(false)]{@link AgoraRtcEngine.enableLocalAudio} or\n         * [enableLocalVideo(false)]{@link AgoraRtcEngine.enableLocalVideo} to disable the local audio sampling or video capturing.\n         * - The role of the local user is `AUDIENCE`.\n         */\n        STREAM_PUBLISH_STATE[STREAM_PUBLISH_STATE[\"PUB_STATE_NO_PUBLISHED\"] = 1] = \"PUB_STATE_NO_PUBLISHED\";\n        /**\n         * 2: Publishing.\n         */\n        STREAM_PUBLISH_STATE[STREAM_PUBLISH_STATE[\"PUB_STATE_PUBLISHING\"] = 2] = \"PUB_STATE_PUBLISHING\";\n        /**\n         * 3: Publishes successfully.\n         */\n        STREAM_PUBLISH_STATE[STREAM_PUBLISH_STATE[\"PUB_STATE_PUBLISHED\"] = 3] = \"PUB_STATE_PUBLISHED\";\n    })(STREAM_PUBLISH_STATE = AgoraRtcEngine.STREAM_PUBLISH_STATE || (AgoraRtcEngine.STREAM_PUBLISH_STATE = {}));\n    /**\n     * The subscribing state.\n     */\n    var STREAM_SUBSCRIBE_STATE;\n    (function (STREAM_SUBSCRIBE_STATE) {\n        /**\n         * 0: The initial subscribing state after joining the channel.\n         */\n        STREAM_SUBSCRIBE_STATE[STREAM_SUBSCRIBE_STATE[\"SUB_STATE_IDLE\"] = 0] = \"SUB_STATE_IDLE\";\n        /**\n         * 1: Fails to subscribe to the remote stream. Possible reasons:\n         * - The remote user:\n         *   - Calls [muteLocalAudioStream(true)]{@link AgoraRtcEngine.muteLocalAudioStream} to stop sending local streams.\n         *   - Calls [disableAudio]{@link AgoraRtcEngine.disableAudio} to disable the\n         * entire audio modules.\n         *   - Calls [enableLocalAudio(false)]{@link AgoraRtcEngine.enableLocalAudio}\n         * to disable the local audio sampling.\n         *   - The role of the remote user is `AUDIENCE`.\n         * - The local user calls the following methods to stop receiving remote streams:\n         * Calls [muteRemoteAudioStream(true)]{@link AgoraRtcEngine.muteRemoteAudioStream},\n         * [muteAllRemoteAudioStreams(true)]{@link AgoraRtcEngine.muteAllRemoteAudioStreams} , or\n         * [setDefaultMuteAllRemoteAudioStreams(true)]{@link AgoraRtcEngine.setDefaultMuteAllRemoteAudioStreams} to stop receiving remote\n         * audio streams.\n         */\n        STREAM_SUBSCRIBE_STATE[STREAM_SUBSCRIBE_STATE[\"SUB_STATE_NO_SUBSCRIBED\"] = 1] = \"SUB_STATE_NO_SUBSCRIBED\";\n        /**\n         * 2: Subscribing.\n         */\n        STREAM_SUBSCRIBE_STATE[STREAM_SUBSCRIBE_STATE[\"SUB_STATE_SUBSCRIBING\"] = 2] = \"SUB_STATE_SUBSCRIBING\";\n        /**\n         * 3: Subscribes to and receives the remote stream successfully.\n         */\n        STREAM_SUBSCRIBE_STATE[STREAM_SUBSCRIBE_STATE[\"SUB_STATE_SUBSCRIBED\"] = 3] = \"SUB_STATE_SUBSCRIBED\";\n    })(STREAM_SUBSCRIBE_STATE = AgoraRtcEngine.STREAM_SUBSCRIBE_STATE || (AgoraRtcEngine.STREAM_SUBSCRIBE_STATE = {}));\n    /**\n     * The remote video frozen type.\n     */\n    var XLA_REMOTE_VIDEO_FROZEN_TYPE;\n    (function (XLA_REMOTE_VIDEO_FROZEN_TYPE) {\n        /**\n         * 0: 500ms video frozen type.\n         */\n        XLA_REMOTE_VIDEO_FROZEN_TYPE[XLA_REMOTE_VIDEO_FROZEN_TYPE[\"XLA_REMOTE_VIDEO_FROZEN_500MS\"] = 0] = \"XLA_REMOTE_VIDEO_FROZEN_500MS\";\n        /**\n         * 1: 200ms video frozen type.\n         */\n        XLA_REMOTE_VIDEO_FROZEN_TYPE[XLA_REMOTE_VIDEO_FROZEN_TYPE[\"XLA_REMOTE_VIDEO_FROZEN_200MS\"] = 1] = \"XLA_REMOTE_VIDEO_FROZEN_200MS\";\n        /**\n         * 2: 600ms video frozen type.\n         */\n        XLA_REMOTE_VIDEO_FROZEN_TYPE[XLA_REMOTE_VIDEO_FROZEN_TYPE[\"XLA_REMOTE_VIDEO_FROZEN_600MS\"] = 2] = \"XLA_REMOTE_VIDEO_FROZEN_600MS\";\n        /**\n         * 3: max video frozen type.\n         */\n        XLA_REMOTE_VIDEO_FROZEN_TYPE[XLA_REMOTE_VIDEO_FROZEN_TYPE[\"XLA_REMOTE_VIDEO_FROZEN_TYPE_MAX\"] = 3] = \"XLA_REMOTE_VIDEO_FROZEN_TYPE_MAX\";\n    })(XLA_REMOTE_VIDEO_FROZEN_TYPE = AgoraRtcEngine.XLA_REMOTE_VIDEO_FROZEN_TYPE || (AgoraRtcEngine.XLA_REMOTE_VIDEO_FROZEN_TYPE = {}));\n    /**\n     * The remote audio frozen type.\n     */\n    var XLA_REMOTE_AUDIO_FROZEN_TYPE;\n    (function (XLA_REMOTE_AUDIO_FROZEN_TYPE) {\n        /**\n         * 0: 80ms audio frozen.\n         */\n        XLA_REMOTE_AUDIO_FROZEN_TYPE[XLA_REMOTE_AUDIO_FROZEN_TYPE[\"XLA_REMOTE_AUDIO_FROZEN_80MS\"] = 0] = \"XLA_REMOTE_AUDIO_FROZEN_80MS\";\n        /**\n         * 1: 200ms audio frozen.\n         */\n        XLA_REMOTE_AUDIO_FROZEN_TYPE[XLA_REMOTE_AUDIO_FROZEN_TYPE[\"XLA_REMOTE_AUDIO_FROZEN_200MS\"] = 1] = \"XLA_REMOTE_AUDIO_FROZEN_200MS\";\n        /**\n         * 2: max audio frozen type.\n         */\n        XLA_REMOTE_AUDIO_FROZEN_TYPE[XLA_REMOTE_AUDIO_FROZEN_TYPE[\"XLA_REMOTE_AUDIO_FROZEN_TYPE_MAX\"] = 2] = \"XLA_REMOTE_AUDIO_FROZEN_TYPE_MAX\";\n    })(XLA_REMOTE_AUDIO_FROZEN_TYPE = AgoraRtcEngine.XLA_REMOTE_AUDIO_FROZEN_TYPE || (AgoraRtcEngine.XLA_REMOTE_AUDIO_FROZEN_TYPE = {}));\n    /**\n     * The reason for the remote video state change.\n     */\n    var REMOTE_VIDEO_STATE_REASON;\n    (function (REMOTE_VIDEO_STATE_REASON) {\n        /**\n         * 0: Internal reasons.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_INTERNAL\"] = 0] = \"REMOTE_VIDEO_STATE_REASON_INTERNAL\";\n        /**\n         * 1: Network congestion.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION\"] = 1] = \"REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION\";\n        /**\n         * 2: Network recovery.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY\"] = 2] = \"REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY\";\n        /**\n         * 3: The local user stops receiving the remote video stream or disables the video module.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED\"] = 3] = \"REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED\";\n        /**\n         * 4: The local user resumes receiving the remote video stream or enables the video module.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED\"] = 4] = \"REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED\";\n        /**\n         * 5: The remote user stops sending the video stream or disables the video module.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED\"] = 5] = \"REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED\";\n        /**\n         * 6: The remote user resumes sending the video stream or enables the video module.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED\"] = 6] = \"REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED\";\n        /**\n         * 7: The remote user leaves the channel.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE\"] = 7] = \"REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE\";\n        /**\n         * 8: The remote audio-and-video stream falls back to the audio-only stream due to poor network conditions.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK\"] = 8] = \"REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK\";\n        /**\n         * 9: The remote audio-only stream switches back to the audio-and-video stream after the network conditions improve.\n         */\n        REMOTE_VIDEO_STATE_REASON[REMOTE_VIDEO_STATE_REASON[\"REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY\"] = 9] = \"REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY\";\n    })(REMOTE_VIDEO_STATE_REASON = AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON || (AgoraRtcEngine.REMOTE_VIDEO_STATE_REASON = {}));\n    /**\n     * Video frame rates.\n     */\n    var FRAME_RATE;\n    (function (FRAME_RATE) {\n        /**\n         * 1: 1 fps\n         */\n        FRAME_RATE[FRAME_RATE[\"FRAME_RATE_FPS_1\"] = 1] = \"FRAME_RATE_FPS_1\";\n        /**\n         * 7: 7 fps\n         */\n        FRAME_RATE[FRAME_RATE[\"FRAME_RATE_FPS_7\"] = 7] = \"FRAME_RATE_FPS_7\";\n        /**\n         * 10: 10 fps\n         */\n        FRAME_RATE[FRAME_RATE[\"FRAME_RATE_FPS_10\"] = 10] = \"FRAME_RATE_FPS_10\";\n        /**\n         * 15: 15 fps\n         */\n        FRAME_RATE[FRAME_RATE[\"FRAME_RATE_FPS_15\"] = 15] = \"FRAME_RATE_FPS_15\";\n        /**\n         * 24: 24 fps\n         */\n        FRAME_RATE[FRAME_RATE[\"FRAME_RATE_FPS_24\"] = 24] = \"FRAME_RATE_FPS_24\";\n        /**\n         * 30: 30 fps\n         */\n        FRAME_RATE[FRAME_RATE[\"FRAME_RATE_FPS_30\"] = 30] = \"FRAME_RATE_FPS_30\";\n        /** @ignore */\n        FRAME_RATE[FRAME_RATE[\"FRAME_RATE_FPS_60\"] = 60] = \"FRAME_RATE_FPS_60\";\n    })(FRAME_RATE = AgoraRtcEngine.FRAME_RATE || (AgoraRtcEngine.FRAME_RATE = {}));\n    /**\n     * Video output orientation modes.\n     */\n    var ORIENTATION_MODE;\n    (function (ORIENTATION_MODE) {\n        /**\n         * 0: (Default) Adaptive mode.\n         *\n         * The video encoder adapts to the orientation mode of the video input device.\n         *\n         * - If the width of the captured video from the SDK is greater than the height, the encoder sends the video in landscape mode.\n         * The encoder also sends the rotational information of the video, and the receiver uses the rotational information to rotate\n         * the received video.\n         * - When you use a custom video source, the output video from the encoder inherits the orientation of the original video. If\n         * the original video is in portrait mode, the output video from the encoder is also in portrait mode. The encoder also sends\n         * the rotational information of the video to the receiver.\n         */\n        ORIENTATION_MODE[ORIENTATION_MODE[\"ORIENTATION_MODE_ADAPTIVE\"] = 0] = \"ORIENTATION_MODE_ADAPTIVE\";\n        /**\n         * 1: Landscape mode.\n         *\n         * The video encoder always sends the video in landscape mode. The video encoder rotates the original video before sending\n         * it and the rotational information is 0. This mode applies to scenarios involving CDN live streaming.\n         */\n        ORIENTATION_MODE[ORIENTATION_MODE[\"ORIENTATION_MODE_FIXED_LANDSCAPE\"] = 1] = \"ORIENTATION_MODE_FIXED_LANDSCAPE\";\n        /**\n         * 2: Portrait mode.\n         *\n         * The video encoder always sends the video in portrait mode. The video encoder rotates the original video before sending it\n         * and the rotational information is 0. This mode applies to scenarios involving CDN live streaming.\n         */\n        ORIENTATION_MODE[ORIENTATION_MODE[\"ORIENTATION_MODE_FIXED_PORTRAIT\"] = 2] = \"ORIENTATION_MODE_FIXED_PORTRAIT\";\n    })(ORIENTATION_MODE = AgoraRtcEngine.ORIENTATION_MODE || (AgoraRtcEngine.ORIENTATION_MODE = {}));\n    /**\n     * Video degradation preferences when the bandwidth is a constraint.\n     */\n    var DEGRADATION_PREFERENCE;\n    (function (DEGRADATION_PREFERENCE) {\n        /**\n         * 0: (Default) Degrade the frame rate in order to maintain the video quality.\n         */\n        DEGRADATION_PREFERENCE[DEGRADATION_PREFERENCE[\"MAINTAIN_QUALITY\"] = 0] = \"MAINTAIN_QUALITY\";\n        /**\n         * 1: Degrade the video quality in order to maintain the frame rate.\n         */\n        DEGRADATION_PREFERENCE[DEGRADATION_PREFERENCE[\"MAINTAIN_FRAMERATE\"] = 1] = \"MAINTAIN_FRAMERATE\";\n        /**\n         * 2: (For future use) Maintain a balance between the frame rate and video quality.\n         */\n        DEGRADATION_PREFERENCE[DEGRADATION_PREFERENCE[\"MAINTAIN_BALANCED\"] = 2] = \"MAINTAIN_BALANCED\";\n    })(DEGRADATION_PREFERENCE = AgoraRtcEngine.DEGRADATION_PREFERENCE || (AgoraRtcEngine.DEGRADATION_PREFERENCE = {}));\n    /**\n     * Stream fallback options.\n     */\n    var STREAM_FALLBACK_OPTIONS;\n    (function (STREAM_FALLBACK_OPTIONS) {\n        /**\n         * 0: No fallback behavior for the local/remote video stream when the uplink/downlink network conditions are poor. The\n         * quality of the stream is not guaranteed.\n         */\n        STREAM_FALLBACK_OPTIONS[STREAM_FALLBACK_OPTIONS[\"STREAM_FALLBACK_OPTION_DISABLED\"] = 0] = \"STREAM_FALLBACK_OPTION_DISABLED\";\n        /**\n         * 1: Under poor downlink network conditions, the remote video stream, to which you subscribe, falls back to the\n         * low-stream (low resolution and low bitrate) video. You can set this option only in the\n         * [setRemoteSubscribeFallbackOption]{@link AgoraRtcEngine.setRemoteSubscribeFallbackOption} method. Nothing happens when you set this\n         * in the [setLocalPublishFallbackOption]{@link AgoraRtcEngine.setLocalPublishFallbackOption} method.\n         */\n        STREAM_FALLBACK_OPTIONS[STREAM_FALLBACK_OPTIONS[\"STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW\"] = 1] = \"STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW\";\n        /**\n         * 2: Under poor uplink network conditions, the published video stream falls back to audio only.\n         *\n         * Under poor downlink network conditions, the remote video stream, to which you subscribe, first falls back to the\n         * low-stream (low resolution and low bitrate) video; and then to an audio-only stream if the network conditions worsen.\n         */\n        STREAM_FALLBACK_OPTIONS[STREAM_FALLBACK_OPTIONS[\"STREAM_FALLBACK_OPTION_AUDIO_ONLY\"] = 2] = \"STREAM_FALLBACK_OPTION_AUDIO_ONLY\";\n    })(STREAM_FALLBACK_OPTIONS = AgoraRtcEngine.STREAM_FALLBACK_OPTIONS || (AgoraRtcEngine.STREAM_FALLBACK_OPTIONS = {}));\n    /**\n     * Camera capturer configuration.\n     */\n    var CAPTURER_OUTPUT_PREFERENCE;\n    (function (CAPTURER_OUTPUT_PREFERENCE) {\n        /**\n         * 0: (Default) self-adapts the camera output parameters to the system performance and network conditions to balance\n         * CPU consumption and video preview quality.\n         */\n        CAPTURER_OUTPUT_PREFERENCE[CAPTURER_OUTPUT_PREFERENCE[\"CAPTURER_OUTPUT_PREFERENCE_AUTO\"] = 0] = \"CAPTURER_OUTPUT_PREFERENCE_AUTO\";\n        /**\n         * 1: Prioritizes the system performance. The SDK chooses the dimension and frame rate of the local camera capture\n         * closest to those set by [setVideoEncoderConfiguration]{@link AgoraRtcEngine.setVideoEncoderConfiguration}\n         */\n        CAPTURER_OUTPUT_PREFERENCE[CAPTURER_OUTPUT_PREFERENCE[\"CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE\"] = 1] = \"CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE\";\n        /**\n         * 2: Prioritizes the local preview quality. The SDK chooses higher camera output parameters to improve the local\n         * video preview quality. This option requires extra CPU and RAM usage for video pre-processing.\n         */\n        CAPTURER_OUTPUT_PREFERENCE[CAPTURER_OUTPUT_PREFERENCE[\"CAPTURER_OUTPUT_PREFERENCE_PREVIEW\"] = 2] = \"CAPTURER_OUTPUT_PREFERENCE_PREVIEW\";\n    })(CAPTURER_OUTPUT_PREFERENCE = AgoraRtcEngine.CAPTURER_OUTPUT_PREFERENCE || (AgoraRtcEngine.CAPTURER_OUTPUT_PREFERENCE = {}));\n    /**\n     * The priority of the remote user.\n     */\n    var PRIORITY_TYPE;\n    (function (PRIORITY_TYPE) {\n        /**\n         * 50: The user's priority is high.\n         */\n        PRIORITY_TYPE[PRIORITY_TYPE[\"PRIORITY_HIGH\"] = 50] = \"PRIORITY_HIGH\";\n        /**\n         * 100: (Default) The user's priority is normal.\n         */\n        PRIORITY_TYPE[PRIORITY_TYPE[\"PRIORITY_NORMAL\"] = 100] = \"PRIORITY_NORMAL\";\n    })(PRIORITY_TYPE = AgoraRtcEngine.PRIORITY_TYPE || (AgoraRtcEngine.PRIORITY_TYPE = {}));\n    /**\n     * Connection states.\n     */\n    var CONNECTION_STATE_TYPE;\n    (function (CONNECTION_STATE_TYPE) {\n        /**\n         * 1: The SDK is disconnected from Agora's edge server.\n         * - This is the initial state before calling the [joinChannel]{@link AgoraRtcEngine.joinChannel} method.\n         * - The SDK also enters this state when the application calls the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method.\n         */\n        CONNECTION_STATE_TYPE[CONNECTION_STATE_TYPE[\"CONNECTION_STATE_DISCONNECTED\"] = 1] = \"CONNECTION_STATE_DISCONNECTED\";\n        /**\n         * 2: The SDK is connecting to Agora's edge server.\n         * - When the application calls the [joinChannel]{@link AgoraRtcEngine.joinChannel} method, the SDK starts to establish a\n         * connection to the specified channel, triggers the [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged}\n         * callback, and switches to the `CONNECTION_STATE_CONNECTING` state.\n         * - When the SDK successfully joins the channel, it triggers the `onConnectionStateChanged` callback and switches to the\n         * [CONNECTION_STATE_CONNECTED]{@link AgoraRtcEngine.CONNECTION_STATE_TYPE.CONNECTION_STATE_CONNECTED} state.\n         * - After the SDK joins the channel and when it finishes initializing the media engine, the SDK triggers the\n         * [onJoinChannelSuccess]{@link AgoraRtcEvents.onJoinChannelSuccess} callback.\n         */\n        CONNECTION_STATE_TYPE[CONNECTION_STATE_TYPE[\"CONNECTION_STATE_CONNECTING\"] = 2] = \"CONNECTION_STATE_CONNECTING\";\n        /**\n         * 3: The SDK is connected to Agora's edge server and has joined a channel. You can now publish or subscribe to a media\n         * stream in the channel.\n         *\n         * If the connection to the channel is lost because, for example, if the network is down or switched, the SDK automatically\n         * tries to reconnect and triggers:\n         * - The [onConnectionInterrupted]{@link AgoraRtcEvents.onConnectionInterrupted} callback (deprecated).\n         * - The [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged} callback and switches to the\n         * [CONNECTION_STATE_RECONNECTING]{@link AgoraRtcEngine.CONNECTION_STATE_TYPE.CONNECTION_STATE_RECONNECTING} state.\n         */\n        CONNECTION_STATE_TYPE[CONNECTION_STATE_TYPE[\"CONNECTION_STATE_CONNECTED\"] = 3] = \"CONNECTION_STATE_CONNECTED\";\n        /**\n         * 4: The SDK keeps rejoining the channel after being disconnected from a joined channel because of network issues.\n         *\n         * - If the SDK cannot rejoin the channel within 10 seconds after being disconnected from Agora's edge server,\n         * the SDK triggers the [onConnectionLost]{@link AgoraRtcEvents.onConnectionLost} callback, stays in the\n         * [CONNECTION_STATE_RECONNECTING]{@link AgoraRtcEngine.CONNECTION_STATE_TYPE.CONNECTION_STATE_RECONNECTING} state, and keeps\n         * rejoining the channel.\n         * - If the SDK fails to rejoin the channel 20 minutes after being disconnected from Agora's edge server, the SDK\n         * triggers the [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged} callback, switches to the\n         * [CONNECTION_STATE_FAILED]{@link AgoraRtcEngine.CONNECTION_STATE_TYPE.CONNECTION_STATE_FAILED} state, and stops rejoining the channel.\n         */\n        CONNECTION_STATE_TYPE[CONNECTION_STATE_TYPE[\"CONNECTION_STATE_RECONNECTING\"] = 4] = \"CONNECTION_STATE_RECONNECTING\";\n        /**\n         * 5: The SDK fails to connect to Agora's edge server or join the channel.\n         *\n         * You must call the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method to leave this state, and call the\n         * [joinChannel]{@link AgoraRtcEngine.joinChannel} method again to rejoin the channel.\n         *\n         * If the SDK is banned from joining the channel by Agora's edge server (through the RESTful API), the SDK triggers the\n         * [onConnectionBanned]{@link AgoraRtcEvents.onConnectionBanned} (deprecated) and\n         * [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged} callbacks.\n         */\n        CONNECTION_STATE_TYPE[CONNECTION_STATE_TYPE[\"CONNECTION_STATE_FAILED\"] = 5] = \"CONNECTION_STATE_FAILED\";\n    })(CONNECTION_STATE_TYPE = AgoraRtcEngine.CONNECTION_STATE_TYPE || (AgoraRtcEngine.CONNECTION_STATE_TYPE = {}));\n    /**\n     * Reasons for a connection state change.\n     */\n    var CONNECTION_CHANGED_REASON_TYPE;\n    (function (CONNECTION_CHANGED_REASON_TYPE) {\n        /**\n         * 0: The SDK is connecting to Agora's edge server.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_CONNECTING\"] = 0] = \"CONNECTION_CHANGED_CONNECTING\";\n        /**\n         * 1: The SDK has joined the channel successfully.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_JOIN_SUCCESS\"] = 1] = \"CONNECTION_CHANGED_JOIN_SUCCESS\";\n        /**\n         * 2: The connection between the SDK and Agora's edge server is interrupted.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_INTERRUPTED\"] = 2] = \"CONNECTION_CHANGED_INTERRUPTED\";\n        /**\n         * 3: The connection between the SDK and Agora's edge server is banned by Agora's edge server.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_BANNED_BY_SERVER\"] = 3] = \"CONNECTION_CHANGED_BANNED_BY_SERVER\";\n        /**\n         * 4: The SDK fails to join the channel for more than 20 minutes and stops reconnecting to the channel.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_JOIN_FAILED\"] = 4] = \"CONNECTION_CHANGED_JOIN_FAILED\";\n        /**\n         * 5: The SDK has left the channel.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_LEAVE_CHANNEL\"] = 5] = \"CONNECTION_CHANGED_LEAVE_CHANNEL\";\n        /**\n         * 6: The connection failed since Appid is not valid.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_INVALID_APP_ID\"] = 6] = \"CONNECTION_CHANGED_INVALID_APP_ID\";\n        /**\n         * 7: The connection failed since channel name is not valid.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_INVALID_CHANNEL_NAME\"] = 7] = \"CONNECTION_CHANGED_INVALID_CHANNEL_NAME\";\n        /**\n         * 8: The connection failed since token is not valid, possibly because:\n         *\n         * - The App Certificate for the project is enabled in Console, but you do not use Token when joining the channel.\n         * If you enable the App Certificate, you must use a token to join the channel.\n         * - The uid that you specify in the [joinChannel]{@link AgoraRtcEngine.joinChannel} method is different from the uid that\n         * you pass for generating the token.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_INVALID_TOKEN\"] = 8] = \"CONNECTION_CHANGED_INVALID_TOKEN\";\n        /**\n         * 9: The connection failed since token is expired.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_TOKEN_EXPIRED\"] = 9] = \"CONNECTION_CHANGED_TOKEN_EXPIRED\";\n        /**\n         * 10: The connection is rejected by server.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_REJECTED_BY_SERVER\"] = 10] = \"CONNECTION_CHANGED_REJECTED_BY_SERVER\";\n        /**\n         * 11: The connection changed to reconnecting since SDK has set a proxy server.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_SETTING_PROXY_SERVER\"] = 11] = \"CONNECTION_CHANGED_SETTING_PROXY_SERVER\";\n        /**\n         * 12: When SDK is in connection failed, the renew token operation will make it connecting.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_RENEW_TOKEN\"] = 12] = \"CONNECTION_CHANGED_RENEW_TOKEN\";\n        /**\n         * 13: The IP Address of SDK client has changed. i.e., Network type or IP/Port changed by network operator might\n         * change client IP address.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_CLIENT_IP_ADDRESS_CHANGED\"] = 13] = \"CONNECTION_CHANGED_CLIENT_IP_ADDRESS_CHANGED\";\n        /**\n         * 14: Timeout for the keep-alive of the connection between the SDK and Agora's edge server. The connection state\n         * changes to [CONNECTION_STATE_RECONNECTING]{@link AgoraRtcEngine.CONNECTION_STATE_TYPE.CONNECTION_STATE_RECONNECTING}.\n         */\n        CONNECTION_CHANGED_REASON_TYPE[CONNECTION_CHANGED_REASON_TYPE[\"CONNECTION_CHANGED_KEEP_ALIVE_TIMEOUT\"] = 14] = \"CONNECTION_CHANGED_KEEP_ALIVE_TIMEOUT\";\n    })(CONNECTION_CHANGED_REASON_TYPE = AgoraRtcEngine.CONNECTION_CHANGED_REASON_TYPE || (AgoraRtcEngine.CONNECTION_CHANGED_REASON_TYPE = {}));\n    /**\n     * Network type.\n     */\n    var NETWORK_TYPE;\n    (function (NETWORK_TYPE) {\n        /**\n         * -1: The network type is unknown.\n         */\n        NETWORK_TYPE[NETWORK_TYPE[\"NETWORK_TYPE_UNKNOWN\"] = -1] = \"NETWORK_TYPE_UNKNOWN\";\n        /**\n         * 0: The SDK disconnects from the network.\n         */\n        NETWORK_TYPE[NETWORK_TYPE[\"NETWORK_TYPE_DISCONNECTED\"] = 0] = \"NETWORK_TYPE_DISCONNECTED\";\n        /**\n         * 1: The network type is LAN.\n         */\n        NETWORK_TYPE[NETWORK_TYPE[\"NETWORK_TYPE_LAN\"] = 1] = \"NETWORK_TYPE_LAN\";\n        /**\n         * 2: The network type is Wi-Fi(including hotspots).\n         */\n        NETWORK_TYPE[NETWORK_TYPE[\"NETWORK_TYPE_WIFI\"] = 2] = \"NETWORK_TYPE_WIFI\";\n        /**\n         * 3: The network type is mobile 2G.\n         */\n        NETWORK_TYPE[NETWORK_TYPE[\"NETWORK_TYPE_MOBILE_2G\"] = 3] = \"NETWORK_TYPE_MOBILE_2G\";\n        /**\n         * 4: The network type is mobile 3G.\n         */\n        NETWORK_TYPE[NETWORK_TYPE[\"NETWORK_TYPE_MOBILE_3G\"] = 4] = \"NETWORK_TYPE_MOBILE_3G\";\n        /**\n         * 5: The network type is mobile 4G.\n         */\n        NETWORK_TYPE[NETWORK_TYPE[\"NETWORK_TYPE_MOBILE_4G\"] = 5] = \"NETWORK_TYPE_MOBILE_4G\";\n    })(NETWORK_TYPE = AgoraRtcEngine.NETWORK_TYPE || (AgoraRtcEngine.NETWORK_TYPE = {}));\n    /**\n     * States of the last-mile network probe test.\n     */\n    var LASTMILE_PROBE_RESULT_STATE;\n    (function (LASTMILE_PROBE_RESULT_STATE) {\n        /**\n         * 1: The last-mile network probe test is complete.\n         */\n        LASTMILE_PROBE_RESULT_STATE[LASTMILE_PROBE_RESULT_STATE[\"LASTMILE_PROBE_RESULT_COMPLETE\"] = 1] = \"LASTMILE_PROBE_RESULT_COMPLETE\";\n        /**\n         * 2: The last-mile network probe test is incomplete and the bandwidth estimation is not available, probably due to\n         * limited test resources.\n         */\n        LASTMILE_PROBE_RESULT_STATE[LASTMILE_PROBE_RESULT_STATE[\"LASTMILE_PROBE_RESULT_INCOMPLETE_NO_BWE\"] = 2] = \"LASTMILE_PROBE_RESULT_INCOMPLETE_NO_BWE\";\n        /**\n         * 3: The last-mile network probe test is not carried out, probably due to poor network conditions.\n         */\n        LASTMILE_PROBE_RESULT_STATE[LASTMILE_PROBE_RESULT_STATE[\"LASTMILE_PROBE_RESULT_UNAVAILABLE\"] = 3] = \"LASTMILE_PROBE_RESULT_UNAVAILABLE\";\n    })(LASTMILE_PROBE_RESULT_STATE = AgoraRtcEngine.LASTMILE_PROBE_RESULT_STATE || (AgoraRtcEngine.LASTMILE_PROBE_RESULT_STATE = {}));\n    /**\n     * Audio output routing.\n     */\n    var AUDIO_ROUTE_TYPE;\n    (function (AUDIO_ROUTE_TYPE) {\n        /**\n         * Default.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_DEFAULT\"] = -1] = \"AUDIO_ROUTE_DEFAULT\";\n        /**\n         * Headset.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_HEADSET\"] = 0] = \"AUDIO_ROUTE_HEADSET\";\n        /**\n         * Earpiece.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_EARPIECE\"] = 1] = \"AUDIO_ROUTE_EARPIECE\";\n        /**\n         * Headset with no microphone.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_HEADSET_NO_MIC\"] = 2] = \"AUDIO_ROUTE_HEADSET_NO_MIC\";\n        /**\n         * Speakerphone.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_SPEAKERPHONE\"] = 3] = \"AUDIO_ROUTE_SPEAKERPHONE\";\n        /**\n         * Loudspeaker.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_LOUDSPEAKER\"] = 4] = \"AUDIO_ROUTE_LOUDSPEAKER\";\n        /**\n         * Bluetooth headset.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_BLUETOOTH\"] = 5] = \"AUDIO_ROUTE_BLUETOOTH\";\n        /**\n         * USB peripheral.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_USB\"] = 6] = \"AUDIO_ROUTE_USB\";\n        /**\n         * HDMI peripheral.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_HDMI\"] = 7] = \"AUDIO_ROUTE_HDMI\";\n        /**\n         * DisplayPort peripheral.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_DISPLAYPORT\"] = 8] = \"AUDIO_ROUTE_DISPLAYPORT\";\n        /**\n         * Apple AirPlay.\n         */\n        AUDIO_ROUTE_TYPE[AUDIO_ROUTE_TYPE[\"AUDIO_ROUTE_AIRPLAY\"] = 9] = \"AUDIO_ROUTE_AIRPLAY\";\n    })(AUDIO_ROUTE_TYPE = AgoraRtcEngine.AUDIO_ROUTE_TYPE || (AgoraRtcEngine.AUDIO_ROUTE_TYPE = {}));\n    /**\n     * Audio session restriction.\n     */\n    var AUDIO_SESSION_OPERATION_RESTRICTION;\n    (function (AUDIO_SESSION_OPERATION_RESTRICTION) {\n        /**\n         * No restriction, the SDK has full control of the audio session operations.\n         */\n        AUDIO_SESSION_OPERATION_RESTRICTION[AUDIO_SESSION_OPERATION_RESTRICTION[\"AUDIO_SESSION_OPERATION_RESTRICTION_NONE\"] = 0] = \"AUDIO_SESSION_OPERATION_RESTRICTION_NONE\";\n        /**\n         * The SDK does not change the audio session category.\n         */\n        AUDIO_SESSION_OPERATION_RESTRICTION[AUDIO_SESSION_OPERATION_RESTRICTION[\"AUDIO_SESSION_OPERATION_RESTRICTION_SET_CATEGORY\"] = 1] = \"AUDIO_SESSION_OPERATION_RESTRICTION_SET_CATEGORY\";\n        /**\n         * The SDK does not change any setting of the audio session (category, mode, categoryOptions).\n         */\n        AUDIO_SESSION_OPERATION_RESTRICTION[AUDIO_SESSION_OPERATION_RESTRICTION[\"AUDIO_SESSION_OPERATION_RESTRICTION_CONFIGURE_SESSION\"] = 2] = \"AUDIO_SESSION_OPERATION_RESTRICTION_CONFIGURE_SESSION\";\n        /**\n         * The SDK keeps the audio session active when leaving a channel.\n         */\n        AUDIO_SESSION_OPERATION_RESTRICTION[AUDIO_SESSION_OPERATION_RESTRICTION[\"AUDIO_SESSION_OPERATION_RESTRICTION_DEACTIVATE_SESSION\"] = 4] = \"AUDIO_SESSION_OPERATION_RESTRICTION_DEACTIVATE_SESSION\";\n        /**\n         * The SDK does not configure the audio session anymore.\n         */\n        AUDIO_SESSION_OPERATION_RESTRICTION[AUDIO_SESSION_OPERATION_RESTRICTION[\"AUDIO_SESSION_OPERATION_RESTRICTION_ALL\"] = 128] = \"AUDIO_SESSION_OPERATION_RESTRICTION_ALL\";\n    })(AUDIO_SESSION_OPERATION_RESTRICTION = AgoraRtcEngine.AUDIO_SESSION_OPERATION_RESTRICTION || (AgoraRtcEngine.AUDIO_SESSION_OPERATION_RESTRICTION = {}));\n    /**\n     * The direction of the camera.\n     */\n    var CAMERA_DIRECTION;\n    (function (CAMERA_DIRECTION) {\n        /**\n         * The rear camera.\n         */\n        CAMERA_DIRECTION[CAMERA_DIRECTION[\"CAMERA_REAR\"] = 0] = \"CAMERA_REAR\";\n        /**\n         * The front camera.\n         */\n        CAMERA_DIRECTION[CAMERA_DIRECTION[\"CAMERA_FRONT\"] = 1] = \"CAMERA_FRONT\";\n    })(CAMERA_DIRECTION = AgoraRtcEngine.CAMERA_DIRECTION || (AgoraRtcEngine.CAMERA_DIRECTION = {}));\n    /**\n     * The detailed options of a user.\n     */\n    var ClientRoleOptions = /** @class */ (function () {\n        function ClientRoleOptions(audienceLatencyLevel) {\n            this.audienceLatencyLevel = audienceLatencyLevel;\n        }\n        return ClientRoleOptions;\n    }());\n    AgoraRtcEngine.ClientRoleOptions = ClientRoleOptions;\n    /**\n     * Quality change of the local video in terms of target frame rate and target bit rate since last count.\n     */\n    var QUALITY_ADAPT_INDICATION;\n    (function (QUALITY_ADAPT_INDICATION) {\n        /**\n         * The quality of the local video stays the same.\n         */\n        QUALITY_ADAPT_INDICATION[QUALITY_ADAPT_INDICATION[\"ADAPT_NONE\"] = 0] = \"ADAPT_NONE\";\n        /**\n         * The quality improves because the network bandwidth increases.\n         */\n        QUALITY_ADAPT_INDICATION[QUALITY_ADAPT_INDICATION[\"ADAPT_UP_BANDWIDTH\"] = 1] = \"ADAPT_UP_BANDWIDTH\";\n        /**\n         * The quality worsens because the network bandwidth decreases.\n         */\n        QUALITY_ADAPT_INDICATION[QUALITY_ADAPT_INDICATION[\"ADAPT_DOWN_BANDWIDTH\"] = 2] = \"ADAPT_DOWN_BANDWIDTH\";\n    })(QUALITY_ADAPT_INDICATION = AgoraRtcEngine.QUALITY_ADAPT_INDICATION || (AgoraRtcEngine.QUALITY_ADAPT_INDICATION = {}));\n    /**\n     * The error code in CHANNEL_MEDIA_RELAY_ERROR.\n     */\n    var CHANNEL_MEDIA_RELAY_ERROR;\n    (function (CHANNEL_MEDIA_RELAY_ERROR) {\n        /**\n         * 0: The state is normal.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_OK\"] = 0] = \"RELAY_OK\";\n        /**\n         * 1: An error occurs in the server response.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_SERVER_ERROR_RESPONSE\"] = 1] = \"RELAY_ERROR_SERVER_ERROR_RESPONSE\";\n        /**\n         * 2: No server response. You can call the\n         * [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method to leave the channel.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_SERVER_NO_RESPONSE\"] = 2] = \"RELAY_ERROR_SERVER_NO_RESPONSE\";\n        /**\n         * 3: The SDK fails to access the service, probably due to limited\n         * resources of the server.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_NO_RESOURCE_AVAILABLE\"] = 3] = \"RELAY_ERROR_NO_RESOURCE_AVAILABLE\";\n        /**\n         * 4: Fails to send the relay request.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_FAILED_JOIN_SRC\"] = 4] = \"RELAY_ERROR_FAILED_JOIN_SRC\";\n        /**\n         * 5: Fails to accept the relay request.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_FAILED_JOIN_DEST\"] = 5] = \"RELAY_ERROR_FAILED_JOIN_DEST\";\n        /**\n         * 6: The server fails to receive the media stream.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_FAILED_PACKET_RECEIVED_FROM_SRC\"] = 6] = \"RELAY_ERROR_FAILED_PACKET_RECEIVED_FROM_SRC\";\n        /**\n         * 7: The server fails to send the media stream.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_FAILED_PACKET_SENT_TO_DEST\"] = 7] = \"RELAY_ERROR_FAILED_PACKET_SENT_TO_DEST\";\n        /**\n         * 8: The SDK disconnects from the server due to poor network\n         * connections. You can call the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method to leave the channel.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_SERVER_CONNECTION_LOST\"] = 8] = \"RELAY_ERROR_SERVER_CONNECTION_LOST\";\n        /**\n         * 9: An internal error occurs in the server.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_INTERNAL_ERROR\"] = 9] = \"RELAY_ERROR_INTERNAL_ERROR\";\n        /**\n         * 10: The token of the source channel has expired.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_SRC_TOKEN_EXPIRED\"] = 10] = \"RELAY_ERROR_SRC_TOKEN_EXPIRED\";\n        /**\n         * 11: The token of the destination channel has expired.\n         */\n        CHANNEL_MEDIA_RELAY_ERROR[CHANNEL_MEDIA_RELAY_ERROR[\"RELAY_ERROR_DEST_TOKEN_EXPIRED\"] = 11] = \"RELAY_ERROR_DEST_TOKEN_EXPIRED\";\n    })(CHANNEL_MEDIA_RELAY_ERROR = AgoraRtcEngine.CHANNEL_MEDIA_RELAY_ERROR || (AgoraRtcEngine.CHANNEL_MEDIA_RELAY_ERROR = {}));\n    /**\n     * The event code in CHANNEL_MEDIA_RELAY_EVENT.\n     */\n    var CHANNEL_MEDIA_RELAY_EVENT;\n    (function (CHANNEL_MEDIA_RELAY_EVENT) {\n        /**\n         * 0: The user disconnects from the server due to poor network\n         * connections.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_NETWORK_DISCONNECTED\"] = 0] = \"RELAY_EVENT_NETWORK_DISCONNECTED\";\n        /**\n         * 1: The network reconnects.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_NETWORK_CONNECTED\"] = 1] = \"RELAY_EVENT_NETWORK_CONNECTED\";\n        /**\n         * 2: The user joins the source channel.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_JOINED_SRC_CHANNEL\"] = 2] = \"RELAY_EVENT_PACKET_JOINED_SRC_CHANNEL\";\n        /**\n         * 3: The user joins the destination channel.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_JOINED_DEST_CHANNEL\"] = 3] = \"RELAY_EVENT_PACKET_JOINED_DEST_CHANNEL\";\n        /**\n         * 4: The SDK starts relaying the media stream to the destination channel.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL\"] = 4] = \"RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL\";\n        /**\n         *  5: The server receives the video stream from the source channel.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_RECEIVED_VIDEO_FROM_SRC\"] = 5] = \"RELAY_EVENT_PACKET_RECEIVED_VIDEO_FROM_SRC\";\n        /**\n         * 6: The server receives the audio stream from the source channel.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_RECEIVED_AUDIO_FROM_SRC\"] = 6] = \"RELAY_EVENT_PACKET_RECEIVED_AUDIO_FROM_SRC\";\n        /**\n         * 7: The destination channel is updated.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL\"] = 7] = \"RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL\";\n        /**\n         * 8: The destination channel update fails due to internal reasons.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED\"] = 8] = \"RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED\";\n        /**\n         * 9: The destination channel does not change, which means that the\n         * destination channel fails to be updated.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_NOT_CHANGE\"] = 9] = \"RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_NOT_CHANGE\";\n        /**\n         * 10: The destination channel name is `null`.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_IS_NULL\"] = 10] = \"RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_IS_NULL\";\n        /**\n         *  11: The video profile is sent to the server.\n         */\n        CHANNEL_MEDIA_RELAY_EVENT[CHANNEL_MEDIA_RELAY_EVENT[\"RELAY_EVENT_VIDEO_PROFILE_UPDATE\"] = 11] = \"RELAY_EVENT_VIDEO_PROFILE_UPDATE\";\n    })(CHANNEL_MEDIA_RELAY_EVENT = AgoraRtcEngine.CHANNEL_MEDIA_RELAY_EVENT || (AgoraRtcEngine.CHANNEL_MEDIA_RELAY_EVENT = {}));\n    /**\n     * The state code in CHANNEL_MEDIA_RELAY_STATE.\n     */\n    var CHANNEL_MEDIA_RELAY_STATE;\n    (function (CHANNEL_MEDIA_RELAY_STATE) {\n        /**\n         * 0: The SDK is initializing.\n         */\n        CHANNEL_MEDIA_RELAY_STATE[CHANNEL_MEDIA_RELAY_STATE[\"RELAY_STATE_IDLE\"] = 0] = \"RELAY_STATE_IDLE\";\n        /**\n         * 1: The SDK tries to relay the media stream to the destination channel.\n         */\n        CHANNEL_MEDIA_RELAY_STATE[CHANNEL_MEDIA_RELAY_STATE[\"RELAY_STATE_CONNECTING\"] = 1] = \"RELAY_STATE_CONNECTING\";\n        /**\n         * 2: The SDK successfully relays the media stream to the destination\n         * channel.\n         */\n        CHANNEL_MEDIA_RELAY_STATE[CHANNEL_MEDIA_RELAY_STATE[\"RELAY_STATE_RUNNING\"] = 2] = \"RELAY_STATE_RUNNING\";\n        /**\n         * 3: A failure occurs. See the details in code.\n         */\n        CHANNEL_MEDIA_RELAY_STATE[CHANNEL_MEDIA_RELAY_STATE[\"RELAY_STATE_FAILURE\"] = 3] = \"RELAY_STATE_FAILURE\";\n    })(CHANNEL_MEDIA_RELAY_STATE = AgoraRtcEngine.CHANNEL_MEDIA_RELAY_STATE || (AgoraRtcEngine.CHANNEL_MEDIA_RELAY_STATE = {}));\n    /**\n     * Video dimensions.\n     */\n    var VideoDimensions = /** @class */ (function () {\n        function VideoDimensions(width, height) {\n            if (width === void 0) { width = 640; }\n            if (height === void 0) { height = 480; }\n            this.width = width;\n            this.height = height;\n        }\n        return VideoDimensions;\n    }());\n    AgoraRtcEngine.VideoDimensions = VideoDimensions;\n    /**\n     * (Recommended) The standard bitrate set in the [setVideoEncoderConfiguration]{@link AgoraRtcEngine.setVideoEncoderConfiguration} method.\n     *\n     * In this mode, the bitrates differ between the live interactive streaming and communication profiles:\n     * - `COMMUNICATION` profile: The video bitrate is the same as the base bitrate.\n     * - `LIVE_BROADCASTING` profile: The video bitrate is twice the base bitrate.\n     */\n    AgoraRtcEngine.STANDARD_BITRATE = 0;\n    /**\n     * The compatible bitrate set in the [setVideoEncoderConfiguration]{@link AgoraRtcEngine.setVideoEncoderConfiguration} method.\n     * The bitrate remains the same regardless of the channel profile. If you choose this mode in the `LIVE_BROADCASTING` profile, the\n     * video frame rate may be lower than the set value.\n     */\n    AgoraRtcEngine.COMPATIBLE_BITRATE = -1;\n    /**\n     * Use the default minimum bitrate.\n     */\n    AgoraRtcEngine.DEFAULT_MIN_BITRATE = -1;\n    /**\n     * Video encoder configurations.\n     */\n    var VideoEncoderConfiguration = /** @class */ (function () {\n        function VideoEncoderConfiguration(dimensions, frameRate, minFrameRate, bitrate, minBitrate, orientationMode, degradationPreference, mirrorMode) {\n            if (dimensions === void 0) { dimensions = new VideoDimensions(); }\n            if (frameRate === void 0) { frameRate = FRAME_RATE.FRAME_RATE_FPS_15; }\n            if (minFrameRate === void 0) { minFrameRate = -1; }\n            if (bitrate === void 0) { bitrate = AgoraRtcEngine.STANDARD_BITRATE; }\n            if (minBitrate === void 0) { minBitrate = AgoraRtcEngine.DEFAULT_MIN_BITRATE; }\n            if (orientationMode === void 0) { orientationMode = ORIENTATION_MODE.ORIENTATION_MODE_ADAPTIVE; }\n            if (degradationPreference === void 0) { degradationPreference = DEGRADATION_PREFERENCE.MAINTAIN_QUALITY; }\n            if (mirrorMode === void 0) { mirrorMode = VIDEO_MIRROR_MODE_TYPE.VIDEO_MIRROR_MODE_AUTO; }\n            this.dimensions = dimensions;\n            this.frameRate = frameRate;\n            this.minFrameRate = minFrameRate;\n            this.bitrate = bitrate;\n            this.minBitrate = minBitrate;\n            this.orientationMode = orientationMode;\n            this.degradationPreference = degradationPreference;\n            this.mirrorMode = mirrorMode;\n        }\n        return VideoEncoderConfiguration;\n    }());\n    AgoraRtcEngine.VideoEncoderConfiguration = VideoEncoderConfiguration;\n    /**\n     * The video and audio properties of the user displaying the video in the CDN live. Agora supports a maximum of 17 transcoding\n     * users in a CDN streaming channel.\n     */\n    var TranscodingUser = /** @class */ (function () {\n        function TranscodingUser(uid, x, y, width, height, zOrder, alpha, audioChannel) {\n            if (alpha === void 0) { alpha = 1.0; }\n            this.uid = uid;\n            this.x = x;\n            this.y = y;\n            this.width = width;\n            this.height = height;\n            this.zOrder = zOrder;\n            this.alpha = alpha;\n            this.audioChannel = audioChannel;\n        }\n        return TranscodingUser;\n    }());\n    AgoraRtcEngine.TranscodingUser = TranscodingUser;\n    /**\n     * Image properties.\n     *\n     * The properties of the watermark and background images.\n     */\n    var RtcImage = /** @class */ (function () {\n        function RtcImage(url, x, y, width, height) {\n            this.url = url;\n            this.x = x;\n            this.y = y;\n            this.width = width;\n            this.height = height;\n        }\n        return RtcImage;\n    }());\n    AgoraRtcEngine.RtcImage = RtcImage;\n    /**\n     * The configuration for advanced features of the RTMP streaming with transcoding.\n     */\n    var LiveStreamAdvancedFeature = /** @class */ (function () {\n        function LiveStreamAdvancedFeature(featureName, opened) {\n            this.featureName = featureName;\n            this.opened = opened;\n        }\n        /**\n         * The advanced feature for high-quality video with a lower bitrate.\n         */\n        LiveStreamAdvancedFeature.LBHQ = 'lbhq';\n        /**\n         * The advanced feature for the optimized video encoder.\n         */\n        LiveStreamAdvancedFeature.VEO = 'veo';\n        return LiveStreamAdvancedFeature;\n    }());\n    AgoraRtcEngine.LiveStreamAdvancedFeature = LiveStreamAdvancedFeature;\n    /**\n     * A struct for managing CDN live audio/video transcoding settings.\n     */\n    var LiveTranscoding = /** @class */ (function () {\n        function LiveTranscoding(width, height, videoBitrate, videoFramerate, lowLatency, videoGop, videoCodecProfile, backgroundColor, userCount, transcodingUsers, transcodingExtraInfo, metadata, watermark, backgroundImage, audioSampleRate, audioBitrate, audioChannels, audioCodecProfile, advancedFeatures, advancedFeatureCount) {\n            if (width === void 0) { width = 360; }\n            if (height === void 0) { height = 640; }\n            if (videoBitrate === void 0) { videoBitrate = 400; }\n            if (videoFramerate === void 0) { videoFramerate = 15; }\n            if (lowLatency === void 0) { lowLatency = false; }\n            if (videoGop === void 0) { videoGop = 30; }\n            if (videoCodecProfile === void 0) { videoCodecProfile = VIDEO_CODEC_PROFILE_TYPE.VIDEO_CODEC_PROFILE_HIGH; }\n            if (backgroundColor === void 0) { backgroundColor = 0x000000; }\n            if (userCount === void 0) { userCount = 0; }\n            if (audioSampleRate === void 0) { audioSampleRate = AUDIO_SAMPLE_RATE_TYPE.AUDIO_SAMPLE_RATE_48000; }\n            if (audioBitrate === void 0) { audioBitrate = 48; }\n            if (audioChannels === void 0) { audioChannels = 1; }\n            if (audioCodecProfile === void 0) { audioCodecProfile = AUDIO_CODEC_PROFILE_TYPE.AUDIO_CODEC_PROFILE_LC_AAC; }\n            if (advancedFeatureCount === void 0) { advancedFeatureCount = 0; }\n            this.width = width;\n            this.height = height;\n            this.videoBitrate = videoBitrate;\n            this.videoFramerate = videoFramerate;\n            this.lowLatency = lowLatency;\n            this.videoGop = videoGop;\n            this.videoCodecProfile = videoCodecProfile;\n            this.backgroundColor = backgroundColor;\n            this.userCount = userCount;\n            this.transcodingUsers = transcodingUsers;\n            this.transcodingExtraInfo = transcodingExtraInfo;\n            this.metadata = metadata;\n            this.watermark = watermark;\n            this.backgroundImage = backgroundImage;\n            this.audioSampleRate = audioSampleRate;\n            this.audioBitrate = audioBitrate;\n            this.audioChannels = audioChannels;\n            this.audioCodecProfile = audioCodecProfile;\n            this.advancedFeatures = advancedFeatures;\n            this.advancedFeatureCount = advancedFeatureCount;\n        }\n        return LiveTranscoding;\n    }());\n    AgoraRtcEngine.LiveTranscoding = LiveTranscoding;\n    /**\n     * Camera capturer configuration.\n     */\n    var CameraCapturerConfiguration = /** @class */ (function () {\n        function CameraCapturerConfiguration(preference, cameraDirection) {\n            this.preference = preference;\n            this.cameraDirection = cameraDirection;\n        }\n        return CameraCapturerConfiguration;\n    }());\n    AgoraRtcEngine.CameraCapturerConfiguration = CameraCapturerConfiguration;\n    /**\n     * Configuration of the injected media stream.\n     */\n    var InjectStreamConfig = /** @class */ (function () {\n        function InjectStreamConfig(width, height, videoGop, videoFramerate, videoBitrate, audioSampleRate, audioBitrate, audioChannels) {\n            if (width === void 0) { width = 0; }\n            if (height === void 0) { height = 0; }\n            if (videoGop === void 0) { videoGop = 30; }\n            if (videoFramerate === void 0) { videoFramerate = 15; }\n            if (videoBitrate === void 0) { videoBitrate = 400; }\n            if (audioSampleRate === void 0) { audioSampleRate = AUDIO_SAMPLE_RATE_TYPE.AUDIO_SAMPLE_RATE_48000; }\n            if (audioBitrate === void 0) { audioBitrate = 48; }\n            if (audioChannels === void 0) { audioChannels = 1; }\n            this.width = width;\n            this.height = height;\n            this.videoGop = videoGop;\n            this.videoFramerate = videoFramerate;\n            this.videoBitrate = videoBitrate;\n            this.audioSampleRate = audioSampleRate;\n            this.audioBitrate = audioBitrate;\n            this.audioChannels = audioChannels;\n        }\n        return InjectStreamConfig;\n    }());\n    AgoraRtcEngine.InjectStreamConfig = InjectStreamConfig;\n    /**\n     * The definition of [ChannelMediaInfo]{@link AgoraRtcEngine.ChannelMediaInfo}.\n     */\n    var ChannelMediaInfo = /** @class */ (function () {\n        function ChannelMediaInfo(channelName, token, uid) {\n            this.channelName = channelName;\n            this.token = token;\n            this.uid = uid;\n        }\n        return ChannelMediaInfo;\n    }());\n    AgoraRtcEngine.ChannelMediaInfo = ChannelMediaInfo;\n    /**\n     * The definition of [ChannelMediaRelayConfiguration]{@link AgoraRtcEngine.ChannelMediaRelayConfiguration}.\n     */\n    var ChannelMediaRelayConfiguration = /** @class */ (function () {\n        function ChannelMediaRelayConfiguration(srcInfo, destInfos, destCount) {\n            this.srcInfo = srcInfo;\n            this.destInfos = destInfos;\n            this.destCount = destCount;\n        }\n        return ChannelMediaRelayConfiguration;\n    }());\n    AgoraRtcEngine.ChannelMediaRelayConfiguration = ChannelMediaRelayConfiguration;\n    /**\n     * @deprecated\n     * Lifecycle of the CDN live video stream.\n     */\n    var RTMP_STREAM_LIFE_CYCLE_TYPE;\n    (function (RTMP_STREAM_LIFE_CYCLE_TYPE) {\n        /**\n         * Bind to the channel lifecycle. If all hosts leave the channel, the CDN live streaming stops after 30 seconds.\n         */\n        RTMP_STREAM_LIFE_CYCLE_TYPE[RTMP_STREAM_LIFE_CYCLE_TYPE[\"RTMP_STREAM_LIFE_CYCLE_BIND2CHANNEL\"] = 1] = \"RTMP_STREAM_LIFE_CYCLE_BIND2CHANNEL\";\n        /**\n         * Bind to the owner of the RTMP stream. If the owner leaves the channel, the CDN live streaming stops immediately.\n         */\n        RTMP_STREAM_LIFE_CYCLE_TYPE[RTMP_STREAM_LIFE_CYCLE_TYPE[\"RTMP_STREAM_LIFE_CYCLE_BIND2OWNER\"] = 2] = \"RTMP_STREAM_LIFE_CYCLE_BIND2OWNER\";\n    })(RTMP_STREAM_LIFE_CYCLE_TYPE = AgoraRtcEngine.RTMP_STREAM_LIFE_CYCLE_TYPE || (AgoraRtcEngine.RTMP_STREAM_LIFE_CYCLE_TYPE = {}));\n    /**\n     * Content hints for screen sharing.\n     */\n    var VideoContentHint;\n    (function (VideoContentHint) {\n        /**\n         * (Default) No content hint.\n         */\n        VideoContentHint[VideoContentHint[\"CONTENT_HINT_NONE\"] = 0] = \"CONTENT_HINT_NONE\";\n        /**\n         * Motion-intensive content. Choose this option if you prefer smoothness or when you are sharing a video clip, movie, or\n         * video game.\n         */\n        VideoContentHint[VideoContentHint[\"CONTENT_HINT_MOTION\"] = 1] = \"CONTENT_HINT_MOTION\";\n        /**\n         * Motionless content. Choose this option if you prefer sharpness or when you are sharing a picture, PowerPoint slide, or text.\n         */\n        VideoContentHint[VideoContentHint[\"CONTENT_HINT_DETAILS\"] = 2] = \"CONTENT_HINT_DETAILS\";\n    })(VideoContentHint = AgoraRtcEngine.VideoContentHint || (AgoraRtcEngine.VideoContentHint = {}));\n    /**\n     * The relative location of the region to the screen or window.\n     */\n    var Rectangle = /** @class */ (function () {\n        function Rectangle(x, y, width, height) {\n            if (x === void 0) { x = 0; }\n            if (y === void 0) { y = 0; }\n            if (width === void 0) { width = 0; }\n            if (height === void 0) { height = 0; }\n            this.x = x;\n            this.y = y;\n            this.width = width;\n            this.height = height;\n        }\n        return Rectangle;\n    }());\n    AgoraRtcEngine.Rectangle = Rectangle;\n    /**\n     * @deprecated\n     * Definition of the rectangular region.\n     */\n    var Rect = /** @class */ (function () {\n        function Rect(top, left, bottom, right) {\n            if (top === void 0) { top = 0; }\n            if (left === void 0) { left = 0; }\n            if (bottom === void 0) { bottom = 0; }\n            if (right === void 0) { right = 0; }\n            this.top = top;\n            this.left = left;\n            this.bottom = bottom;\n            this.right = right;\n        }\n        return Rect;\n    }());\n    AgoraRtcEngine.Rect = Rect;\n    /**\n     * The options of the watermark image to be added.\n     */\n    var WatermarkOptions = /** @class */ (function () {\n        function WatermarkOptions(visibleInPreview, positionInLandscapeMode, positionInPortraitMode) {\n            if (visibleInPreview === void 0) { visibleInPreview = true; }\n            if (positionInLandscapeMode === void 0) { positionInLandscapeMode = new Rectangle(); }\n            if (positionInPortraitMode === void 0) { positionInPortraitMode = new Rectangle(); }\n            this.visibleInPreview = visibleInPreview;\n            this.positionInLandscapeMode = positionInLandscapeMode;\n            this.positionInPortraitMode = positionInPortraitMode;\n        }\n        return WatermarkOptions;\n    }());\n    AgoraRtcEngine.WatermarkOptions = WatermarkOptions;\n    /**\n     * Screen sharing encoding parameters.\n     */\n    var ScreenCaptureParameters = /** @class */ (function () {\n        function ScreenCaptureParameters(dimensions, frameRate, bitrate, captureMouseCursor, windowFocus, excludeWindowList, excludeWindowCount) {\n            if (dimensions === void 0) { dimensions = new VideoDimensions(1920, 1080); }\n            if (frameRate === void 0) { frameRate = 5; }\n            if (bitrate === void 0) { bitrate = AgoraRtcEngine.STANDARD_BITRATE; }\n            if (captureMouseCursor === void 0) { captureMouseCursor = true; }\n            if (windowFocus === void 0) { windowFocus = false; }\n            if (excludeWindowCount === void 0) { excludeWindowCount = 0; }\n            this.dimensions = dimensions;\n            this.frameRate = frameRate;\n            this.bitrate = bitrate;\n            this.captureMouseCursor = captureMouseCursor;\n            this.windowFocus = windowFocus;\n            this.excludeWindowList = excludeWindowList;\n            this.excludeWindowCount = excludeWindowCount;\n        }\n        return ScreenCaptureParameters;\n    }());\n    AgoraRtcEngine.ScreenCaptureParameters = ScreenCaptureParameters;\n    /**\n     * @ignore\n     * Video display settings of the `VideoCanvas` class.\n     */\n    var VideoCanvas = /** @class */ (function () {\n        function VideoCanvas(view, renderMode, channelId, uid, priv, mirrorMode) {\n            if (renderMode === void 0) { renderMode = RENDER_MODE_TYPE.RENDER_MODE_HIDDEN; }\n            if (uid === void 0) { uid = 0; }\n            if (mirrorMode === void 0) { mirrorMode = VIDEO_MIRROR_MODE_TYPE.VIDEO_MIRROR_MODE_AUTO; }\n            this.view = view;\n            this.renderMode = renderMode;\n            this.channelId = channelId;\n            this.uid = uid;\n            this.priv = priv;\n            this.mirrorMode = mirrorMode;\n        }\n        return VideoCanvas;\n    }());\n    AgoraRtcEngine.VideoCanvas = VideoCanvas;\n    /**\n     * The contrast level, used with the `lightening` parameter.\n     */\n    var LIGHTENING_CONTRAST_LEVEL;\n    (function (LIGHTENING_CONTRAST_LEVEL) {\n        /**\n         * Low contrast level.\n         */\n        LIGHTENING_CONTRAST_LEVEL[LIGHTENING_CONTRAST_LEVEL[\"LIGHTENING_CONTRAST_LOW\"] = 0] = \"LIGHTENING_CONTRAST_LOW\";\n        /**\n         * (Default) Normal contrast level.\n         */\n        LIGHTENING_CONTRAST_LEVEL[LIGHTENING_CONTRAST_LEVEL[\"LIGHTENING_CONTRAST_NORMAL\"] = 1] = \"LIGHTENING_CONTRAST_NORMAL\";\n        /**\n         * High contrast level.\n         */\n        LIGHTENING_CONTRAST_LEVEL[LIGHTENING_CONTRAST_LEVEL[\"LIGHTENING_CONTRAST_HIGH\"] = 2] = \"LIGHTENING_CONTRAST_HIGH\";\n    })(LIGHTENING_CONTRAST_LEVEL = AgoraRtcEngine.LIGHTENING_CONTRAST_LEVEL || (AgoraRtcEngine.LIGHTENING_CONTRAST_LEVEL = {}));\n    /**\n     * Image enhancement options.\n     */\n    var BeautyOptions = /** @class */ (function () {\n        function BeautyOptions(lighteningContrastLevel, lighteningLevel, smoothnessLevel, rednessLevel) {\n            if (lighteningContrastLevel === void 0) { lighteningContrastLevel = LIGHTENING_CONTRAST_LEVEL.LIGHTENING_CONTRAST_NORMAL; }\n            if (lighteningLevel === void 0) { lighteningLevel = 0; }\n            if (smoothnessLevel === void 0) { smoothnessLevel = 0; }\n            if (rednessLevel === void 0) { rednessLevel = 0; }\n            this.lighteningContrastLevel = lighteningContrastLevel;\n            this.lighteningLevel = lighteningLevel;\n            this.smoothnessLevel = smoothnessLevel;\n            this.rednessLevel = rednessLevel;\n        }\n        return BeautyOptions;\n    }());\n    AgoraRtcEngine.BeautyOptions = BeautyOptions;\n    /**\n     * Regions for connection.\n     */\n    var AREA_CODE;\n    (function (AREA_CODE) {\n        /**\n         * Mainland China.\n         */\n        AREA_CODE[AREA_CODE[\"AREA_CODE_CN\"] = 1] = \"AREA_CODE_CN\";\n        /**\n         * North America.\n         */\n        AREA_CODE[AREA_CODE[\"AREA_CODE_NA\"] = 2] = \"AREA_CODE_NA\";\n        /**\n         * Europe.\n         */\n        AREA_CODE[AREA_CODE[\"AREA_CODE_EU\"] = 4] = \"AREA_CODE_EU\";\n        /**\n         * Asia, excluding Mainland China.\n         */\n        AREA_CODE[AREA_CODE[\"AREA_CODE_AS\"] = 8] = \"AREA_CODE_AS\";\n        /**\n         * Japan.\n         */\n        AREA_CODE[AREA_CODE[\"AREA_CODE_JP\"] = 16] = \"AREA_CODE_JP\";\n        /**\n         * India.\n         */\n        AREA_CODE[AREA_CODE[\"AREA_CODE_IN\"] = 32] = \"AREA_CODE_IN\";\n        /**\n         * (Default) Global.\n         */\n        AREA_CODE[AREA_CODE[\"AREA_CODE_GLOB\"] = 4294967295] = \"AREA_CODE_GLOB\";\n    })(AREA_CODE = AgoraRtcEngine.AREA_CODE || (AgoraRtcEngine.AREA_CODE = {}));\n    /**\n     * @ignore\n     */\n    var ENCRYPTION_CONFIG;\n    (function (ENCRYPTION_CONFIG) {\n        ENCRYPTION_CONFIG[ENCRYPTION_CONFIG[\"ENCRYPTION_FORCE_SETTING\"] = 1] = \"ENCRYPTION_FORCE_SETTING\";\n        ENCRYPTION_CONFIG[ENCRYPTION_CONFIG[\"ENCRYPTION_FORCE_DISABLE_PACKET\"] = 2] = \"ENCRYPTION_FORCE_DISABLE_PACKET\";\n    })(ENCRYPTION_CONFIG = AgoraRtcEngine.ENCRYPTION_CONFIG || (AgoraRtcEngine.ENCRYPTION_CONFIG = {}));\n    /**\n     * Definition of RtcEngineContext.\n     */\n    var RtcEngineContext = /** @class */ (function () {\n        function RtcEngineContext(appId) {\n            /**\n             * The region for connection. This advanced feature applies to scenarios that have regional restrictions.\n             *\n             * For the regions that Agora supports, see #AREA_CODE. After specifying the region, the SDK connects to the Agora servers within that region.\n             *\n             * @note The SDK supports specify only one region.\n             */\n            this.areaCode = AREA_CODE.AREA_CODE_GLOB;\n            this.appId = appId;\n        }\n        return RtcEngineContext;\n    }());\n    AgoraRtcEngine.RtcEngineContext = RtcEngineContext;\n    /**\n     * Metadata type of the observer.\n     * @note We only support video metadata for now.\n     */\n    var METADATA_TYPE;\n    (function (METADATA_TYPE) {\n        /**\n         * -1: the metadata type is unknown.\n         */\n        METADATA_TYPE[METADATA_TYPE[\"UNKNOWN_METADATA\"] = -1] = \"UNKNOWN_METADATA\";\n        /**\n         * 0: the metadata type is video.\n         */\n        METADATA_TYPE[METADATA_TYPE[\"VIDEO_METADATA\"] = 0] = \"VIDEO_METADATA\";\n    })(METADATA_TYPE = AgoraRtcEngine.METADATA_TYPE || (AgoraRtcEngine.METADATA_TYPE = {}));\n    /**\n     * The defination of [Metadata]{@link AgoraRtcEngine.Metadata}.\n     */\n    var Metadata = /** @class */ (function () {\n        function Metadata(uid, size, buffer, timeStampMs) {\n            this.uid = uid;\n            this.size = size;\n            this.buffer = buffer;\n            this.timeStampMs = timeStampMs;\n        }\n        return Metadata;\n    }());\n    AgoraRtcEngine.Metadata = Metadata;\n    /**\n     * Encryption mode.\n     */\n    var ENCRYPTION_MODE;\n    (function (ENCRYPTION_MODE) {\n        /**\n         * 1: (Default) 128-bit AES encryption, XTS mode.\n         */\n        ENCRYPTION_MODE[ENCRYPTION_MODE[\"AES_128_XTS\"] = 1] = \"AES_128_XTS\";\n        /**\n         * 2: 128-bit AES encryption, ECB mode.\n         */\n        ENCRYPTION_MODE[ENCRYPTION_MODE[\"AES_128_ECB\"] = 2] = \"AES_128_ECB\";\n        /**\n         * 3: 256-bit AES encryption, XTS mode.\n         */\n        ENCRYPTION_MODE[ENCRYPTION_MODE[\"AES_256_XTS\"] = 3] = \"AES_256_XTS\";\n        /**\n         * 4: 128-bit SM4 encryption, ECB mode.\n         */\n        ENCRYPTION_MODE[ENCRYPTION_MODE[\"SM4_128_ECB\"] = 4] = \"SM4_128_ECB\";\n        /**\n         * Enumerator boundary.\n         */\n        ENCRYPTION_MODE[ENCRYPTION_MODE[\"MODE_END\"] = 5] = \"MODE_END\";\n    })(ENCRYPTION_MODE = AgoraRtcEngine.ENCRYPTION_MODE || (AgoraRtcEngine.ENCRYPTION_MODE = {}));\n    /**\n     * Configurations of built-in encryption schemas.\n     */\n    var EncryptionConfig = /** @class */ (function () {\n        function EncryptionConfig(encryptionMode, encryptionKey) {\n            if (encryptionMode === void 0) { encryptionMode = ENCRYPTION_MODE.AES_128_XTS; }\n            this.encryptionMode = encryptionMode;\n            this.encryptionKey = encryptionKey;\n        }\n        return EncryptionConfig;\n    }());\n    AgoraRtcEngine.EncryptionConfig = EncryptionConfig;\n})(AgoraRtcEngine || (AgoraRtcEngine = {}));\n(function (AgoraRtcEngine) {\n    /**\n     * TODO\n     *\n     * @param context\n     */\n    function initialize(context) {\n        return callNativeMethod(API_TYPE.INITIALIZE, context);\n    }\n    AgoraRtcEngine.initialize = initialize;\n    /**\n     * Releases all resources of the Agora engine.\n     *\n     * Use this method for apps in which users occasionally make voice or video calls. When users do not make calls, you can free up\n     * resources for other operations. Once you call `release` to release the Agora engine, you cannot use any method or\n     * callback in the SDK any more.\n     *\n     * If you want to use the real-time communication functions again, you must call [init]{@link AgoraRtcEngine.init} to initialize a\n     * new Agora engine.\n     *\n     * @note If you want to reinitialize the Agora engine after releasing the current one, ensure that you wait till the\n     * `release` method completes executing.\n     */\n    function release() {\n        callNativeMethod(API_TYPE.RELEASE);\n    }\n    AgoraRtcEngine.release = release;\n    /**\n     * Listens for the events during the Agora engine runtime.\n     */\n    function on(type, callback) {\n        // @ts-ignore\n        return window.agoraBridge.on(\"on\" + type, callback);\n    }\n    AgoraRtcEngine.on = on;\n    /**\n     * Stops monitoring the events during the Agora engine runtime.\n     */\n    function off(type, callback) {\n        // @ts-ignore\n        window.agoraBridge.off(\"on\" + type, callback);\n    }\n    AgoraRtcEngine.off = off;\n    /**\n     * Sets the channel profile of the Agora engine.\n     *\n     * The Agora engine differentiates channel profiles and applies optimization algorithms accordingly.\n     * For example, it prioritizes smoothness and low latency for a video call, and prioritizes video quality for the live interactive\n     * video streaming.\n     *\n     * @warning\n     * - To ensure the quality of real-time communication, we recommend that all users in a channel use the same channel profile.\n     * - Call this method before calling [joinChannel]{@link AgoraRtcEngine.joinChannel} . You cannot set the channel profile once you have\n     * joined the channel.\n     * - The default audio route and video encoding bitrate are different in different channel profiles. For details, see\n     * [setDefaultAudioRouteToSpeakerphone]{@link AgoraRtcEngine.setDefaultAudioRouteToSpeakerphone} and\n     * [setVideoEncoderConfiguration]{@link AgoraRtcEngine.setVideoEncoderConfiguration}.\n     *\n     * @param profile The channel profile of the Agora engine. See [CHANNEL_PROFILE_TYPE]{@link AgoraRtcEngine.CHANNEL_PROFILE_TYPE}.\n     *\n     * @return\n     * - 0(`ERR_OK`): Success.\n     * - < 0: Failure.\n     *  - -2(`ERR_INVALID_ARGUMENT`): The parameter is invalid.\n     *  - -7(`ERR_NOT_INITIALIZED`): The SDK is not initialized.\n     */\n    function setChannelProfile(profile) {\n        return callNativeMethod(API_TYPE.SET_CHANNEL_PROFILE, { profile: profile });\n    }\n    AgoraRtcEngine.setChannelProfile = setChannelProfile;\n    /**\n     * TODO\n     *\n     * @param role\n     * @param options\n     */\n    function setClientRole(role, options) {\n        return callNativeMethod(API_TYPE.SET_CLIENT_ROLE, { role: role, options: options });\n    }\n    AgoraRtcEngine.setClientRole = setClientRole;\n    /**\n     * Joins a channel with the user ID.\n     *\n     * Users in the same channel can talk to each other, and multiple users in the same channel can start a group chat. Users with\n     * different App IDs cannot call each other.\n     *\n     * You must call the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method to exit the current call before entering another channel.\n     *\n     * A successful [joinChannel]{@link AgoraRtcEngine.joinChannel} method call triggers the following callbacks:\n     * - The local client: [onJoinChannelSuccess]{@link AgoraRtcEvents.onJoinChannelSuccess}\n     * - The remote client: [onUserJoined]{@link AgoraRtcEvents.onUserJoined} , if the user joining the channel is in the `COMMUNICATION`\n     * profile, or is a host in the `LIVE_BROADCASTING` profile.\n     *\n     * When the connection between the client and Agora server is interrupted due to poor network conditions, the SDK tries reconnecting\n     * to the server. When the local client successfully rejoins the channel, the SDK triggers the\n     * [onRejoinChannelSuccess]{@link AgoraRtcEvents.onRejoinChannelSuccess} callback on the local client.\n     *\n     * @note A channel does not accept duplicate uids, such as two users with the same `uid`. If you set `uid` as 0, the system\n     * automatically assigns a `uid`. If you want to join a channel from different devices, ensure that each device has a different uid.\n     *\n     * @warning Ensure that the App ID used for creating the token is the same App ID used by the [init]{@link AgoraRtcEngine.init} method for\n     * initializing the Agora engine. Otherwise, the CDN live streaming may fail.\n     *\n     * @param token The token for authentication:\n     * - In situations not requiring high security: You can use the temporary token generated at Console. For details, see\n     * [Get a temporary token](https://docs.AgoraRtcEngine.io/en/Agora%20Platform/token?platform=All%20Platforms#get-a-temporary-token).\n     * - In situations requiring high security: Set it as the token generated at your server. For details, see\n     * [Get a token](https://docs.AgoraRtcEngine.io/en/Agora%20Platform/token?platform=All%20Platforms#generatetoken).\n     * @param channelId The unique channel name for the Agora RTC session in the string format smaller than 64 bytes.\n     * Supported characters:\n     * - All lowercase English letters: a to z.\n     * - All uppercase English letters: A to Z.\n     * - All numeric characters: 0 to 9.\n     * - The space character.\n     * - Punctuation characters and other symbols, including: \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\",\n     * \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \" {\", \"}\", \"|\", \"~\", \",\".\n     * @param info (Optional) The additional information about the channel. This parameter can be set to `null` or contain channel\n     * related information. Other users in the channel will not receive this message.\n     * @param uid (Optional) User ID. A 32-bit unsigned integer with a value ranging from 1 to 2<sup>32</sup>-1. The `uid` must be unique.\n     * If a `uid` is not assigned (or set to `0`), the SDK assigns and returns a `uid` in the\n     * [onJoinChannelSuccess]{@link AgoraRtcEvents.onJoinChannelSuccess} callback. Your application must record and maintain the returned\n     * `uid` since the SDK does not do so.\n     * @return\n     * - 0(ERR_OK): Success.\n     * - < 0: Failure.\n     *   - -2(ERR_INVALID_ARGUMENT): The parameter is invalid.\n     *   - -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n     */\n    function joinChannel(token, channelId, info, uid) {\n        if (info === void 0) { info = ''; }\n        if (uid === void 0) { uid = 0; }\n        return callNativeMethod(API_TYPE.JOIN_CHANNEL, {\n            token: token,\n            channelId: channelId,\n            info: info,\n            uid: uid,\n        });\n    }\n    AgoraRtcEngine.joinChannel = joinChannel;\n    /**\n     * Switches to a different channel.\n     *\n     * This method allows the audience of a `LIVE_BROADCASTING` channel to switch to a different channel.\n     *\n     * After the user successfully switches to another channel, the [onLeaveChannel]{@link AgoraRtcEvents.onLeaveChannel}\n     * and [onJoinChannelSuccess]{@link AgoraRtcEvents.onJoinChannelSuccess} callbacks are triggered to indicate that the\n     * user has left the original channel and joined a new one.\n     *\n     * @note This method applies to the audience role in a `LIVE_BROADCASTING` channel only.\n     *\n     * @param token The token for authentication:\n     * - In situations not requiring high security: You can use the temporary token generated at Console. For details, see\n     * [Get a temporary token](https://docs.AgoraRtcEngine.io/en/Agora%20Platform/token?platform=All%20Platforms#get-a-temporary-token).\n     * - In situations requiring high security: Set it as the token generated at your server. For details, see\n     * [Get a token](https://docs.AgoraRtcEngine.io/en/Agora%20Platform/token?platform=All%20Platforms#generatetoken).\n     * @param channelId The unique channel name for the Agora RTC session in the string format smaller than 64 bytes.\n     * Supported characters:\n     * - All lowercase English letters: a to z.\n     * - All uppercase English letters: A to Z.\n     * - All numeric characters: 0 to 9.\n     * - The space character.\n     * - Punctuation characters and other symbols, including: \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\",\n     * \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \" {\", \"}\", \"|\", \"~\", \",\".\n     *\n     * @return\n     * - 0(ERR_OK): Success.\n     * - < 0: Failure.\n     *  - -1(ERR_FAILED): A general error occurs (no specified reason).\n     *  - -2(ERR_INVALID_ARGUMENT): The parameter is invalid.\n     *  - -5(ERR_REFUSED): The request is rejected, probably because the user is not an audience.\n     *  - -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n     *  - -102(ERR_INVALID_CHANNEL_NAME): The channel name is invalid.\n     *  - -113(ERR_NOT_IN_CHANNEL): The user is not in the channel.\n     */\n    function switchChannel(token, channelId) {\n        return callNativeMethod(API_TYPE.SWITCH_CHANNEL, { token: token, channelId: channelId });\n    }\n    AgoraRtcEngine.switchChannel = switchChannel;\n    /**\n     * Allows a user to leave a channel, such as hanging up or exiting a call.\n     *\n     * After joining a channel, the user must call the `leaveChannel` method to end the call before joining another channel.\n     *\n     * This method returns `0` if the user leaves the channel and releases all resources related to the call.\n     *\n     * This method call is asynchronous, and the user has not left the channel when the method call returns. Once the user leaves the\n     * channel, the SDK triggers the [onLeaveChannel]{@link AgoraRtcEvents.onLeaveChannel} callback. A successful\n     * [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method call triggers the following callbacks:\n     * - The local client: [onLeaveChannel]{@link AgoraRtcEvents.onLeaveChannel}.\n     * - The remote client: [onUserOffline]{@link AgoraRtcEvents.onUserOffline}, if the user leaving the channel is in the\n     * `COMMUNICATION` channel, or is a host in the `LIVE_BROADCASTING` profile.\n     *\n     * **Note**\n     *\n     * - If you call the [release]{@link AgoraRtcEngine.release} method immediately after the `leaveChannel` method, the `leaveChannel` process\n     * interrupts, and the [onLeaveChannel]{@link AgoraRtcEvents.onLeaveChannel} callback is not triggered.\n     * - If you call the `leaveChannel` method during a CDN live streaming, the SDK triggers the\n     * [removePublishStreamUrl]{@link AgoraRtcEngine.removePublishStreamUrl} method.\n     *\n     * @return - 0(ERR_OK): Success.\n     * - < 0: Failure.\n     *   - -1(ERR_FAILED): A general error occurs (no specified reason).\n     *   - -2(ERR_INVALID_ARGUMENT): The parameter is invalid.\n     *   - -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n     */\n    function leaveChannel() {\n        return callNativeMethod(API_TYPE.LEAVE_CHANNEL);\n    }\n    AgoraRtcEngine.leaveChannel = leaveChannel;\n    /**\n     * Gets a new token when the current token expires after a period of time.\n     *\n     * The `token` expires after a period of time once the token schema is enabled when:\n     * - The SDK triggers the [onTokenPrivilegeWillExpire]{@link AgoraRtcEvents.onTokenPrivilegeWillExpire} callback, or\n     * - The [onConnectionStateChanged]{@link AgoraRtcEvents.onConnectionStateChanged} reports `CONNECTION_CHANGED_TOKEN_EXPIRED(9)`.\n     *\n     * The application should call this method to get the new `token`. Failure to do so will result in the SDK disconnecting from the\n     * server.\n     *\n     * @param token The new token.\n     *\n     * @return\n     * - 0(ERR_OK): Success.\n     * - < 0: Failure.\n     *   - -1(ERR_FAILED): A general error occurs (no specified reason).\n     *   - -2(ERR_INVALID_ARGUMENT): The parameter is invalid.\n     *   - -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n     */\n    function renewToken(token) {\n        return callNativeMethod(API_TYPE.RE_NEW_TOKEN, { token: token });\n    }\n    AgoraRtcEngine.renewToken = renewToken;\n    /**\n     * Registers a user account.\n     *\n     * Once registered, the user account can be used to identify the local user when the user joins the channel. After the user\n     * successfully registers a user account, the SDK triggers the\n     * [onLocalUserRegistered]{@link AgoraRtcEvents.onLocalUserRegistered} callback on the local client, reporting the user ID and\n     * user account of the local user.\n     *\n     * To join a channel with a user account, you can choose either of the following:\n     *\n     * - Call the `registerLocalUserAccount` method to create a user account, and then the\n     * [joinChannelWithUserAccount]{@link AgoraRtcEngine.joinChannelWithUserAccount} method to join the channel.\n     * - Call the `joinChannelWithUserAccount` method to join the channel.\n     *\n     * The difference between the two is that for the former, the time elapsed between calling the `joinChannelWithUserAccount` method\n     * and joining the channel is shorter than the latter.\n     *\n     * **Note**\n     *\n     * - Ensure that you set the `userAccount` parameter. Otherwise, this method does not take effect.\n     * - Ensure that the value of the `userAccount` parameter is unique in the channel.\n     * - To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel\n     * with a user ID, then ensure all the other users use the user ID too. The same applies to the user account. If a user joins\n     * the channel with the Agora Web SDK, ensure that the uid of the user is set to the same parameter type.\n     *\n     * @param appId The App ID of your project.\n     * @param userAccount The user account. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter\n     * and do not set it as `null`. Supported character scopes are:\n     * - All lowercase English letters: a to z.\n     * - All uppercase English letters: A to Z.\n     * - All numeric characters: 0 to 9.\n     * - The space character.\n     * - Punctuation characters and other symbols, including: \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\",\n     * \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \" {\", \"}\", \"|\", \"~\", \",\".\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function registerLocalUserAccount(appId, userAccount) {\n        return callNativeMethod(API_TYPE.REGISTER_LOCAL_USER_ACCOUNT, {\n            appId: appId,\n            userAccount: userAccount,\n        });\n    }\n    AgoraRtcEngine.registerLocalUserAccount = registerLocalUserAccount;\n    /**\n     * Joins the channel with a user account.\n     *\n     * After the user successfully joins the channel, the SDK triggers the following callbacks:\n     *\n     * - The local client: [onLocalUserRegistered]{@link AgoraRtcEvents.onLocalUserRegistered} and\n     * [onJoinChannelSuccess]{@link AgoraRtcEvents.onJoinChannelSuccess}.\n     * - The remote client: [onUserJoined]{@link AgoraRtcEvents.onUserJoined} and\n     * [onUserInfoUpdated]{@link AgoraRtcEvents.onUserInfoUpdated}, if the user joining the channel is in the `COMMUNICATION` profile, or\n     * is a host in the `LIVE_BROADCASTING` profile.\n     *\n     * **Note**\n     *\n     * - To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel\n     * with a user ID, then ensure all the other users use the user ID too. The same applies to the user account.\n     * - If a user joins the\n     * channel with the Agora Web SDK, ensure that the uid of the user is set to the same parameter type.\n     *\n     * @param token The token for authentication:\n     * - In situations not requiring high security: You can use the temporary token generated at Console. For details, see\n     * [Get a temporary token](https://docs.AgoraRtcEngine.io/en/Agora%20Platform/token?platform=All%20Platforms#get-a-temporary-token).\n     * - In situations requiring high security: Set it as the token generated at your server. For details, see\n     * [Get a token](https://docs.AgoraRtcEngine.io/en/Agora%20Platform/token?platform=All%20Platforms#generatetoken).\n     * @param channelId The channel name. The maximum length of this parameter is 64 bytes. Supported character scopes are:\n     * - All lowercase English letters: a to z.\n     * - All uppercase English letters: A to Z.\n     * - All numeric characters: 0 to 9.\n     * - The space character.\n     * - Punctuation characters and other symbols, including: \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\",\n     * \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \" {\", \"}\", \"|\", \"~\", \",\".\n     * @param userAccount The user account. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter\n     * and do not set it as `null`. Supported character scopes are:\n     * - All lowercase English letters: a to z.\n     * - All uppercase English letters: A to Z.\n     * - All numeric characters: 0 to 9.\n     * - The space character.\n     * - Punctuation characters and other symbols, including: \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\",\n     * \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \" {\", \"}\", \"|\", \"~\", \",\".\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     *   - -2(`ERR_INVALID_ARGUMENT`)\n     *   - -3(`ERR_NOT_READY`)\n     *   - -5(`ERR_REFUSED`)\n     */\n    function joinChannelWithUserAccount(token, channelId, userAccount) {\n        return callNativeMethod(API_TYPE.JOIN_CHANNEL_WITH_USER_ACCOUNT, {\n            token: token,\n            channelId: channelId,\n            userAccount: userAccount,\n        });\n    }\n    AgoraRtcEngine.joinChannelWithUserAccount = joinChannelWithUserAccount;\n    /**\n     * Gets the user information by passing in the user account.\n     *\n     * After a remote user joins the channel, the SDK gets the user ID and user account of the remote user, caches them\n     * in [UserInfo]{@link AgoraRtcEngine.UserInfo}, and triggers the\n     * [onUserInfoUpdated]{@link AgoraRtcEvents.onUserInfoUpdated}  callback on the local client.\n     *\n     * After receiving the [onUserInfoUpdated]{@link AgoraRtcEvents.onUserInfoUpdated} callback, you can call this method\n     * to get the user ID of the remote user from the `UserInfo` interface by passing in the user account.\n     *\n     * @param userAccount The user account of the user. Ensure that you set this parameter.\n     *\n     * @return A [UserInfo]{@link AgoraRtcEngine.UserInfo} interface that identifies the user.\n     */\n    function getUserInfoByUserAccount(userAccount) {\n        return callNativeMethod(API_TYPE.GET_USER_INFO_BY_USER_ACCOUNT, {\n            userAccount: userAccount,\n        });\n    }\n    AgoraRtcEngine.getUserInfoByUserAccount = getUserInfoByUserAccount;\n    /**\n     * Gets the user information by passing in the user ID.\n     *\n     * After a remote user joins the channel, the SDK gets the user ID and user account of the remote user,\n     * caches [UserInfo]{@link AgoraRtcEngine.UserInfo}, and triggers the\n     * [onUserInfoUpdated]{@link AgoraRtcEvents.onUserInfoUpdated} callback on the local client.\n     *\n     * After receiving the [onUserInfoUpdated]{@link AgoraRtcEvents.onUserInfoUpdated} callback, you can call this method\n     * to get the user account of the remote user from the `UserInfo` interface by passing in the user ID.\n     *\n     * @param uid The user ID of the remote user. Ensure that you set this parameter.\n     *\n     * @return A [UserInfo]{@link AgoraRtcEngine.UserInfo} interface that identifies the user.\n     */\n    function getUserInfoByUid(uid) {\n        return callNativeMethod(API_TYPE.GET_USER_INFO_BY_UID, { uid: uid });\n    }\n    AgoraRtcEngine.getUserInfoByUid = getUserInfoByUid;\n    /**\n     * Starts an audio call test.\n     *\n     * This method starts an audio call test to determine whether the audio devices (for example, headset and speaker)\n     * and the network connection are working properly.\n     *\n     * In the audio call test, you record your voice. If the recording plays back within the set time interval, the\n     * audio devices and the network connection are working properly.\n     *\n     * **Note**\n     *\n     * - Call this method before joining a channel.\n     * - After calling this method, call the [stopEchoTest]{@link AgoraRtcEngine.stopEchoTest} method to end the test.\n     * Otherwise, the app cannot run the next echo test, or call the [joinChannel]{@link AgoraRtcEngine.joinChannel} method.\n     * - In the `LIVE_BROADCASTING` profile, only a host can call this method.\n     *\n     * @param intervalInSeconds The time interval (s) between when you speak and when the recording plays back.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function startEchoTest(intervalInSeconds) {\n        if (intervalInSeconds === undefined) {\n            return callNativeMethod(API_TYPE.START_ECHO_TEST);\n        }\n        return callNativeMethod(API_TYPE.START_ECHO_TEST_2, { intervalInSeconds: intervalInSeconds });\n    }\n    AgoraRtcEngine.startEchoTest = startEchoTest;\n    /**\n     * Stops the audio call test.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function stopEchoTest() {\n        return callNativeMethod(API_TYPE.STOP_ECHO_TEST);\n    }\n    AgoraRtcEngine.stopEchoTest = stopEchoTest;\n    /**\n     * Enables the video module.\n     *\n     * Call this method either before joining a channel or during a call. If this method is called before joining a\n     * channel, the call starts in the video mode. If this method is called during an audio call, the audio mode\n     * switches to the video mode. To disable the video module, call the [disableVideo]{@link AgoraRtcEngine.disableVideo} method.\n     *\n     * A successful [enableVideo]{@link AgoraRtcEngine.enableVideo} method call triggers the\n     * [onUserEnableVideo]{@link AgoraRtcEvents.onUserEnableVideo}(true) callback on the remote client.\n     *\n     * **Note**\n     *\n     * - This method affects the internal engine and can be called after the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method.\n     * - This method resets the internal engine and takes some time to take effect. We recommend using the following\n     * API methods to control the video engine modules separately:\n     *   - [enableLocalVideo]{@link AgoraRtcEngine.enableLocalVideo}: Whether to enable the camera to create the local video stream.\n     *   - [muteLocalVideoStream]{@link AgoraRtcEngine.muteLocalVideoStream}: Whether to publish the local video stream.\n     *   - [muteRemoteVideoStream]{@link AgoraRtcEngine.muteRemoteVideoStream}: Whether to subscribe to and play the remote video stream.\n     *   - [muteAllRemoteVideoStreams]{@link AgoraRtcEngine.muteAllRemoteVideoStreams}: Whether to subscribe to and play all remote video streams.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableVideo() {\n        return callNativeMethod(API_TYPE.ENABLE_VIDEO);\n    }\n    AgoraRtcEngine.enableVideo = enableVideo;\n    /**\n     * Disables the video module.\n     *\n     * This method can be called before joining a channel or during a call. If this method is called before joining a\n     * channel, the call starts in audio mode. If this method is called during a video call, the video mode switches\n     * to the audio mode. To enable the video module, call the [enableVideo]{@link AgoraRtcEngine.enableVideo} method.\n     *\n     * A successful [disableVideo]{@link AgoraRtcEngine.disableVideo} method call triggers the\n     * [onUserEnableVideo]{@link AgoraRtcEvents.onUserEnableVideo} (false) callback on the remote client.\n     *\n     * **Note**\n     *\n     * - This method affects the internal engine and can be called after the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method.\n     * - This method resets the internal engine and takes some time to take effect. We recommend using the following API\n     * methods to control the video engine modules separately:\n     *   - [enableLocalVideo]{@link AgoraRtcEngine.enableLocalVideo} : Whether to enable the camera to create the local video stream.\n     *   - [muteLocalVideoStream]{@link AgoraRtcEngine.muteLocalVideoStream} : Whether to publish the local video stream.\n     *   - [muteRemoteVideoStream]{@link AgoraRtcEngine.muteRemoteVideoStream} : Whether to subscribe to and play the remote video stream.\n     *   - [muteAllRemoteVideoStreams]{@link AgoraRtcEngine.muteAllRemoteVideoStreams} : Whether to subscribe to and play all remote video streams.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function disableVideo() {\n        return callNativeMethod(API_TYPE.DISABLE_VIDEO);\n    }\n    AgoraRtcEngine.disableVideo = disableVideo;\n    /**\n     * Sets the video profile.\n     *\n     * @deprecated This method is deprecated. Use the [setVideoEncoderConfiguration]{@link AgoraRtcEngine.setVideoEncoderConfiguration}\n     * method instead.\n     *\n     * Each video profile includes a set of parameters, such as the resolution, frame rate, and bitrate. If the camera\n     * device does not support the specified resolution, the SDK automatically chooses a suitable camera resolution,\n     * keeping the encoder resolution specified by the `setVideoProfile` method.\n     *\n     * **Note**\n     *\n     * - If you do not need to set the video profile after joining the channel, call this method before the\n     * [enableVideo]{@link AgoraRtcEngine.enableVideo} method to reduce the render time of the first video frame.\n     * - Always set the video profile before calling the [joinChannel]{@link AgoraRtcEngine.joinChannel} or\n     * [startPreview]{@link AgoraRtcEngine.startPreview} method.\n     *\n     * @param profile Sets the video profile. See [VIDEO_PROFILE_TYPE]{@link AgoraRtcEngine.VIDEO_PROFILE_TYPE}.\n     * @param swapWidthAndHeight Sets whether to swap the width and height of the video stream:\n     * - true: Swap the width and height.\n     * - false: (Default) Do not swap the width and height.\n     * The width and height of the output video are consistent with the set video profile.\n     *\n     * @note Since the landscape or portrait mode of the output video can be decided directly by the video profile,\n     * We recommend setting `swapWidthAndHeight` to `false` (default).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setVideoProfile(profile, swapWidthAndHeight) {\n        return callNativeMethod(API_TYPE.SET_VIDEO_PROFILE, {\n            profile: profile,\n            swapWidthAndHeight: swapWidthAndHeight,\n        });\n    }\n    AgoraRtcEngine.setVideoProfile = setVideoProfile;\n    /**\n     * Sets the video encoder configuration.\n     *\n     * Each video encoder configuration corresponds to a set of video parameters, including the resolution, frame rate,\n     * bitrate, and video orientation.\n     *\n     * The parameters specified in this method are the maximum values under ideal network conditions. If the video\n     * engine cannot render the video using the specified parameters due to poor network conditions, the parameters\n     * further down the list are considered until a successful configuration is found.\n     *\n     * @note If you do not need to set the video encoder configuration after joining the channel, you can call this\n     * method before the [enableVideo]{@link AgoraRtcEngine.enableVideo} method to reduce the render time of the first video frame.\n     *\n     * @param config Sets the local video encoder configuration. See\n     * [VideoEncoderConfiguration]{@link AgoraRtcEngine.VideoEncoderConfiguration}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setVideoEncoderConfiguration(config) {\n        return callNativeMethod(API_TYPE.SET_VIDEO_ENCODER_CONFIGURATION, {\n            config: config,\n        });\n    }\n    AgoraRtcEngine.setVideoEncoderConfiguration = setVideoEncoderConfiguration;\n    /**\n     * Sets the camera capture configuration.\n     *\n     * For a video call or the live interactive video streaming, generally the SDK controls the camera output\n     * parameters. When the default camera capturer settings do not meet special requirements or cause performance\n     * problems, we recommend using this method to set the camera capturer configuration:\n     * - If the resolution or frame rate of the captured raw video data are higher than those set by\n     * [setVideoEncoderConfiguration]{@link AgoraRtcEngine.setVideoEncoderConfiguration}, processing video frames requires\n     * extra CPU and RAM usage and degrades performance. We recommend setting `config` as\n     * `CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE(1)` to avoid such problems.\n     * - If you do not need local video preview or are willing to sacrifice preview quality, we recommend setting\n     * `config` as `CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE(1)` to optimize CPU and RAM usage.\n     * - If you want better quality for the local video preview, we recommend setting config as\n     * `CAPTURER_OUTPUT_PREFERENCE_PREVIEW(2)`.\n     *\n     * @note Call this method before enabling the local camera. That said, you can call this method before calling\n     * [joinChannel]{@link AgoraRtcEngine.joinChannel}, [enableVideo]{@link AgoraRtcEngine.enableVideo}, or\n     * [enableLocalVideo]{@link AgoraRtcEngine.enableLocalVideo}, depending on which method you use to turn on your local camera.\n     *\n     * @param config Sets the camera capturer configuration. See\n     * [CameraCapturerConfiguration]{@link AgoraRtcEngine.CameraCapturerConfiguration}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setCameraCapturerConfiguration(config) {\n        return callNativeMethod(API_TYPE.SET_CAMERA_CAPTURER_CONFIGURATION, {\n            config: config,\n        });\n    }\n    AgoraRtcEngine.setCameraCapturerConfiguration = setCameraCapturerConfiguration;\n    /**\n     * TODO\n     *\n     * @param canvas\n     */\n    function setupLocalVideo(canvas) {\n        var yuvCanvas = YUVCanvas.attach(canvas, { webGL: false });\n        requestAnimationFrame(draw);\n        function draw() {\n            if (!canvas.isConnected)\n                return;\n            // @ts-ignore\n            var buffer = window.bufferMap[0];\n            if (!buffer) {\n                requestAnimationFrame(draw);\n                return;\n            }\n            var format = YUVBuffer.format({\n                width: buffer.width,\n                height: buffer.height,\n                chromaWidth: buffer.width / 2,\n                chromaHeight: buffer.height / 2,\n            });\n            var frame = YUVBuffer.frame(format, {\n                bytes: new Uint8Array(new Uint8Array(buffer.yBuffer)),\n                stride: buffer.yStride,\n            }, {\n                bytes: new Uint8Array(new Uint8Array(buffer.uBuffer)),\n                stride: buffer.uStride,\n            }, {\n                bytes: new Uint8Array(new Uint8Array(buffer.vBuffer)),\n                stride: buffer.vStride,\n            });\n            yuvCanvas.drawFrame(frame);\n            requestAnimationFrame(draw);\n        }\n    }\n    AgoraRtcEngine.setupLocalVideo = setupLocalVideo;\n    /**\n     * TODO\n     *\n     * @param canvas\n     * @param uid\n     */\n    function setupRemoteVideo(canvas, uid) {\n        var yuvCanvas = YUVCanvas.attach(canvas, { webGL: false });\n        requestAnimationFrame(draw);\n        function draw() {\n            if (!canvas.isConnected)\n                return;\n            // @ts-ignore\n            var buffer = window.bufferMap[uid];\n            if (!buffer) {\n                requestAnimationFrame(draw);\n                return;\n            }\n            var format = YUVBuffer.format({\n                width: buffer.width,\n                height: buffer.height,\n                chromaWidth: buffer.width / 2,\n                chromaHeight: buffer.height / 2,\n            });\n            var frame = YUVBuffer.frame(format, {\n                bytes: new Uint8Array(new Uint8Array(buffer.yBuffer)),\n                stride: buffer.yStride,\n            }, {\n                bytes: new Uint8Array(new Uint8Array(buffer.uBuffer)),\n                stride: buffer.uStride,\n            }, {\n                bytes: new Uint8Array(new Uint8Array(buffer.vBuffer)),\n                stride: buffer.vStride,\n            });\n            yuvCanvas.drawFrame(frame);\n            requestAnimationFrame(draw);\n        }\n    }\n    AgoraRtcEngine.setupRemoteVideo = setupRemoteVideo;\n    /**\n     * Starts the local video preview before joining the channel.\n     *\n     * Before calling this method, you must call the [enableVideo]{@link AgoraRtcEngine.enableVideo} method to enable video.\n     *\n     * @note Once the `startPreview` method is called to start the local video preview, if you leave the channel by\n     * calling the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method, the local video preview remains until you call\n     * the [stopPreview]{@link AgoraRtcEngine.stopPreview} method to disable it.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function startPreview() {\n        return callNativeMethod(API_TYPE.START_PREVIEW);\n    }\n    AgoraRtcEngine.startPreview = startPreview;\n    /**\n     * Prioritizes a remote user's stream.\n     *\n     * Use this method with the [setRemoteSubscribeFallbackOption]{@link AgoraRtcEngine.setRemoteSubscribeFallbackOption} method.\n     * If the fallback function is enabled for a subscribed stream, the SDK ensures the high-priority user gets the\n     * best possible stream quality.\n     *\n     * @note The Agora SDK supports setting `userPriority` as `PRIORITY_HIGH` for one user only.\n     *\n     * @param uid The ID of the remote user.\n     * @param userPriority Sets the priority of the remote user. See [PRIORITY_TYPE]{@link AgoraRtcEngine.PRIORITY_TYPE}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setRemoteUserPriority(uid, userPriority) {\n        return callNativeMethod(API_TYPE.SET_REMOTE_USER_PRIORITY, {\n            uid: uid,\n            userPriority: userPriority,\n        });\n    }\n    AgoraRtcEngine.setRemoteUserPriority = setRemoteUserPriority;\n    /**\n     * Stops the local video preview and disables video.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function stopPreview() {\n        return callNativeMethod(API_TYPE.STOP_PREVIEW);\n    }\n    AgoraRtcEngine.stopPreview = stopPreview;\n    /**\n     * Enables the audio module.\n     *\n     * The audio mode is enabled by default.\n     *\n     * **Note**\n     *\n     * - This method affects the internal engine and can be called after the [leaveChannel]{@link AgoraRtcEngine.leaveChannel}\n     * method. You can call this method either before or after joining a channel.\n     * - This method resets the internal engine and takes some time to take effect. We recommend using the following\n     * API methods to control the audio engine modules separately:\n     *   - [enableLocalAudio]{@link AgoraRtcEngine.enableLocalAudio}: Whether to enable the microphone to create the local audio stream.\n     *   - [muteLocalAudioStream]{@link AgoraRtcEngine.muteLocalAudioStream}: Whether to publish the local audio stream.\n     *   - [muteRemoteAudioStream]{@link AgoraRtcEngine.muteRemoteAudioStream}: Whether to subscribe to and play the remote audio stream.\n     *   - [muteAllRemoteAudioStreams]{@link AgoraRtcEngine.muteAllRemoteAudioStreams}: Whether to subscribe to and play all remote audio streams.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableAudio() {\n        return callNativeMethod(API_TYPE.ENABLE_AUDIO);\n    }\n    AgoraRtcEngine.enableAudio = enableAudio;\n    /**\n     * Disables/Re-enables the local audio function.\n     *\n     * The audio function is enabled by default. This method disables or re-enables the local audio function, that is,\n     * to stop or restart local audio capturing.\n     *\n     * This method does not affect receiving or playing the remote audio streams,and `enableLocalAudio(false)` is\n     * applicable to scenarios where the user wants to receive remote audio streams without sending any audio stream to\n     * other users in the channel.\n     *\n     * Once the local audio function is disabled or re-enabled, the SDK triggers the\n     * [onLocalAudioStateChanged]{@link AgoraRtcEvents.onLocalAudioStateChanged} callback, which reports\n     * `LOCAL_AUDIO_STREAM_STATE_STOPPED(0)` or `LOCAL_AUDIO_STREAM_STATE_RECORDING(1)`.\n     *\n     * **Note**\n     *\n     * This method is different from the [muteLocalAudioStream]{@link AgoraRtcEngine.muteLocalAudioStream} method:\n     *   - `enableLocalAudio: Disables/Re-enables the local audio capturing and processing. If you disable or re-enable\n     * local audio recording using the `enableLocalAudio` method, the local user may hear a pause in the remote audio\n     * playback.\n     *   - [muteLocalAudioStream]{@link AgoraRtcEngine.muteLocalAudioStream}: Sends/Stops sending the local audio streams.\n     *\n     * @param enabled Sets whether to disable/re-enable the local audio function:\n     * - true: (Default) Re-enable the local audio function, that is, to start the local audio capturing device\n     * (for example, the microphone).\n     * - false: Disable the local audio function, that is, to stop local audio capturing.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableLocalAudio(enabled) {\n        return callNativeMethod(API_TYPE.ENABLE_LOCAL_AUDIO, { enabled: enabled });\n    }\n    AgoraRtcEngine.enableLocalAudio = enableLocalAudio;\n    /**\n     * Disables the audio module.\n     *\n     * **Note**\n     *\n     * - This method affects the internal engine and can be called after the [leaveChannel]{@link AgoraRtcEngine.leaveChannel}\n     * method. You can call this method either before or after joining a channel.\n     * - This method resets the internal engine and takes some time to take effect. We recommend using the\n     * [enableLocalAudio]{@link AgoraRtcEngine.enableLocalAudio} and [muteLocalAudioStream]{@link AgoraRtcEngine.muteLocalAudioStream}\n     * methods to capture, process, and send the local audio streams.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function disableAudio() {\n        return callNativeMethod(API_TYPE.DISABLE_AUDIO);\n    }\n    AgoraRtcEngine.disableAudio = disableAudio;\n    /**\n     * Sets the audio parameters and application scenarios.\n     *\n     * **Note**\n     *\n     * - The `setAudioProfile` method must be called before the [joinChannel]{@link AgoraRtcEngine.joinChannel} method.\n     * - In the `COMMUNICATION` and `LIVE_BROADCASTING` profiles, the bitrate may be different from your settings due\n     * to network self-adaptation.\n     * - In scenarios requiring high-quality audio, for example, a music teaching scenario, we recommend setting\n     * `profile` as `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` and `scenario` as `AUDIO_SCENARIO_GAME_STREAMING(3)`.\n     *\n     * @param  profile Sets the sample rate, bitrate, encoding mode, and the number of channels. See\n     * [AUDIO_PROFILE_TYPE]{@link AgoraRtcEngine.AUDIO_PROFILE_TYPE}.\n     * @param  scenario Sets the audio application scenario. See [AUDIO_SCENARIO_TYPE]{@link AgoraRtcEngine.AUDIO_SCENARIO_TYPE}.\n     * Under different audio scenarios, the device uses different volume tracks, i.e. either the in-call volume or\n     * the media volume. For details, see\n     * [What is the difference between the in-call volume and the media volume?](https://docs.AgoraRtcEngine.io/en/faq/system_volume).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setAudioProfile(profile, scenario) {\n        return callNativeMethod(API_TYPE.SET_AUDIO_PROFILE, { profile: profile, scenario: scenario });\n    }\n    AgoraRtcEngine.setAudioProfile = setAudioProfile;\n    /**\n     * Stops/Resumes sending the local audio stream.\n     *\n     * A successful `muteLocalAudioStream` method call triggers the [onUserMuteAudio]{@link AgoraRtcEvents.onUserMuteAudio}\n     * callback on the remote client.\n     *\n     * **Note**\n     *\n     * - When `mute` is set as `true`, this method does not disable the microphone, which does not affect any ongoing recording.\n     * - If you call [setChannelProfile]{@link AgoraRtcEngine.setChannelProfile} after this method, the SDK resets whether or not to mute\n     * the local audio according to the channel profile and user role. Therefore, we recommend calling this method after the\n     * `setChannelProfile` method.\n     *\n     * @param mute Sets whether to send or stop sending the local audio stream:\n     * - true: Stops sending the local audio stream.\n     * - false: (Default) Sends the local audio stream.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function muteLocalAudioStream(mute) {\n        return callNativeMethod(API_TYPE.MUTE_LOCAL_AUDIO_STREAM, { mute: mute });\n    }\n    AgoraRtcEngine.muteLocalAudioStream = muteLocalAudioStream;\n    /**\n     * Stops/Resumes receiving all remote users' audio streams.\n     *\n     * @param mute Sets whether to receive or stop receiving all remote users' audio streams.\n     * - true: Stops receiving all remote users' audio streams.\n     * - false: (Default) Receives all remote users' audio streams.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function muteAllRemoteAudioStreams(mute) {\n        return callNativeMethod(API_TYPE.MUTE_ALL_REMOTE_AUDIO_STREAMS, { mute: mute });\n    }\n    AgoraRtcEngine.muteAllRemoteAudioStreams = muteAllRemoteAudioStreams;\n    /**\n     * Stops/Resumes receiving all remote users' audio streams by default.\n     *\n     * You can call this method either before or after joining a channel. If you call `setDefaultMuteAllRemoteAudioStreams (true)`\n     * after joining a channel, the remote audio streams of all subsequent users are not received.\n     *\n     * @note If you want to resume receiving the audio stream, call [muteRemoteAudioStream(false)]{@link AgoraRtcEngine.muteRemoteAudioStream},\n     * and specify the ID of the remote user whose audio stream you want to receive. To receive the audio streams of multiple remote\n     * users, call `muteRemoteAudioStream(false)` as many times. Calling `setDefaultMuteAllRemoteAudioStreams (false)` resumes\n     * receiving the audio streams of subsequent users only.\n     *\n     * @param mute Sets whether to receive/stop receiving all remote users' audio streams by default:\n     * - true:  Stops receiving all remote users' audio streams by default.\n     * - false: (Default) Receives all remote users' audio streams by default.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setDefaultMuteAllRemoteAudioStreams(mute) {\n        return callNativeMethod(API_TYPE.SET_DEFAULT_MUTE_ALL_REMOTE_AUDIO_STREAMS, { mute: mute });\n    }\n    AgoraRtcEngine.setDefaultMuteAllRemoteAudioStreams = setDefaultMuteAllRemoteAudioStreams;\n    /**\n     * Adjusts the playback volume of a specified remote user.\n     *\n     * You can call this method as many times as necessary to adjust the playback volume of different remote users, or to\n     * repeatedly adjust the playback volume of the same remote user.\n     *\n     * **Note**\n     *\n     * - Call this method after joining a channel.\n     * - The playback volume here refers to the mixed volume of a specified remote user.\n     * - This method can only adjust the playback volume of one specified remote user at a time. To adjust the playback volume of\n     * different remote users, call the method as many times, once for each remote user.\n     *\n     * @param uid The ID of the remote user.\n     * @param volume The playback volume of the specified remote user. The value ranges from 0 to 100:\n     * - 0: Mute.\n     * - 100: Original volume.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function adjustUserPlaybackSignalVolume(uid, volume) {\n        return callNativeMethod(API_TYPE.ADJUST_USER_PLAYBACK_SIGNAL_VOLUME, {\n            uid: uid,\n            volume: volume,\n        });\n    }\n    AgoraRtcEngine.adjustUserPlaybackSignalVolume = adjustUserPlaybackSignalVolume;\n    /**\n     * Stops/Resumes receiving a specified remote user's audio stream.\n     *\n     * @note If you called the [muteAllRemoteAudioStreams]{@link AgoraRtcEngine.muteAllRemoteAudioStreams} method and set `mute`\n     * as `true` to stop receiving all remote users' audio streams, call the `muteAllRemoteAudioStreams` method and set\n     * `mute` as `false` before calling this method. The `muteAllRemoteAudioStreams` method sets all remote audio\n     * streams, while the `muteAllRemoteAudioStreams` method sets a specified remote audio stream.\n     *\n     * @param userId User ID of the specified remote user sending the audio.\n     * @param mute Sets whether to receive/stop receiving a specified remote user's audio stream:\n     * - true: Stops receiving the specified remote user's audio stream.\n     * - false: (Default) Receives the specified remote user's audio stream.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function muteRemoteAudioStream(userId, mute) {\n        return callNativeMethod(API_TYPE.MUTE_REMOTE_AUDIO_STREAM, {\n            userId: userId,\n            mute: mute,\n        });\n    }\n    AgoraRtcEngine.muteRemoteAudioStream = muteRemoteAudioStream;\n    /**\n     * Stops/Resumes sending the local video stream.\n     *\n     * A successful `muteLocalVideoStream` method call triggers the\n     * [onUserMuteVideo]{@link AgoraRtcEvents.onUserMuteVideo} callback on the remote client.\n     *\n     * **Note**\n     *\n     * - When set to `true`, this method does not disable the camera which does not affect the retrieval of the local\n     * video streams. This method executes faster than the [enableLocalVideo]{@link AgoraRtcEngine.enableLocalVideo} method\n     * which controls the sending of the local video stream.\n     * - If you call [setChannelProfile]{@link AgoraRtcEngine.setChannelProfile} after this method, the SDK resets whether or\n     * not to mute the local video according to the channel profile and user role. Therefore, we recommend calling\n     * this method after the `setChannelProfile` method.\n     *\n     * @param mute Sets whether to send/stop sending the local video stream:\n     * - true: Stop sending the local video stream.\n     * - false: (Default) Send the local video stream.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function muteLocalVideoStream(mute) {\n        return callNativeMethod(API_TYPE.MUTE_LOCAL_VIDEO_STREAM, { mute: mute });\n    }\n    AgoraRtcEngine.muteLocalVideoStream = muteLocalVideoStream;\n    /**\n     * Enables/Disables the local video capture.\n     *\n     * This method disables or re-enables the local video capturer, and does not affect receiving the remote video stream.\n     *\n     * After you call the [enableVideo]{@link AgoraRtcEngine.enableVideo} method, the local video capturer is enabled by default.\n     * You can call `enableLocalVideo(false)` to disable the local video capturer. If you want to re-enable it, call\n     * `[enableLocalVideo(true)`.\n     *\n     * After the local video capturer is successfully disabled or re-enabled, the SDK triggers the\n     * [onUserEnableLocalVideo]{@link AgoraRtcEvents.onUserEnableLocalVideo} callback on the remote client.\n     *\n     * @note This method affects the internal engine and can be called after the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method.\n     *\n     * @param enabled Sets whether to disable/re-enable the local video, including the capturer, renderer, and sender:\n     * - true: (Default) Re-enable the local video.\n     * - false: Disable the local video. Once the local video is disabled, the remote users can no longer receive the\n     * video stream of this user, while this user can still receive the video streams of the other remote users.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableLocalVideo(enabled) {\n        return callNativeMethod(API_TYPE.ENABLE_LOCAL_VIDEO, { enabled: enabled });\n    }\n    AgoraRtcEngine.enableLocalVideo = enableLocalVideo;\n    /**\n     * Stops/Resumes receiving all video stream from a specified remote user.\n     *\n     * @param  mute Sets whether to receive/stop receiving all remote users' video streams:\n     * - true: Stop receiving all remote users' video streams.\n     * - false: (Default) Receive all remote users' video streams.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function muteAllRemoteVideoStreams(mute) {\n        return callNativeMethod(API_TYPE.MUTE_ALL_REMOTE_VIDEO_STREAMS, { mute: mute });\n    }\n    AgoraRtcEngine.muteAllRemoteVideoStreams = muteAllRemoteVideoStreams;\n    /**\n     * Stops/Resumes receiving all remote users' video streams by default.\n     *\n     * You can call this method either before or after joining a channel. If you call `setDefaultMuteAllRemoteVideoStreams (true)`\n     * after joining a channel, the remote video streams of all subsequent users are not received.\n     *\n     * @note If you want to resume receiving the video stream, call [muteRemoteVideoStream(false)]{@link AgoraRtcEngine.muteRemoteVideoStream},\n     * and specify the ID of the remote user whose video stream you want to receive. To receive the video streams of multiple\n     * remote users, call `muteRemoteVideoStream(false)` as many times. Calling `setDefaultMuteAllRemoteVideoStreams(false)`\n     * resumes receiving the video streams of subsequent users only.\n     *\n     * @param mute Sets whether to receive/stop receiving all remote users' video streams by default:\n     * - true: Stop receiving all remote users' video streams by default.\n     * - false: (Default) Receive all remote users' video streams by default.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setDefaultMuteAllRemoteVideoStreams(mute) {\n        return callNativeMethod(API_TYPE.SET_DEFAULT_MUTE_ALL_REMOTE_VIDEO_STREAMS, { mute: mute });\n    }\n    AgoraRtcEngine.setDefaultMuteAllRemoteVideoStreams = setDefaultMuteAllRemoteVideoStreams;\n    /**\n     * Stops/Resumes receiving the video stream from a specified remote user.\n     *\n     * @note If you called the [muteAllRemoteVideoStreams]{@link AgoraRtcEngine.muteAllRemoteVideoStreams} method and set `mute`\n     * as `true` to stop receiving all remote video streams, call the `muteAllRemoteVideoStreams` method and set `mute`\n     * as `false` before calling this method.\n     *\n     * @param userId User ID of the specified remote user.\n     * @param mute Sets whether to stop/resume receiving the video stream from a specified remote user:\n     * - true: Stop receiving the specified remote user's video stream.\n     * - false: (Default) Receive the specified remote user's video stream.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function muteRemoteVideoStream(userId, mute) {\n        return callNativeMethod(API_TYPE.MUTE_REMOTE_VIDEO_STREAM, {\n            userId: userId,\n            mute: mute,\n        });\n    }\n    AgoraRtcEngine.muteRemoteVideoStream = muteRemoteVideoStream;\n    /**\n     * Sets the stream type of the remote video.\n     *\n     * Under limited network conditions, if the publisher has not disabled the dual-stream mode using `enableDualStreamMode(false)`,\n     * the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or\n     * the low-video stream (the low resolution, and low bitrate video stream).\n     *\n     * By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream.\n     * This method allows the app to adjust the corresponding video stream type based on the size of the video window to\n     * reduce the bandwidth and resources.\n     *\n     * The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality\n     * video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n     *\n     * The method result returns in the [onApiCallExecuted]{@link AgoraRtcEvents.onApiCallExecuted} callback.\n     *\n     * @param userId ID of the remote user sending the video stream.\n     * @param streamType  Sets the video-stream type. See [REMOTE_VIDEO_STREAM_TYPE]{@link AgoraRtcEngine.REMOTE_VIDEO_STREAM_TYPE}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setRemoteVideoStreamType(userId, streamType) {\n        return callNativeMethod(API_TYPE.SET_REMOTE_VIDEO_STREAM_TYPE, {\n            userId: userId,\n            streamType: streamType,\n        });\n    }\n    AgoraRtcEngine.setRemoteVideoStreamType = setRemoteVideoStreamType;\n    /**\n     * Sets the default stream type of remote videos.\n     *\n     * Under limited network conditions, if the publisher has not disabled the dual-stream mode using `enableDualStreamMode(false)`,\n     * the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or\n     * the low-video stream (the low resolution, and low bitrate video stream).\n     *\n     * By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream.\n     *\n     * This method allows the app to adjust the corresponding video stream type based on the size of the video window to\n     * reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream.\n     * Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate,\n     * and bitrate of the low-video stream.\n     *\n     * The method result returns in the [onApiCallExecuted]{@link AgoraRtcEvents.onApiCallExecuted} callback.\n     *\n     * @param streamType Sets the default video-stream type. See [REMOTE_VIDEO_STREAM_TYPE]{@link AgoraRtcEngine.REMOTE_VIDEO_STREAM_TYPE}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setRemoteDefaultVideoStreamType(streamType) {\n        return callNativeMethod(API_TYPE.SET_REMOTE_DEFAULT_VIDEO_STREAM_TYPE, {\n            streamType: streamType,\n        });\n    }\n    AgoraRtcEngine.setRemoteDefaultVideoStreamType = setRemoteDefaultVideoStreamType;\n    /**\n     * Enables the [onAudioVolumeIndication]{@link AgoraRtcEvents.onAudioVolumeIndication} callback at a set time interval\n     * to report on which users are speaking and the speakers' volume.\n     *\n     * Once this method is enabled, the SDK returns the volume indication in the\n     * [onAudioVolumeIndication]{@link AgoraRtcEvents.onAudioVolumeIndication} callback at the set time interval, whether\n     * or not any user is speaking in the channel.\n     *\n     * @param interval Sets the time interval between two consecutive volume indications:\n     * - &le; 0: Disables the volume indication.\n     * - &gt; 0: Time interval (ms) between two consecutive volume indications. We recommend setting `interval` &gt; 200 ms.\n     * Do not set `interval` &lt; 10 ms, or the `onAudioVolumeIndication` callback will not be triggered.\n     * @param smooth  Smoothing factor sets the sensitivity of the audio volume indicator. The value ranges between\n     * 0 and 10. The greater the value, the more sensitive the indicator. The recommended value is 3.\n     * @param report_vad - true: Enable the voice activity detection of the local user. Once it is enabled, the `vad`\n     * parameter of the `onAudioVolumeIndication` callback reports the voice activity status of the local user.\n     * - false: (Default) Disable the voice activity detection of the local user. Once it is disabled, the `vad`\n     * parameter of the `onAudioVolumeIndication` callback does not report the voice activity status of the local user,\n     * except for the scenario where the engine automatically detects the voice activity of the local user.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableAudioVolumeIndication(interval, smooth, report_vad) {\n        return callNativeMethod(API_TYPE.ENABLE_AUDIO_VOLUME_INDICATION, {\n            interval: interval,\n            smooth: smooth,\n            report_vad: report_vad,\n        });\n    }\n    AgoraRtcEngine.enableAudioVolumeIndication = enableAudioVolumeIndication;\n    /**\n     * Starts an audio recording on the client.\n     *\n     * The SDK allows recording during a call. After successfully calling this method, you can record the audio of all\n     * the users in the channel and get an audio recording file.\n     *\n     * Supported formats of the recording file are as follows:\n     * - .wav: Large file size with high fidelity.\n     * - .aac: Small file size with low fidelity.\n     *\n     * **Note**\n     *\n     * - Ensure that the directory you use to save the recording file exists and is writable.\n     * - This method is usually called after the `joinChannel` method. The recording automatically stops when you call\n     * the `leaveChannel` method.\n     * - For better recording effects, set quality as\n     * [AUDIO_RECORDING_QUALITY_MEDIUM]{@link AgoraRtcEngine.AUDIO_RECORDING_QUALITY_TYPE.AUDIO_RECORDING_QUALITY_MEDIUM} or\n     * [AUDIO_RECORDING_QUALITY_HIGH]{@link AgoraRtcEngine.AUDIO_RECORDING_QUALITY_TYPE.AUDIO_RECORDING_QUALITY_HIGH} when\n     * `sampleRate` is 44.1 kHz or 48 kHz.\n     *\n     * @param filePath The absolute file path of the recording file. The string of the file name is in UTF-8, such as\n     * /dir1/dir2/dir3/audio.aac.\n     * @param quality Sets the audio recording quality. See\n     * [AUDIO_RECORDING_QUALITY_TYPE]{@link AgoraRtcEngine.AUDIO_RECORDING_QUALITY_TYPE}.\n     * @param sampleRate Sample rate (Hz) of the recording file. Supported values are as follows:\n     * - 16000\n     * - (Default) 32000\n     * - 44100\n     * - 48000\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function startAudioRecording(filePath, quality, sampleRate) {\n        if (sampleRate === undefined) {\n            return callNativeMethod(API_TYPE.START_AUDIO_RECORDING, {\n                filePath: filePath,\n                quality: quality,\n            });\n        }\n        return callNativeMethod(API_TYPE.START_AUDIO_RECORDING2, {\n            filePath: filePath,\n            sampleRate: sampleRate,\n            quality: quality,\n        });\n    }\n    AgoraRtcEngine.startAudioRecording = startAudioRecording;\n    /**\n     * Stops an audio recording on the client.\n     *\n     * You can call this method before calling the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method else, the\n     * recording automatically stops when the `leaveChannel` method is called.\n     *\n     * @return\n     * - 0: Success\n     * - < 0: Failure.\n     */\n    function stopAudioRecording() {\n        return callNativeMethod(API_TYPE.STOP_AUDIO_RECORDING);\n    }\n    AgoraRtcEngine.stopAudioRecording = stopAudioRecording;\n    /**\n     * Starts playing and mixing the music file.\n     *\n     * This method mixes the specified local audio file with the audio stream from the microphone, or replaces the\n     * microphone's audio stream with the specified local audio file. You can choose whether the other user can hear\n     * the local audio playback and specify the number of playback loops. This method also supports online music\n     * playback.\n     *\n     * When the audio mixing file playback finishes after calling this method, the SDK triggers the\n     * [onAudioMixingFinished]{@link AgoraRtcEvents.onAudioMixingFinished} callback.\n     *\n     * A successful `startAudioMixing` method call triggers the\n     * [onAudioMixingStateChanged]{@link AgoraRtcEvents.onAudioMixingStateChanged}(PLAY) callback on the local client.\n     *\n     * When the audio mixing file playback finishes, the SDK triggers the `onAudioMixingStateChanged(STOPPED)`\n     * callback on the local client.\n     *\n     * **Note**\n     *\n     * - Call this method after joining a channel, otherwise issues may occur.\n     * - If the local audio mixing file does not exist, or if the SDK does not support the file format or cannot\n     * access the music file URL, the SDK returns `WARN_AUDIO_MIXING_OPEN_ERROR(-701)`.\n     * - If you want to play an online music file, ensure that the time interval between calling this method is more\n     * than 100 ms, or the `AUDIO_MIXING_ERROR_TOO_FREQUENT_CALL(702)` error code occurs.\n     *\n     * @param filePath The absolute path (including the suffixes of the filename) of the local or online audio file to\n     * mix, for example, c:\\music\\audio.mp4. Supported audio formats: 3GP, ASF, ADTS, AVI, MP3, MP4, MPEG-4, SAMI, and\n     * WAVE. For more information, see [Supported Media Formats in Media Foundation](https://docs.microsoft.com/en-us/windows/desktop/medfound/supported-media-formats-in-media-foundation).\n     * @param loopback Sets which user can hear the audio mixing:\n     * - true: Only the local user can hear the audio mixing.\n     * - false: Both users can hear the audio mixing.\n     * @param replace Sets the audio mixing content:\n     * - true: Only publish the specified audio file. The audio stream from the microphone is not published.\n     * - false: The local audio file is mixed with the audio stream from the microphone.\n     * @param cycle Sets the number of playback loops:\n     * - Positive integer: Number of playback loops.\n     * - `-1`: Infinite playback loops.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function startAudioMixing(filePath, loopback, replace, cycle) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.START_AUDIO_MIXING, {\n            filePath: filePath,\n            loopback: loopback,\n            replace: replace,\n            cycle: cycle,\n        });\n    }\n    AgoraRtcEngine.startAudioMixing = startAudioMixing;\n    /**\n     * Stops playing and mixing the music file.\n     *\n     * Call this method when you are in a channel.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function stopAudioMixing() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.STOP_AUDIO_MIXING);\n    }\n    AgoraRtcEngine.stopAudioMixing = stopAudioMixing;\n    /**\n     * Pauses playing and mixing the music file.\n     *\n     * Call this method when you are in a channel.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function pauseAudioMixing() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.PAUSE_AUDIO_MIXING);\n    }\n    AgoraRtcEngine.pauseAudioMixing = pauseAudioMixing;\n    /**\n     * Resumes playing and mixing the music file.\n     *\n     * Call this method when you are in a channel.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function resumeAudioMixing() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.RESUME_AUDIO_MIXING);\n    }\n    AgoraRtcEngine.resumeAudioMixing = resumeAudioMixing;\n    /**\n     * Sets the high-quality audio preferences.\n     *\n     * @deprecated This callback is deprecated.\n     *\n     * Call this method and set all parameters before joining a channel.\n     * Do not call this method again after joining a channel.\n     *\n     * @param fullband Sets whether to enable/disable full-band codec (48-kHz sample rate). Not compatible with SDK\n     * versions before v1.7.4:\n     * - true: Enable full-band codec.\n     * - false: Disable full-band codec.\n     * @param  stereo Sets whether to enable/disable stereo codec. Not compatible with SDK versions before v1.7.4:\n     * - true: Enable stereo codec.\n     * - false: Disable stereo codec.\n     * @param fullBitrate Sets whether to enable/disable high-bitrate mode. Recommended in voice-only mode:\n     * - true: Enable high-bitrate mode.\n     * - false: Disable high-bitrate mode.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setHighQualityAudioParameters(fullband, stereo, fullBitrate) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_HIGH_QUALITY_AUDIO_PARAMETERS, {\n            fullband: fullband,\n            stereo: stereo,\n            fullBitrate: fullBitrate,\n        });\n    }\n    AgoraRtcEngine.setHighQualityAudioParameters = setHighQualityAudioParameters;\n    /**\n     * Adjusts the volume during audio mixing.\n     *\n     * Call this method when you are in a channel.\n     *\n     * @note Calling this method does not affect the volume of audio effect file playback invoked by the\n     * [playEffect]{@link AgoraRtcEngine.playEffect} method.\n     *\n     * @param volume Audio mixing volume. The value ranges between 0 and 100 (default).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function adjustAudioMixingVolume(volume) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.ADJUST_AUDIO_MIXING_VOLUME, { volume: volume });\n    }\n    AgoraRtcEngine.adjustAudioMixingVolume = adjustAudioMixingVolume;\n    /**\n     * Adjusts the audio mixing volume for local playback.\n     *\n     * @note Call this method when you are in a channel.\n     *\n     * @param volume Audio mixing volume for local playback. The value ranges between 0 and 100 (default).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function adjustAudioMixingPlayoutVolume(volume) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.ADJUST_AUDIO_MIXING_PLAYOUT_VOLUME, { volume: volume });\n    }\n    AgoraRtcEngine.adjustAudioMixingPlayoutVolume = adjustAudioMixingPlayoutVolume;\n    /**\n     * Retrieves the audio mixing volume for local playback.\n     *\n     * This method helps troubleshoot audio volume related issues.\n     *\n     * @note Call this method when you are in a channel.\n     *\n     * @return\n     * - &ge; 0: The audio mixing volume, if this method call succeeds. The value range is [0,100].\n     * - < 0: Failure.\n     */\n    function getAudioMixingPlayoutVolume() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.GET_AUDIO_MIXING_PLAYOUT_VOLUME);\n    }\n    AgoraRtcEngine.getAudioMixingPlayoutVolume = getAudioMixingPlayoutVolume;\n    /**\n     * Adjusts the audio mixing volume for publishing (for remote users).\n     *\n     * @note Call this method when you are in a channel.\n     *\n     * @param volume Audio mixing volume for publishing. The value ranges between 0 and 100 (default).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function adjustAudioMixingPublishVolume(volume) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.ADJUST_AUDIO_MIXING_PUBLISH_VOLUME, { volume: volume });\n    }\n    AgoraRtcEngine.adjustAudioMixingPublishVolume = adjustAudioMixingPublishVolume;\n    /**\n     * Retrieves the audio mixing volume for publishing.\n     *\n     * This method helps troubleshoot audio volume related issues.\n     *\n     * @note Call this method when you are in a channel.\n     *\n     * @return\n     * - &ge; 0: The audio mixing volume for publishing, if this method call succeeds. The value range is [0,100].\n     * - < 0: Failure.\n     */\n    function getAudioMixingPublishVolume() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.GET_AUDIO_MIXING_PUBLISH_VOLUME);\n    }\n    AgoraRtcEngine.getAudioMixingPublishVolume = getAudioMixingPublishVolume;\n    /**\n     * Retrieves the duration (ms) of the music file.\n     *\n     * Call this method when you are in a channel.\n     *\n     * @return\n     * - &ge; 0: The audio mixing duration, if this method call succeeds.\n     * - < 0: Failure.\n     */\n    function getAudioMixingDuration() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.GET_AUDIO_MIXING_DURATION);\n    }\n    AgoraRtcEngine.getAudioMixingDuration = getAudioMixingDuration;\n    /**\n     * Retrieves the playback position (ms) of the music file.\n     *\n     * Call this method when you are in a channel.\n     *\n     * @return\n     * - &ge; 0: The current playback position of the audio mixing, if this method call succeeds.\n     * - < 0: Failure.\n     */\n    function getAudioMixingCurrentPosition() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.GET_AUDIO_MIXING_CURRENT_POSITION);\n    }\n    AgoraRtcEngine.getAudioMixingCurrentPosition = getAudioMixingCurrentPosition;\n    /**\n     * Sets the playback position of the music file to a different starting position (the default plays from the beginning).\n     *\n     * @param pos The playback starting position (ms) of the music file.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setAudioMixingPosition(pos) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_AUDIO_MIXING_POSITION, { pos: pos });\n    }\n    AgoraRtcEngine.setAudioMixingPosition = setAudioMixingPosition;\n    /**\n     * Sets the pitch of the local music file.\n     *\n     * When a local music file is mixed with a local human voice, call this method to set the pitch of the local music file only.\n     *\n     * @note Call this method after calling [startAudioMixing]{@link AgoraRtcEngine.startAudioMixing}.\n     *\n     * @param pitch Sets the pitch of the local music file by chromatic scale. The default value is 0,\n     * which means keeping the original pitch. The value ranges from -12 to 12, and the pitch value between\n     * consecutive values is a chromatic value. The greater the absolute value of this parameter, the\n     * higher or lower the pitch of the local music file.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setAudioMixingPitch(pitch) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_AUDIO_MIXING_PITCH, { pitch: pitch });\n    }\n    AgoraRtcEngine.setAudioMixingPitch = setAudioMixingPitch;\n    /**\n     * Retrieves the volume of the audio effects.\n     *\n     * The value ranges between 0.0 and 100.0.\n     *\n     * @return\n     * - &ge; 0: Volume of the audio effects, if this method call succeeds.\n     * - < 0: Failure.\n     */\n    function getEffectsVolume() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.GET_EFFECTS_VOLUME);\n    }\n    AgoraRtcEngine.getEffectsVolume = getEffectsVolume;\n    /**\n     * Sets the volume of the audio effects.\n     *\n     * @param volume Sets the volume of the audio effects. The value ranges between 0 and 100 (default).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setEffectsVolume(volume) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_EFFECTS_VOLUME, { volume: volume });\n    }\n    AgoraRtcEngine.setEffectsVolume = setEffectsVolume;\n    /**\n     * Sets the volume of a specified audio effect.\n     *\n     * @param soundId ID of the audio effect. Each audio effect has a unique ID.\n     * @param volume Sets the volume of the specified audio effect. The value ranges between 0 and 100 (default).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setVolumeOfEffect(soundId, volume) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_VOLUME_OF_EFFECT, { soundId: soundId, volume: volume });\n    }\n    AgoraRtcEngine.setVolumeOfEffect = setVolumeOfEffect;\n    /**\n     * Enables/Disables face detection for the local user.\n     *\n     * Once face detection is enabled, the SDK triggers the\n     * [onFacePositionChanged]{@link AgoraRtcEvents.onFacePositionChanged} callback to report the face information of the\n     * local user, which includes the following aspects:\n     * - The width and height of the local video.\n     * - The position of the human face in the local video.\n     * - The distance between the human face and the device screen.\n     *\n     * @param enabled Determines whether to enable the face detection function for the local user:\n     * - true: Enable face detection.\n     * - false: (Default) Disable face detection.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableFaceDetection(enabled) {\n        return callNativeMethod(API_TYPE.ENABLE_FACE_DETECTION, { enabled: enabled });\n    }\n    AgoraRtcEngine.enableFaceDetection = enableFaceDetection;\n    /**\n     * Plays a specified local or online audio effect file.\n     *\n     * This method allows you to set the loop count, pitch, pan, and gain of the audio effect file, as well as whether\n     * the remote user can hear the audio effect.\n     *\n     * To play multiple audio effect files simultaneously, call this method multiple times with different soundIds and\n     * filePaths. We recommend playing no more than three audio effect files at the same time.\n     *\n     * @param soundId ID of the specified audio effect. Each audio effect has a unique ID.\n     *\n     * @note If the audio effect is preloaded into the memory through the [preloadEffect]{@link AgoraRtcEngine.preloadEffect}\n     * method, the value of `soundID` must be the same as that in the `preloadEffect` method.\n     * @param filePath Specifies the absolute path (including the suffixes of the filename) to the local audio effect\n     * file or the URL of the online audio effect file, for example, c:/music/audio.mp4. Supported audio formats: mp3,\n     * mp4, m4a, aac, 3gp, mkv and wav.\n     * @param loopCount Sets the number of times the audio effect loops:\n     * - 0: Play the audio effect once.\n     * - 1: Play the audio effect twice.\n     * - -1: Play the audio effect in an indefinite loop until the [stopEffect]{@link AgoraRtcEngine.stopEffect} or\n     * [stopAllEffects]{@link AgoraRtcEngine.stopAllEffects} method is called.\n     * @param pitch Sets the pitch of the audio effect. The value ranges between 0.5 and 2. The default value is 1\n     * (no change to the pitch). The lower the value, the lower the pitch.\n     * @param pan Sets the spatial position of the audio effect. The value ranges between -1.0 and 1.0:\n     * - 0.0: The audio effect displays ahead.\n     * - 1.0: The audio effect displays to the right.\n     * - -1.0: The audio effect displays to the left.\n     * @param gain  Sets the volume of the audio effect. The value ranges between 0 and 100 (default). The lower the\n     * value, the lower the volume of the audio effect.\n     * @param publish Sets whether or not to publish the specified audio effect to the remote stream:\n     * - true: The locally played audio effect is published to the Agora Cloud and the remote users can hear it.\n     * - false: The locally played audio effect is not published to the Agora Cloud and the remote users cannot hear it.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function playEffect(soundId, filePath, loopCount, pitch, pan, gain, publish) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.PLAY_EFFECT, {\n            soundId: soundId,\n            filePath: filePath,\n            loopCount: loopCount,\n            pitch: pitch,\n            pan: pan,\n            gain: gain,\n            publish: publish,\n        });\n    }\n    AgoraRtcEngine.playEffect = playEffect;\n    /**\n     * Stops playing a specified audio effect.\n     *\n     * @param soundId ID of the audio effect to stop playing. Each audio effect has a unique ID.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function stopEffect(soundId) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.STOP_EFFECT, {\n            soundId: soundId,\n        });\n    }\n    AgoraRtcEngine.stopEffect = stopEffect;\n    /**\n     * Stops playing all audio effects.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function stopAllEffects() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.STOP_ALL_EFFECTS);\n    }\n    AgoraRtcEngine.stopAllEffects = stopAllEffects;\n    /**\n     * Preloads a specified audio effect file into the memory.\n     *\n     * To ensure smooth communication, limit the size of the audio effect file. We recommend using this method to\n     * preload the audio effect before calling the [joinChannel]{@link AgoraRtcEngine.joinChannel} method.\n     * Supported audio formats: mp3, aac, m4a, 3gp, and wav.\n     *\n     * @note This method does not support online audio effect files.\n     *\n     * @param soundId ID of the audio effect. Each audio effect has a unique ID.\n     * @param filePath The absolute path of the audio effect file.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function preloadEffect(soundId, filePath) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.PRE_LOAD_EFFECT, {\n            soundId: soundId,\n            filePath: filePath,\n        });\n    }\n    AgoraRtcEngine.preloadEffect = preloadEffect;\n    /**\n     * Releases a specified preloaded audio effect from the memory.\n     *\n     * @param soundId ID of the audio effect. Each audio effect has a unique ID.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function unloadEffect(soundId) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.UN_LOAD_EFFECT, {\n            soundId: soundId,\n        });\n    }\n    AgoraRtcEngine.unloadEffect = unloadEffect;\n    /**\n     * Pauses a specified audio effect.\n     *\n     * @param soundId ID of the audio effect. Each audio effect has a unique ID.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function pauseEffect(soundId) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.PAUSE_EFFECT, {\n            soundId: soundId,\n        });\n    }\n    AgoraRtcEngine.pauseEffect = pauseEffect;\n    /**\n     * Pauses all audio effects.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function pauseAllEffects() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.PAUSE_ALL_EFFECTS);\n    }\n    AgoraRtcEngine.pauseAllEffects = pauseAllEffects;\n    /**\n     * Resumes playing a specified audio effect.\n     *\n     * @param soundId ID of the audio effect. Each audio effect has a unique ID.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function resumeEffect(soundId) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.RESUME_EFFECT, {\n            soundId: soundId,\n        });\n    }\n    AgoraRtcEngine.resumeEffect = resumeEffect;\n    /**\n     * Resumes playing all audio effects.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function resumeAllEffects() {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.RESUME_ALL_EFFECTS);\n    }\n    AgoraRtcEngine.resumeAllEffects = resumeAllEffects;\n    /**\n     * Enables/Disables stereo panning for remote users.\n     *\n     * Ensure that you call this method before [joinChannel]{@link AgoraRtcEngine.joinChannel} to enable stereo panning for\n     * remote users so that the local user can track the position of a remote user by calling\n     * [setRemoteVoicePosition]{@link AgoraRtcEngine.setRemoteVoicePosition}.\n     *\n     * @param enabled Sets whether or not to enable stereo panning for remote users:\n     * - true: enables stereo panning.\n     * - false: disables stereo panning.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableSoundPositionIndication(enabled) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.ENABLE_SOUND_POSITION_INDICATION, { enabled: enabled });\n    }\n    AgoraRtcEngine.enableSoundPositionIndication = enableSoundPositionIndication;\n    /**\n     * Sets the sound position and gain of a remote user.\n     *\n     * When the local user calls this method to set the sound position of a remote user, the sound difference between\n     * the left and right channels allows the local user to track the real-time position of the remote user, creating\n     * a real sense of space. This method applies to massively multiplayer online games, such as Battle Royale games.\n     *\n     * **Note**\n     *\n     * - For this method to work, enable stereo panning for remote users by calling the\n     * [enableSoundPositionIndication]{@link AgoraRtcEngine.enableSoundPositionIndication} method before joining a channel.\n     * - This method requires hardware support. For the best sound positioning, we recommend using a stereo speaker.\n     *\n     * @param uid The ID of the remote user.\n     * @param pan The sound position of the remote user. The value ranges from -1.0 to 1.0:\n     * - 0.0: the remote sound comes from the front.\n     * - -1.0: the remote sound comes from the left.\n     * - 1.0: the remote sound comes from the right.\n     * @param gain Gain of the remote user. The value ranges from 0.0 to 100.0. The default value is 100.0\n     * (the original gain of the remote user). The smaller the value, the less the gain.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setRemoteVoicePosition(uid, pan, gain) {\n        return callNativeMethod(API_TYPE.SET_REMOTE_VOICE_POSITIONN, {\n            uid: uid,\n            pan: pan,\n            gain: gain,\n        });\n    }\n    AgoraRtcEngine.setRemoteVoicePosition = setRemoteVoicePosition;\n    /**\n     * Changes the voice pitch of the local speaker.\n     *\n     * @param pitch Sets the voice pitch. The value ranges between 0.5 and 2.0. The lower the value, the lower the\n     * voice pitch. The default value is 1.0 (no change to the local voice pitch).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLocalVoicePitch(pitch) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_LOCAL_VOICE_CHANGER, { pitch: pitch });\n    }\n    AgoraRtcEngine.setLocalVoicePitch = setLocalVoicePitch;\n    /**\n     * Sets the local voice equalization effect.\n     *\n     * @param bandFrequency Sets the band frequency. The value ranges between 0 and 9, representing the respective\n     * 10-band center frequencies of the voice effects, including 31, 62, 125, 250, 500, 1k, 2k, 4k, 8k, and 16k Hz. See\n     * [AUDIO_EQUALIZATION_BAND_FREQUENCY]{@link AgoraRtcEngine.AUDIO_EQUALIZATION_BAND_FREQUENCY}.\n     * @param bandGain Sets the gain of each band in dB. The value ranges between -15 and 15.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLocalVoiceEqualization(bandFrequency, bandGain) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_LOCAL_VOICE_EQUALIZATION, {\n            bandFrequency: bandFrequency,\n            bandGain: bandGain,\n        });\n    }\n    AgoraRtcEngine.setLocalVoiceEqualization = setLocalVoiceEqualization;\n    /**\n     * Sets the local voice reverberation.\n     *\n     * You can also use [setLocalVoiceReverbPreset]{@link AgoraRtcEngine.setLocalVoiceReverbPreset} to use the preset reverberation effect,\n     * such as pop music, R&B or rock music effects.\n     *\n     * @param reverbKey Sets the reverberation key. See [AUDIO_REVERB_TYPE]{@link AgoraRtcEngine.AUDIO_REVERB_TYPE}.\n     * @param value Sets the value of the reverberation key.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLocalVoiceReverb(reverbKey, value) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_LOCAL_VOICE_REVERB, { reverbKey: reverbKey, value: value });\n    }\n    AgoraRtcEngine.setLocalVoiceReverb = setLocalVoiceReverb;\n    /**\n     * Sets the local voice changer option.\n     *\n     * This method can be used to set the local voice effect for users in a `COMMUNICATION` channel or hosts in a\n     * `LIVE_BROADCASTING` channel.\n     *\n     * Voice changer options include the following voice effects:\n     * - `VOICE_CHANGER_XXX`: Changes the local voice to an old man, a little boy, or the Hulk. Applies to the voice\n     * talk scenario.\n     * - `VOICE_BEAUTY_XXX`: Beautifies the local voice by making it sound more vigorous, resounding, or adding spacial\n     * resonance. Applies to the voice talk and singing scenario.\n     * - `GENERAL_VOICE_BEAUTY_XXX`: Adds gender-based beautification effect to the local voice. Applies to the voice\n     * talk scenario.\n     *   - For a male-sounding voice: Adds magnetism to the voice.\n     *   - For a female-sounding voice: Adds freshness or vitality to the voice.\n     *\n     * **Note**\n     *\n     * - To achieve better voice effect quality, Agora recommends setting the profile parameter in\n     * [setAudioProfile]{@link AgoraRtcEngine.setAudioProfile} as `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or\n     * `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`.\n     * - This method works best with the human voice, and Agora does not recommend using it for audio containing music\n     * and a human voice.\n     * - Do not use this method with [setLocalVoiceReverbPreset]{@link AgoraRtcEngine.setLocalVoiceReverbPreset}, because the\n     * method called later overrides the one called earlier.\n     *\n     * @param voiceChanger Sets the local voice changer option. The default value is `VOICE_CHANGER_OFF`, which means\n     * the original voice. See details in [VOICE_CHANGER_PRESET]{@link AgoraRtcEngine.VOICE_CHANGER_PRESET}.\n     * Gender-based beatification effect works best only when assigned a proper gender:\n     * - For a male-sounding voice: `GENERAL_BEAUTY_VOICE_MALE_MAGNETIC`.\n     * - For a female-sounding voice: `GENERAL_BEAUTY_VOICE_FEMALE_FRESH` or `GENERAL_BEAUTY_VOICE_FEMALE_VITALITY`.\n     *\n     * Failure to do so can lead to voice distortion.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure. Check if the enumeration is properly set.\n     */\n    function setLocalVoiceChanger(voiceChanger) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_LOCAL_VOICE_CHANGER, { voiceChanger: voiceChanger });\n    }\n    AgoraRtcEngine.setLocalVoiceChanger = setLocalVoiceChanger;\n    /**\n     * Sets the local voice reverberation option, including the virtual stereo.\n     *\n     * This method sets the local voice reverberation for users in a `COMMUNICATION` channel or hosts in a `LIVE_BROADCASTING` channel.\n     * After successfully calling this method, all users in the channel can hear the voice with reverberation.\n     *\n     * **Note**\n     *\n     * - When calling this method with enumerations that begin with `AUDIO_REVERB_FX`, ensure that you set profile in\n     * [setAudioProfile]{@link AgoraRtcEngine.setAudioProfile} as `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or\n     * `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`; otherwise, this methods cannot set the corresponding voice\n     * reverberation option.\n     * - When calling this method with `AUDIO_VIRTUAL_STEREO`, Agora recommends setting the `profile` parameter in\n     * `setAudioProfile` as `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`.\n     * - This method works best with the human voice, and Agora does not recommend using it for audio containing music\n     * and a human voice.\n     * - Do not use this method with [setLocalVoiceChanger]{@link AgoraRtcEngine.setLocalVoiceChanger}, because the method\n     * called later overrides the one called earlier.\n     *\n     * @param reverbPreset The local voice reverberation option. The default value is `AUDIO_REVERB_OFF`,\n     * which means the original voice.  See [AUDIO_REVERB_PRESET]{@link AgoraRtcEngine.AUDIO_REVERB_PRESET}.\n     * To achieve better voice effects, Agora recommends the enumeration whose name begins with `AUDIO_REVERB_FX`.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLocalVoiceReverbPreset(reverbPreset) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_LOCAL_VOICE_REVERB_PRESET, { reverbPreset: reverbPreset });\n    }\n    AgoraRtcEngine.setLocalVoiceReverbPreset = setLocalVoiceReverbPreset;\n    /**\n     * TODO\n     *\n     * @param preset\n     */\n    function setVoiceBeautifierPreset(preset) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_VOICE_BEAUTIFIER_PRESET, { preset: preset });\n    }\n    AgoraRtcEngine.setVoiceBeautifierPreset = setVoiceBeautifierPreset;\n    /**\n     * TODO\n     *\n     * @param preset\n     */\n    function setAudioEffectPreset(preset) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_AUDIO_EFFECT_PRESET, { preset: preset });\n    }\n    AgoraRtcEngine.setAudioEffectPreset = setAudioEffectPreset;\n    /**\n     * TODO\n     *\n     * @param preset\n     * @param param1\n     * @param param2\n     */\n    function setAudioEffectParameters(preset, param1, param2) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_AUDIO_EFFECT_PARAMETERS, { preset: preset, param1: param1, param2: param2 });\n    }\n    AgoraRtcEngine.setAudioEffectParameters = setAudioEffectParameters;\n    /**\n     * Sets the log files that the SDK outputs.\n     *\n     * By default, the SDK outputs five log files, `agorasdk.log`, `agorasdk_1.log`, `agorasdk_2.log`, `agorasdk_3.log`,\n     * `agorasdk_4.log`, each with a default size of 1024 KB.\n     *\n     * These log files are encoded in UTF-8. The SDK writes the latest logs in `agorasdk.log`. When `agorasdk.log` is\n     * full, the SDK deletes the log file with the earliest modification time among the other four, renames\n     * `agorasdk.log` to the name of the deleted log file, and create a new `agorasdk.log` to record latest logs.\n     *\n     * @note Ensure that you call this method immediately after calling [init]{@link AgoraRtcEngine.init}, otherwise the output\n     * logs may not be complete.\n     *\n     * @param filePath The absolute path of log files. The default file path is as follows:\n     * - Android: `/storage/emulated/0/Android/data/<package name>/files/agorasdk.log`\n     * - iOS: `App Sandbox/Library/caches/agorasdk.log`\n     *\n     * Ensure that the directory for the log files exists and is writable. You can use this parameter to rename the log files.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLogFile(filePath) {\n        return callNativeMethod(API_TYPE.SET_LOG_FILE, { filePath: filePath });\n    }\n    AgoraRtcEngine.setLogFile = setLogFile;\n    /**\n     * Sets the output log level of the SDK.\n     *\n     * You can use one or a combination of the log filter levels. The log level follows the sequence of `OFF`,\n     * `CRITICAL`, `ERROR`, `WARNING`, `INFO`, and `DEBUG`. Choose a level to see the logs preceding that level.\n     *\n     * If you set the log level to `WARNING`, you see the logs within levels `CRITICAL`, `ERROR`, and `WARNING`.\n     *\n     * @param filter Sets the log filter level. See [LOG_FILTER_TYPE]{@link AgoraRtcEngine.LOG_FILTER_TYPE}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLogFilter(filter) {\n        return callNativeMethod(API_TYPE.SET_LOG_FILTER, { filter: filter });\n    }\n    AgoraRtcEngine.setLogFilter = setLogFilter;\n    /**\n     * Sets the size of a log file that the SDK outputs.\n     *\n     * By default, the SDK outputs five log files, `agorasdk.log`, `agorasdk_1.log`, `agorasdk_2.log`, `agorasdk_3.log`,\n     * `agorasdk_4.log`, each with a default size of 1024 KB.\n     *\n     * These log files are encoded in UTF-8. The SDK writes the latest logs in `agorasdk.log`. When `agorasdk.log` is\n     * full, the SDK deletes the log file with the earliest modification time among the other four, renames\n     * `agorasdk.log` to the name of the deleted log file, and create a new `agorasdk.log` to record latest logs.\n     *\n     * @param fileSizeInKBytes The size (KB) of a log file. The default value is 1024 KB. If you set `fileSizeInKByte`\n     * to 1024 KB, the SDK outputs at most 5 MB log files; if you set it to less than 1024 KB, the maximum size of a\n     * log file is still 1024 KB.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLogFileSize(fileSizeInKBytes) {\n        return callNativeMethod(API_TYPE.SET_LOG_FILE_SIZE, { fileSizeInKBytes: fileSizeInKBytes });\n    }\n    AgoraRtcEngine.setLogFileSize = setLogFileSize;\n    /**\n     * @ignore\n     * Updates the display mode of the local video view.\n     *\n     * After initializing the local video view, you can call this method to update its rendering and mirror modes. It\n     * affects only the video view that the local user sees, not the published local video stream.\n     *\n     * **Note**\n     *\n     * - Ensure that you have called the [setupLocalVideo]{@link AgoraRtcEngine.setupLocalVideo} method to initialize the local\n     * video view before calling this method.\n     * - During a call, you can call this method as many times as necessary to update the display mode of the local\n     * video view.\n     *\n     * @param renderMode The rendering mode of the local video view. See [RENDER_MODE_TYPE]{@link AgoraRtcEngine.RENDER_MODE_TYPE}.\n     * @param mirrorMode The mirror mode of the local video view. See [VIDEO_MIRROR_MODE_TYPE]{@link AgoraRtcEngine.VIDEO_MIRROR_MODE_TYPE}.\n     *\n     * **Note**\n     *\n     * If you use a front camera, the SDK enables the mirror mode by default; if you use a rear camera, the SDK\n     * disables the mirror mode by default.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLocalRenderMode(renderMode, mirrorMode) {\n        if (mirrorMode === undefined) {\n            return callNativeMethod(API_TYPE.SET_LOCAL_RENDER_MODE, { renderMode: renderMode });\n        }\n        return callNativeMethod(API_TYPE.SET_LOCAL_RENDER_MODE_2, {\n            renderMode: renderMode,\n            mirrorMode: mirrorMode,\n        });\n    }\n    AgoraRtcEngine.setLocalRenderMode = setLocalRenderMode;\n    /**\n     * @ignore\n     * Updates the display mode of the video view of a remote user.\n     *\n     * After initializing the video view of a remote user, you can call this method to update its rendering and mirror\n     * modes. This method affects only the video view that the local user sees.\n     *\n     * **Note**\n     *\n     * - Ensure that you have called the [setupRemoteVideo]{@link AgoraRtcEngine.setupRemoteVideo} method to initialize the\n     * remote video view before calling this method.\n     * - During a call, you can call this method as many times as necessary to update the display mode of the video\n     * view of a remote user.\n     *\n     * @param userId The ID of the remote user.\n     * @param renderMode The rendering mode of the remote video view. See [RENDER_MODE_TYPE]{@link AgoraRtcEngine.RENDER_MODE_TYPE}.\n     * @param mirrorMode The mirror mode of the remote video view. See [VIDEO_MIRROR_MODE_TYPE]{@link AgoraRtcEngine.VIDEO_MIRROR_MODE_TYPE}.\n     *\n     * **Note**\n     *\n     * The SDK disables the mirror mode by default.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setRemoteRenderMode(userId, renderMode, mirrorMode) {\n        if (mirrorMode === undefined) {\n            return callNativeMethod(API_TYPE.SET_REMOTE_RENDER_MODE, {\n                userId: userId,\n                renderMode: renderMode,\n            });\n        }\n        return callNativeMethod(API_TYPE.SET_REMOTE_RENDER_MODE_2, {\n            userId: userId,\n            renderMode: renderMode,\n            mirrorMode: mirrorMode,\n        });\n    }\n    AgoraRtcEngine.setRemoteRenderMode = setRemoteRenderMode;\n    /**\n     * @ignore\n     * Sets the local video mirror mode.\n     *\n     * @deprecated This method is deprecated, use the [setupLocalVideo]{@link AgoraRtcEngine.setupLocalVideo} or\n     * [setLocalRenderMode]{@link AgoraRtcEngine.setLocalRenderMode} method instead.\n     *\n     * You must call this method before calling the [startPreview]{@link AgoraRtcEngine.startPreview} method, otherwise the\n     * mirror mode will not work.\n     *\n     * **Warning**\n     * - Call this method after calling the `setupLocalVideo` method to initialize the local video view.\n     * - During a call, you can call this method as many times as necessary to update the mirror mode of the local video view.\n     *\n     * @param mirrorMode Sets the local video mirror mode. See [VIDEO_MIRROR_MODE_TYPE]{@link AgoraRtcEngine.VIDEO_MIRROR_MODE_TYPE}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLocalVideoMirrorMode(mirrorMode) {\n        return callNativeMethod(API_TYPE.SET_LOCAL_VIDEO_MIRROR_MODE, {\n            mirrorMode: mirrorMode,\n        });\n    }\n    AgoraRtcEngine.setLocalVideoMirrorMode = setLocalVideoMirrorMode;\n    /**\n     * Sets the stream mode to the single-stream (default) or dual-stream mode. (`LIVE_BROADCASTING` only.)\n     *\n     * If the dual-stream mode is enabled, the receiver can choose to receive the high stream (high-resolution and\n     * high-bitrate video stream), or the low stream (low-resolution and low-bitrate video stream).\n     *\n     * @param enabled Sets the stream mode:\n     * - true: Dual-stream mode.\n     * - false: Single-stream mode.\n     */\n    function enableDualStreamMode(enabled) {\n        return callNativeMethod(API_TYPE.ENABLE_DUAL_STREAM_MODE, { enabled: enabled });\n    }\n    AgoraRtcEngine.enableDualStreamMode = enableDualStreamMode;\n    /**\n     * @ignore\n     * Sets the external audio source. Please call this method before [joinChannel]{@link AgoraRtcEngine.joinChannel}.\n     *\n     * @param enabled Sets whether to enable/disable the external audio source:\n     * - true: Enables the external audio source.\n     * - false: (Default) Disables the external audio source.\n     * @param sampleRate Sets the sample rate (Hz) of the external audio source, which can be set as 8000, 16000,\n     * 32000, 44100, or 48000 Hz.\n     * @param channels Sets the number of audio channels of the external audio source:\n     * - 1: Mono.\n     * - 2: Stereo.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setExternalAudioSource(enabled, sampleRate, channels) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_EXTERNAL_AUDIO_SOURCE, {\n            enabled: enabled,\n            sampleRate: sampleRate,\n            channels: channels,\n        });\n    }\n    AgoraRtcEngine.setExternalAudioSource = setExternalAudioSource;\n    /**\n     * @ignore\n     * Sets the external audio sink.\n     *\n     * This method applies to scenarios where you want to use external audio\n     * data for playback. After enabling the external audio sink, you can call\n     * the [pullAudioFrame]{@link AgoraRtcEngine.pullAudioFrame} method to pull the\n     * remote audio data, process it, and play it with the audio effects that you want.\n     *\n     * @note Once you enable the external audio sink, the app will not retrieve any\n     * audio data from the\n     * [onPlaybackAudioFrame]{@link AgoraRtcEvents.onPlaybackAudioFrame} callback.\n     *\n     * @param enabled\n     * - true: Enables the external audio sink.\n     * - false: (Default) Disables the external audio sink.\n     * @param sampleRate Sets the sample rate (Hz) of the external audio sink,\n     * which can be set as 16000, 32000, 44100 or 48000.\n     * @param channels Sets the number of audio channels of the external\n     * audio sink:\n     * - 1: Mono.\n     * - 2: Stereo.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setExternalAudioSink(enabled, sampleRate, channels) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_EXTERNAL_AUDIO_SINK, {\n            enabled: enabled,\n            sampleRate: sampleRate,\n            channels: channels,\n        });\n    }\n    AgoraRtcEngine.setExternalAudioSink = setExternalAudioSink;\n    /**\n     * @ignore\n     * Sets the audio recording format for the [onRecordAudioFrame]{@link AgoraRtcEvents.onRecordAudioFrame} callback.\n     *\n     * @param sampleRate Sets the sample rate (`samplesPerSec`) returned in the onRecordAudioFrame* callback, which can be set as 8000, 16000, 32000, 44100, or 48000 Hz.\n     * @param channel Sets the number of audio channels (`channels`) returned in the *onRecordAudioFrame* callback:\n     * - 1: Mono\n     * - 2: Stereo\n     * @param mode Sets the use mode (see [RAW_AUDIO_FRAME_OP_MODE_TYPE)]{@link AgoraRtcEngine.RAW_AUDIO_FRAME_OP_MODE_TYPE)} of the *onRecordAudioFrame* callback.\n     * @param samplesPerCall Sets the number of samples returned in the *onRecordAudioFrame* callback. `samplesPerCall` is usually set as 1024 for RTMP streaming.\n     * @note The SDK triggers the `onRecordAudioFrame` callback according to the sample interval. Ensure that the sample interval ≥ 0.01 (s). And, Sample interval (sec) = `samplePerCall`/(`sampleRate` × `channel`).\n     * @return\n     *     - 0: Success.\n     * - < 0: Failure.\n     */\n    function setRecordingAudioFrameParameters(sampleRate, channel, mode, samplesPerCall) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_RECORDING_AUDIO_FRAME_PARAMETERS, {\n            sampleRate: sampleRate,\n            channel: channel,\n            mode: mode,\n            samplesPerCall: samplesPerCall,\n        });\n    }\n    AgoraRtcEngine.setRecordingAudioFrameParameters = setRecordingAudioFrameParameters;\n    /**\n     * @ignore\n     * Sets the audio playback format for the [onPlaybackAudioFrame]{@link AgoraRtcEngine.onPlaybackAudioFrame} callback.\n     *\n     * @param sampleRate Sets the sample rate (`samplesPerSec`) returned in the *onPlaybackAudioFrame* callback,\n     * which can be set as 8000, 16000, 32000, 44100, or 48000 Hz.\n     * @param channel Sets the number of channels (`channels`) returned in the *onPlaybackAudioFrame* callback:\n     * - 1: Mono\n     * - 2: Stereo\n     * @param mode Sets the use mode (see [RAW_AUDIO_FRAME_OP_MODE_TYPE)]{@link AgoraRtcEngine.RAW_AUDIO_FRAME_OP_MODE_TYPE)} of the\n     * `onPlaybackAudioFrame` callback.\n     * @param samplesPerCall Sets the number of samples returned in the `onPlaybackAudioFrame` callback. `samplesPerCall`\n     * is usually set as 1024 for RTMP streaming.\n     * @note The SDK triggers the `onPlaybackAudioFrame` callback according to the sample interval. Ensure that the sample\n     * interval ≥ 0.01 (s). And, Sample interval (sec) = `samplePerCall`/(`sampleRate` × `channel`).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setPlaybackAudioFrameParameters(sampleRate, channel, mode, samplesPerCall) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_PLAYBACK_AUDIO_FRAME_PARAMETERS, {\n            sampleRate: sampleRate,\n            channel: channel,\n            mode: mode,\n            samplesPerCall: samplesPerCall,\n        });\n    }\n    AgoraRtcEngine.setPlaybackAudioFrameParameters = setPlaybackAudioFrameParameters;\n    /**\n     * @ignore\n     * Sets the mixed audio format for the [onMixedAudioFrame]{@link AgoraRtcEngine.onMixedAudioFrame} callback.\n     *\n     * @param sampleRate Sets the sample rate (`samplesPerSec`) returned in the `onMixedAudioFrame` callback, which can be set as\n     * 8000, 16000, 32000, 44100, or 48000 Hz.\n     * @param samplesPerCall Sets the number of samples (`samples`) returned in the *onMixedAudioFrame* callback. `samplesPerCall`\n     * is usually set as 1024 for RTMP streaming.\n     * @note The SDK triggers the `onMixedAudioFrame` callback according to the sample interval. Ensure that the sample\n     * interval ≥ 0.01 (s). And, Sample interval (sec) = `samplePerCall`/(`sampleRate` × `channels`).\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setMixedAudioFrameParameters(sampleRate, samplesPerCall) {\n        return callNativeMethodAudioEffect(API_TYPE_AUDIO_EFFECT.SET_MIXED_AUDIO_FRAME_PARAMETERS, {\n            sampleRate: sampleRate,\n            samplesPerCall: samplesPerCall,\n        });\n    }\n    AgoraRtcEngine.setMixedAudioFrameParameters = setMixedAudioFrameParameters;\n    /**\n     * Adjusts the recording volume.\n     *\n     * @param volume Recording volume. To avoid echoes and improve call quality,\n     * Agora recommends setting the value of volume between 0 and 100. If you\n     * need to set the value higher than 100, contact support@AgoraRtcEngine.io first.\n     * - 0: Mute.\n     * - 100: Original volume.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function adjustRecordingSignalVolume(volume) {\n        return callNativeMethod(API_TYPE.ADJUST_RECORDING_SIGNAL_VOLUME, {\n            volume: volume,\n        });\n    }\n    AgoraRtcEngine.adjustRecordingSignalVolume = adjustRecordingSignalVolume;\n    /**\n     * Adjusts the playback volume of all remote users.\n     *\n     * **Note**\n     *\n     * - This method adjusts the playback volume that is the mixed volume of all remote users.\n     * - (Since v3.1.2) To mute the local audio playback, call both the `adjustPlaybackSignalVolume` and\n     * [adjustAudioMixingVolume]{@link AgoraRtcEngine.adjustAudioMixingVolume} methods and set the volume as `0`.\n     *\n     * @param volume The playback volume of all remote users. To avoid echoes and\n     * improve call quality, Agora recommends setting the value of volume between\n     * 0 and 100. If you need to set the value higher than 100, contact\n     * support@AgoraRtcEngine.io first.\n     * - 0: Mute.\n     * - 100: Original volume.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function adjustPlaybackSignalVolume(volume) {\n        return callNativeMethod(API_TYPE.ADJUST_PLAYBACK_SIGNAL_VOLUME, { volume: volume });\n    }\n    AgoraRtcEngine.adjustPlaybackSignalVolume = adjustPlaybackSignalVolume;\n    /**\n     * Enables interoperability with the Agora Web SDK.\n     *\n     * @deprecated This method is deprecated. As of v3.1.2, the Native SDK automatically enables interoperability with\n     * the Web SDK, so you no longer need to call this method.\n     *\n     * **Note**\n     *\n     * - This method applies only to the `LIVE_BROADCASTING` profile. In the `COMMUNICATION` profile, interoperability\n     * with the Agora Web SDK is enabled by default.\n     * - If the channel has Web SDK users, ensure that you call this method, or the video of the Native user will be a\n     * black screen for the Web user.\n     *\n     * @param enabled Sets whether to enable/disable interoperability with the Agora Web SDK:\n     * - true: Enable.\n     * - false: (Default) Disable.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableWebSdkInteroperability(enabled) {\n        return callNativeMethod(API_TYPE.ENABLE_WEB_SDK_INTEROPER_ABILITY, {\n            enabled: enabled,\n        });\n    }\n    AgoraRtcEngine.enableWebSdkInteroperability = enableWebSdkInteroperability;\n    /**\n     * @ignore\n     * Sets the preferences for the high-quality video. (`LIVE_BROADCASTING` only).\n     *\n     * @deprecated This method is deprecated. Agora recommends using the `degradationPrefer` parameter of\n     * [VideoEncoderConfiguration]{@link AgoraRtcEngine.VideoEncoderConfiguration}.\n     *\n     * @param preferFrameRateOverImageQuality Sets the video quality preference:\n     * - true: Frame rate over image quality.\n     * - false: (Default) Image quality over frame rate.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setVideoQualityParameters(preferFrameRateOverImageQuality) {\n        return callNativeMethod(API_TYPE.SET_VIDEO_QUALITY_PARAMETERS, {\n            preferFrameRateOverImageQuality: preferFrameRateOverImageQuality,\n        });\n    }\n    AgoraRtcEngine.setVideoQualityParameters = setVideoQualityParameters;\n    /**\n     * Sets the fallback option for the published video stream based on the network conditions.\n     *\n     * If `option` is set as\n     * [STREAM_FALLBACK_OPTION_AUDIO_ONLY]{@link AgoraRtcEngine.STREAM_FALLBACK_OPTIONS.STREAM_FALLBACK_OPTION_AUDIO_ONLY}(2),\n     * the SDK will:\n     * - Disable the upstream video but enable audio only when the network conditions deteriorate and cannot support\n     * both video and audio.\n     * - Re-enable the video when the network conditions improve.\n     *\n     * When the published video stream falls back to audio only or when the audio-only stream switches back to the video,\n     * the SDK triggers the [onLocalPublishFallbackToAudioOnly]{@link AgoraRtcEvents.onLocalPublishFallbackToAudioOnly} callback.\n     *\n     * @note Agora does not recommend using this method for CDN live streaming, because the remote CDN live user will\n     * have a noticeable lag when the published video stream falls back to audio only.\n     *\n     * @param option Sets the fallback option for the published video stream. See\n     * [STREAM_FALLBACK_OPTIONS]{@link AgoraRtcEngine.STREAM_FALLBACK_OPTIONS}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLocalPublishFallbackOption(option) {\n        return callNativeMethod(API_TYPE.SET_LOCAL_PUBLISH_FALLBACK_OPTION, {\n            option: option,\n        });\n    }\n    AgoraRtcEngine.setLocalPublishFallbackOption = setLocalPublishFallbackOption;\n    /**\n     * Sets the fallback option for the remotely subscribed video stream based on the network conditions.\n     *\n     * The default setting for `option` is\n     * [STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW]{@link AgoraRtcEngine.STREAM_FALLBACK_OPTIONS.STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW}(1),\n     * where the remotely subscribed video stream falls back to the low-stream video (low resolution and low bitrate) under poor\n     * downlink network conditions.\n     *\n     * If `option` is set as\n     * [STREAM_FALLBACK_OPTION_AUDIO_ONLY]{@link AgoraRtcEngine.STREAM_FALLBACK_OPTIONS.STREAM_FALLBACK_OPTION_AUDIO_ONLY} (2), the\n     * SDK automatically switches the video from a high-stream to a low-stream, or disables the video when the downlink network\n     * conditions cannot support both audio and video to guarantee the quality of the audio. The SDK monitors the network quality\n     * and restores the video stream when the network conditions improve.\n     *\n     * When the remotely subscribed video stream falls back to audio only or when the audio-only stream switches back to the video\n     * stream, the SDK triggers the [onRemoteSubscribeFallbackToAudioOnly]{@link AgoraRtcEvents.onRemoteSubscribeFallbackToAudioOnly}\n     * callback.\n     *\n     * @param  option  Sets the fallback option for the remotely subscribed video stream. See\n     * [STREAM_FALLBACK_OPTIONS]{@link AgoraRtcEngine.STREAM_FALLBACK_OPTIONS}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setRemoteSubscribeFallbackOption(option) {\n        return callNativeMethod(API_TYPE.SET_REMOTE_SUBSCRIBE_FALLBACK_OPTION, {\n            option: option,\n        });\n    }\n    AgoraRtcEngine.setRemoteSubscribeFallbackOption = setRemoteSubscribeFallbackOption;\n    /**\n     * Switches between front and rear cameras.\n     *\n     * @param direction Sets the camera to be used. See [CAMERA_DIRECTION]{@link AgoraRtcEngine.CAMERA_DIRECTION}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function switchCamera(direction) {\n        if (direction === undefined) {\n            return callNativeMethod(API_TYPE.SWITCH_CAMERA);\n        }\n        return callNativeMethod(API_TYPE.SWITCH_CAMERA_2, { direction: direction });\n    }\n    AgoraRtcEngine.switchCamera = switchCamera;\n    /**\n     * Sets the default audio playback route.\n     *\n     * This method sets whether the received audio is routed to the earpiece or speakerphone by default before joining a channel.\n     *\n     * If a user does not call this method, the audio is routed to the earpiece by default. If you need to change the default\n     * audio route after joining a channel, call the [setEnableSpeakerphone]{@link AgoraRtcEngine.setEnableSpeakerphone} method.\n     *\n     * The default setting for each profile:\n     * - `COMMUNICATION`: In a voice call, the default audio route is the earpiece. In a video call, the default audio\n     * route is the speakerphone. If a user who is in the `COMMUNICATION` profile calls the\n     * [disableVideo]{@link AgoraRtcEngine.disableVideo} method or if the user calls the\n     * [muteLocalVideoStream]{@link AgoraRtcEngine.muteLocalVideoStream} and\n     * [muteAllRemoteVideoStreams]{@link AgoraRtcEngine.muteAllRemoteVideoStreams} methods, the default audio route switches\n     * back to the earpiece automatically.\n     * - `LIVE_BROADCASTING`: Speakerphone.\n     *\n     * **Note**\n     *\n     * - This method is applicable only to the `COMMUNICATION` profile.\n     * - For iOS, this method only works in a voice call.\n     * - Call this method before calling the [joinChannel]{@link AgoraRtcEngine.joinChannel} method.\n     *\n     * @param defaultToSpeaker Sets the default audio route:\n     * - true: Route the audio to the speakerphone. If the playback device connects to the earpiece or Bluetooth, the\n     * audio cannot be routed to the speakerphone.\n     * - false: (Default) Route the audio to the earpiece. If a headset is plugged in, the audio is routed to the headset.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setDefaultAudioRouteToSpeakerphone(defaultToSpeaker) {\n        return callNativeMethod(API_TYPE.SET_DEFAULT_AUDIO_ROUTE_SPEAKER_PHONE, {\n            defaultToSpeaker: defaultToSpeaker,\n        });\n    }\n    AgoraRtcEngine.setDefaultAudioRouteToSpeakerphone = setDefaultAudioRouteToSpeakerphone;\n    /**\n     * Enables/Disables the audio playback route to the speakerphone.\n     *\n     * This method sets whether the audio is routed to the speakerphone or earpiece.\n     *\n     * See the default audio route explanation in the\n     * [setDefaultAudioRouteToSpeakerphone]{@link AgoraRtcEngine.setDefaultAudioRouteToSpeakerphone} method and check whether it\n     * is necessary to call this method.\n     *\n     * **Note**\n     *\n     * - Ensure that you have successfully called the [joinChannel]{@link AgoraRtcEngine.joinChannel} method before calling this method.\n     * - After calling this method, the SDK returns the [onAudioRouteChanged]{@link AgoraRtcEvents.onAudioRouteChanged}\n     * callback to indicate the changes.\n     * - This method does not take effect if a headset is used.\n     *\n     * @param speakerOn Sets whether to route the audio to the speakerphone or earpiece:\n     * - true: Route the audio to the speakerphone. If the playback device connects to the earpiece or Bluetooth, the\n     * audio cannot be routed to the speakerphone.\n     * - false: Route the audio to the earpiece. If a headset is plugged in, the audio is routed to the headset.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setEnableSpeakerphone(speakerOn) {\n        return callNativeMethod(API_TYPE.SET_ENABLE_SPEAKER_PHONE, { speakerOn: speakerOn });\n    }\n    AgoraRtcEngine.setEnableSpeakerphone = setEnableSpeakerphone;\n    /**\n     * Enables in-ear monitoring.\n     *\n     * @param enabled Determines whether to enable in-ear monitoring.\n     * - true: Enable.\n     * - false: (Default) Disable.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableInEarMonitoring(enabled) {\n        return callNativeMethod(API_TYPE.ENABLE_IN_EAR_MONITORING, { enabled: enabled });\n    }\n    AgoraRtcEngine.enableInEarMonitoring = enableInEarMonitoring;\n    /**\n     * Sets the volume of the in-ear monitor.\n     *\n     * @param volume Sets the volume of the in-ear monitor. The value ranges between 0 and 100 (default).\n     *\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setInEarMonitoringVolume(volume) {\n        return callNativeMethod(API_TYPE.SET_IN_EAR_MONITORING_VOLUME, { volume: volume });\n    }\n    AgoraRtcEngine.setInEarMonitoringVolume = setInEarMonitoringVolume;\n    /**\n     * Checks whether the speakerphone is enabled.\n     *\n     * @return\n     * - true: The speakerphone is enabled, and the audio plays from the speakerphone.\n     * - false: The speakerphone is not enabled, and the audio plays from devices other than the speakerphone. For example, the headset or earpiece.\n     */\n    function isSpeakerphoneEnabled() {\n        return callNativeMethod(API_TYPE.IS_SPEAKER_PHONE_ENABLED);\n    }\n    AgoraRtcEngine.isSpeakerphoneEnabled = isSpeakerphoneEnabled;\n    /**\n     * TODO\n     *\n     * @param restriction\n     */\n    function setAudioSessionOperationRestriction(restriction) {\n        return callNativeMethod(API_TYPE.SET_AUDIO_SESSION_OPERATION_RESTRICTION, {\n            restriction: restriction,\n        });\n    }\n    AgoraRtcEngine.setAudioSessionOperationRestriction = setAudioSessionOperationRestriction;\n    /**\n     * TODO\n     *\n     * @param enabled\n     * @param deviceName\n     */\n    function enableLoopbackRecording(enabled, deviceName) {\n        return callNativeMethod(API_TYPE.ENABLE_LOOP_BACK_RECORDING, {\n            enabled: enabled,\n            deviceName: deviceName,\n        });\n    }\n    AgoraRtcEngine.enableLoopbackRecording = enableLoopbackRecording;\n    /**\n     * TODO\n     *\n     * @param displayId\n     * @param regionRect\n     * @param captureParams\n     */\n    function startScreenCaptureByDisplayId(displayId, regionRect, captureParams) {\n        return callNativeMethod(API_TYPE.START_SCREEN_CAPTURE_BY_DISPLAY_ID, {\n            displayId: displayId,\n            regionRect: regionRect,\n            captureParams: captureParams,\n        });\n    }\n    AgoraRtcEngine.startScreenCaptureByDisplayId = startScreenCaptureByDisplayId;\n    /**\n     * TODO\n     *\n     * @param screenRect\n     * @param regionRect\n     * @param captureParams\n     */\n    function startScreenCaptureByScreenRect(screenRect, regionRect, captureParams) {\n        return callNativeMethod(API_TYPE.START_SCREEN_CAPTURE_BY_SCREEN_RECT, {\n            screenRect: screenRect,\n            regionRect: regionRect,\n            captureParams: captureParams,\n        });\n    }\n    AgoraRtcEngine.startScreenCaptureByScreenRect = startScreenCaptureByScreenRect;\n    /**\n     * TODO\n     *\n     * @param windowId\n     * @param regionRect\n     * @param captureParams\n     */\n    function startScreenCaptureByWindowId(windowId, regionRect, captureParams) {\n        return callNativeMethod(API_TYPE.START_SCREEN_CAPTURE_BY_WINDOW_ID, {\n            windowId: windowId,\n            regionRect: regionRect,\n            captureParams: captureParams,\n        });\n    }\n    AgoraRtcEngine.startScreenCaptureByWindowId = startScreenCaptureByWindowId;\n    /**\n     * TODO\n     *\n     * @param contentHint\n     */\n    function setScreenCaptureContentHint(contentHint) {\n        return callNativeMethod(API_TYPE.SET_SCREEN_CAPTURE_CONTENT_HINT, {\n            contentHint: contentHint,\n        });\n    }\n    AgoraRtcEngine.setScreenCaptureContentHint = setScreenCaptureContentHint;\n    /**\n     * TODO\n     *\n     * @param captureParams\n     */\n    function updateScreenCaptureParameters(captureParams) {\n        return callNativeMethod(API_TYPE.UPDATE_SCREEN_CAPTURE_PARAMETERS, {\n            captureParams: captureParams,\n        });\n    }\n    AgoraRtcEngine.updateScreenCaptureParameters = updateScreenCaptureParameters;\n    /**\n     * TODO\n     *\n     * @param regionRect\n     */\n    function updateScreenCaptureRegion(regionRect) {\n        return callNativeMethod(API_TYPE.UPDATE_SCREEN_CAPTURE_REGION, {\n            regionRect: regionRect,\n        });\n    }\n    AgoraRtcEngine.updateScreenCaptureRegion = updateScreenCaptureRegion;\n    /**\n     * TODO\n     */\n    function stopScreenCapture() {\n        return callNativeMethod(API_TYPE.STOP_SCREEN_CAPTURE);\n    }\n    AgoraRtcEngine.stopScreenCapture = stopScreenCapture;\n    /**\n     * Retrieves the current call ID.\n     *\n     * When a user joins a channel on a client, a `callId` is generated to identify the call from the client. Feedback\n     * methods, such as [rate]{@link AgoraRtcEngine.rate} and [complain]{@link AgoraRtcEngine.complain} , must be called after the call\n     * ends to submit feedback to the SDK.\n     *\n     * The `rate` and `complain` methods require the `callId` parameter retrieved from the `getCallId` method during a\n     * call. `callId` is passed as an argument into the `rate` and `complain` methods after the call ends.\n     *\n     * @return The current call ID.\n     */\n    function getCallId() {\n        return callNativeMethod(API_TYPE.GET_CALL_ID);\n    }\n    AgoraRtcEngine.getCallId = getCallId;\n    /**\n     * Allows a user to rate a call after the call ends.\n     *\n     * @param callId The ID of the call, retrieved from the [getCallId]{@link AgoraRtcEngine.getCallId} method.\n     * @param rating  Rating of the call. The value is between 1 (lowest score) and 5 (highest score). If you set a\n     * value out of this range, the `ERR_INVALID_ARGUMENT(-2)` error returns.\n     * @param description (Optional) The description of the rating, with a string length of less than 800 bytes.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function rate(callId, rating, description) {\n        return callNativeMethod(API_TYPE.RATE, { callId: callId, rating: rating, description: description });\n    }\n    AgoraRtcEngine.rate = rate;\n    /**\n     * Allows a user to complain about the call quality after a call ends.\n     *\n     * @param callId The ID of the call, retrieved from the [getCallId]{@link AgoraRtcEngine.getCallId} method.\n     * @param description (Optional) The description of the complaint, with a string length of less than 800 bytes.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function complain(callId, description) {\n        return callNativeMethod(API_TYPE.COMPLAIN, { callId: callId, description: description });\n    }\n    AgoraRtcEngine.complain = complain;\n    /**\n     * Retrieves the SDK version number.\n     *\n     * @return The version of the current SDK in the string format. For example, `\"3.1.2\"`.\n     */\n    function getVersion() {\n        return callNativeMethod(API_TYPE.GET_VERSION);\n    }\n    AgoraRtcEngine.getVersion = getVersion;\n    /**\n     * Enables the network connection quality test.\n     *\n     * This method tests the quality of the users' network connections and is disabled by default.\n     *\n     * Before a user joins a channel or before an audience switches to a host, call this method to check the uplink network quality.\n     *\n     * This method consumes additional network traffic, and hence may affect communication quality.\n     *\n     * Call the [disableLastmileTest]{@link AgoraRtcEngine.disableLastmileTest} method to disable this test after receiving\n     * the [onLastmileQuality]{@link AgoraRtcEvents.onLastmileQuality} callback, and before joining a channel.\n     *\n     * **Note**\n     *\n     * - Do not call any other methods before receiving the `onLastmileQuality` callback. Otherwise, the callback may\n     * be interrupted by other methods, and hence may not be triggered.\n     * - A host should not call this method after joining a channel (when in a call).\n     * - If you call this method to test the last-mile quality, the SDK consumes the bandwidth of a video stream, whose\n     * bitrate corresponds to the bitrate you set in the\n     * [setVideoEncoderConfiguration]{@link AgoraRtcEngine.setVideoEncoderConfiguration} method. After you join the channel,\n     * whether you have called the `disableLastmileTest` method or not, the SDK automatically stops consuming the bandwidth.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function enableLastmileTest() {\n        return callNativeMethod(API_TYPE.ENABLE_LAST_MILE_TEST);\n    }\n    AgoraRtcEngine.enableLastmileTest = enableLastmileTest;\n    /**\n     * Disables the network connection quality test.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function disableLastmileTest() {\n        return callNativeMethod(API_TYPE.DISABLE_LAST_MILE_TEST);\n    }\n    AgoraRtcEngine.disableLastmileTest = disableLastmileTest;\n    /**\n     * Starts the last-mile network probe test.\n     *\n     * This method starts the last-mile network probe test before joining a channel to get the uplink and downlink last-mile network\n     * statistics, including the bandwidth, packet loss, jitter, and round-trip time (RTT).\n     *\n     * Call this method to check the uplink network quality before users join a channel or before an audience switches to a host.\n     *\n     * Once this method is enabled, the SDK returns the following callbacks:\n     * - [onLastmileQuality]{@link AgoraRtcEvents.onLastmileQuality}: the SDK triggers this callback within two seconds\n     * depending on the network conditions. This callback rates the network conditions and is more closely linked to the user experience.\n     * - [onLastmileProbeResult]{@link AgoraRtcEvents.onLastmileProbeResult}: the SDK triggers this callback within 30 seconds depending\n     * on the network conditions. This callback returns the real-time statistics of the network conditions and is more objective.\n     *\n     * **Note**\n     *\n     * - This method consumes extra network traffic and may affect communication quality. We do not recommend calling this method\n     * together with [enableLastmileTest]{@link AgoraRtcEngine.enableLastmileTest}.\n     * - Do not call other methods before receiving the `onLastmileQuality` and `onLastmileProbeResult` callbacks. Otherwise,\n     * the callbacks may be interrupted.\n     * - In the `LIVE_BROADCASTING` profile, a host should not call this method after joining a channel.\n     *\n     * @param config Sets the configurations of the last-mile network probe test. See\n     * [LastmileProbeConfig]{@link AgoraRtcEngine.LastmileProbeConfig}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function startLastmileProbeTest(config) {\n        return callNativeMethod(API_TYPE.START_LAST_MILE_PROBE_TEST, { config: config });\n    }\n    AgoraRtcEngine.startLastmileProbeTest = startLastmileProbeTest;\n    /**\n     * Stops the last-mile network probe test.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function stopLastmileProbeTest() {\n        return callNativeMethod(API_TYPE.STOP_LAST_MILE_PROBE_TEST);\n    }\n    AgoraRtcEngine.stopLastmileProbeTest = stopLastmileProbeTest;\n    /**\n     * Retrieves the warning or error description.\n     *\n     * @param code Warning code or error code returned in the [onWarning]{@link AgoraRtcEvents.onWarning} or\n     * [onError]{@link AgoraRtcEvents.onError} callback.\n     *\n     * @return See [WARN_CODE_TYPE]{@link AgoraRtcEngine.WARN_CODE_TYPE} or [ERROR_CODE_TYPE]{@link AgoraRtcEngine.ERROR_CODE_TYPE}.\n     */\n    function getErrorDescription(code) {\n        return callNativeMethod(API_TYPE.GET_ERROR_DESCRIPTION, { code: code });\n    }\n    AgoraRtcEngine.getErrorDescription = getErrorDescription;\n    /**\n     * Enables built-in encryption with an encryption password before users join a channel.\n     *\n     * @deprecated This method is deprecated from v3.1.2. Use the [enableEncryption]{@link AgoraRtcEngine.enableEncryption} instead.\n     *\n     * All users in a channel must use the same encryption password. The encryption password is automatically cleared\n     * once a user leaves the channel.\n     *\n     * If an encryption password is not specified, the encryption functionality will be disabled.\n     *\n     * **Note**\n     *\n     * - Do not use this method for CDN live streaming.\n     * - For optimal transmission, ensure that the encrypted data size does not exceed the original data size + 16\n     * bytes. 16 bytes is the maximum padding size for AES encryption.\n     *\n     * @param secret The encryption password.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setEncryptionSecret(secret) {\n        return callNativeMethod(API_TYPE.SET_ENCRYPTION_SECTRT, { secret: secret });\n    }\n    AgoraRtcEngine.setEncryptionSecret = setEncryptionSecret;\n    /**\n     * Sets the built-in encryption mode.\n     *\n     * @deprecated This method is deprecated from v3.1.2. Use the [enableEncryption]{@link AgoraRtcEngine.enableEncryption} instead.\n     *\n     * The Agora SDK supports built-in encryption, which is set to the `aes-128-xts` mode by default. Call this method\n     * to use other encryption modes.\n     * All users in the same channel must use the same encryption mode and password.\n     *\n     * Refer to the information related to the AES encryption algorithm on the differences between the encryption modes.\n     *\n     * @note Call the [setEncryptionSecret]{@link AgoraRtcEngine.setEncryptionSecret} method to enable the built-in encryption\n     * function before calling this method.\n     *\n     * @param encryptionMode The set encryption mode:\n     * - \"aes-128-xts\": (Default) 128-bit AES encryption, XTS mode.\n     * - \"aes-128-ecb\": 128-bit AES encryption, ECB mode.\n     * - \"aes-256-xts\": 256-bit AES encryption, XTS mode.\n     * - \"\": When encryptionMode is set as `null`, the encryption mode is set as \"aes-128-xts\" by default.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setEncryptionMode(encryptionMode) {\n        return callNativeMethod(API_TYPE.SET_ENCRYPTION_MODE, { encryptionMode: encryptionMode });\n    }\n    AgoraRtcEngine.setEncryptionMode = setEncryptionMode;\n    /**\n     * Enables/Disables the built-in encryption.\n     *\n     * In scenarios requiring high security, Agora recommends calling this method to enable the built-in encryption\n     * before joining a channel.\n     *\n     * All users in the same channel must use the same encryption mode and encryption key. Once all users leave the\n     * channel, the encryption key of this channel is automatically cleared.\n     *\n     * **Note**\n     *\n     * - If you enable the built-in encryption, you cannot use the RTMP streaming function.\n     * - Agora supports four encryption modes. If you choose an encryption mode (excepting `SM4_128_ECB` mode), you\n     * need to add an external encryption library when integrating the Android or iOS SDK.\n     *\n     * @param enabled Whether to enable the built-in encryption:\n     * - true: Enable the built-in encryption.\n     * - false: Disable the built-in encryption.\n     * @param config Configurations of built-in encryption schemas. See [EncryptionConfig]{@link AgoraRtcEngine.EncryptionConfig}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     *  - -2(ERR_INVALID_ARGUMENT): An invalid parameter is used. Set the parameter with a valid value.\n     *  - -4(ERR_NOT_SUPPORTED): The encryption mode is incorrect or the SDK fails to load the external encryption\n     * library. Check the enumeration or reload the external encryption library.\n     *  - -7(ERR_NOT_INITIALIZED): The SDK is not initialized. Initialize the Agora engine before calling this method.\n     */\n    function enableEncryption(enabled, config) {\n        return callNativeMethod(API_TYPE.ENABLE_ENCRYPTION, { enabled: enabled, config: config });\n    }\n    AgoraRtcEngine.enableEncryption = enableEncryption;\n    /**\n     * Registers a packet observer.\n     *\n     * The Agora SDK allows your application to register a packet observer to receive callbacks for voice or video packet transmission.\n     *\n     * **Note**\n     *\n     * - The size of the packet sent to the network after processing should not exceed 1200 bytes, otherwise, the packet may fail to\n     * be sent.\n     * - Ensure that both receivers and senders call this method, otherwise, you may meet undefined behaviors such as no voice and\n     * black screen.\n     * - When you use CDN live streaming, recording or storage functions, Agora doesn't recommend calling this method.\n     *\n     * @param observer The registered packet observer.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function registerPacketObserver(observer) {\n        return callNativeMethod(API_TYPE.REGISTER_PACKET_OBSERVER, { observer: observer });\n    }\n    AgoraRtcEngine.registerPacketObserver = registerPacketObserver;\n    /**\n     * Creates a data stream.\n     *\n     * Each user can create up to five data streams during the lifecycle of the Agora engine.\n     *\n     * @note Set both the `reliable` and `ordered` parameters to `true` or `false`. Do not set one as `true` and the other as `false`.\n     *\n     * @param streamId The ID of the created data stream.\n     * @param reliable Sets whether or not the recipients are guaranteed to receive the data stream from the sender within five seconds:\n     * - true: The recipients receive the data stream from the sender within five seconds. If the recipient does not receive the\n     * data stream within five seconds, an error is reported to the application.\n     * - false: There is no guarantee that the recipients receive the data stream within five seconds and no error message is\n     * reported for any delay or missing data stream.\n     * @param ordered Sets whether or not the recipients receive the data stream in the sent order:\n     * - true: The recipients receive the data stream in the sent order.\n     * - false: The recipients do not receive the data stream in the sent order.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function createDataStream(streamId, reliable, ordered) {\n        return callNativeMethod(API_TYPE.CREATE_DATA_STREAM, {\n            streamId: streamId,\n            reliable: reliable,\n            ordered: ordered,\n        });\n    }\n    AgoraRtcEngine.createDataStream = createDataStream;\n    /**\n     * Sends data stream messages to all users in a channel.\n     *\n     * The SDK has the following restrictions on this method:\n     * - Up to 30 packets can be sent per second in a channel with each packet having a maximum size of 1 kB.\n     * - Each client can send up to 6 kB of data per second.\n     * - Each user can have up to five data streams simultaneously.\n     *\n     * A successful `sendStreamMessage` method call triggers the [onStreamMessage]{@link AgoraRtcEvents.onStreamMessage}\n     * callback on the remote client, from which the remote user gets the stream message. A failed `sendStreamMessage`\n     * method call triggers the [onStreamMessageError]{@link AgoraRtcEvents.onStreamMessageError} callback on the remote client.\n     *\n     * @note This method applies only to the `COMMUNICATION` profile or to the hosts in the `LIVE_BROADCASTING` profile.\n     * If an audience in the `LIVE_BROADCASTING` profile calls this method, the audience may be switched to a host.\n     *\n     * @param streamId ID of the sent data stream, returned in the [createDataStream]{@link AgoraRtcEngine.createDataStream} method.\n     * @param data The sent data.\n     * @param length Length of the sent data.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function sendStreamMessage(streamId, data, length) {\n        return callNativeMethod(API_TYPE.SEND_STREAM_MESSAGE, { streamId: streamId, length: length }, data);\n    }\n    AgoraRtcEngine.sendStreamMessage = sendStreamMessage;\n    /**\n     * Publishes the local stream to a specified CDN live RTMP address. (CDN live only.)\n     *\n     * The SDK returns the result of this method call in the [onStreamPublished]{@link AgoraRtcEvents.onStreamPublished} callback.\n     *\n     * The `addPublishStreamUrl` method call triggers the [onRtmpStreamingStateChanged]{@link AgoraRtcEvents.onRtmpStreamingStateChanged}\n     * callback on the local client to report the state of adding a local stream to the CDN.\n     *\n     * **Note**\n     *\n     * - Ensure that the user joins the channel before calling this method.\n     * - Ensure that you enable the RTMP Converter service before using this function.\n     * - This method adds only one stream RTMP URL address each time it is called.\n     * - This method applies to `LIVE_BROADCASTING` only.\n     *\n     * @param url The CDN streaming URL in the RTMP format. The maximum length of this parameter is 1024 bytes. The RTMP URL address\n     * must not contain special characters, such as Chinese language characters.\n     * @param transcodingEnabled Sets whether transcoding is enabled/disabled:\n     * - true: Enable transcoding. To [transcode](https://docs.AgoraRtcEngine.io/en/Agora%20Platform/terms?platform=All%20Platforms#transcoding)\n     * the audio or video streams when publishing them to CDN live, often used for combining the audio and video streams of multiple\n     * hosts in CDN live. If you set this parameter as `true`, ensure that you call the\n     * [setLiveTranscoding]{@link AgoraRtcEngine.setLiveTranscoding} method before this method.\n     * - false: Disable transcoding.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     *   - -2(ERR_INVALID_ARGUMENT): The RTMP URL address is `null` or has a string length of 0.\n     *   - -7(ERR_NOT_INITIALIZED): You have not initialized the Agora engine when publishing the stream.\n     */\n    function addPublishStreamUrl(url, transcodingEnabled) {\n        return callNativeMethod(API_TYPE.ADD_PUBLISH_STREAM_URL, {\n            url: url,\n            transcodingEnabled: transcodingEnabled,\n        });\n    }\n    AgoraRtcEngine.addPublishStreamUrl = addPublishStreamUrl;\n    /**\n     * Removes an RTMP stream from the CDN. (CDN live only.)\n     *\n     * This method removes the RTMP URL address (added by the [addPublishStreamUrl]{@link AgoraRtcEngine.addPublishStreamUrl}\n     * method) from a CDN live stream. The SDK returns the result of this method call in the\n     * [onStreamUnpublished]{@link AgoraRtcEvents.onStreamUnpublished} callback.\n     *\n     * The `removePublishStreamUrl` method call triggers the\n     * [onRtmpStreamingStateChanged]{@link AgoraRtcEvents.onRtmpStreamingStateChanged} callback on the local client to report the\n     * state of removing an RTMP stream from the CDN.\n     *\n     * **Note**\n     *\n     * - This method removes only one RTMP URL address each time it is called.\n     * - The RTMP URL address must not contain special characters, such as Chinese language characters.\n     * - This method applies to `LIVE_BROADCASTING` only.\n     *\n     * @param url The RTMP URL address to be removed. The maximum length of this parameter is 1024 bytes.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function removePublishStreamUrl(url) {\n        return callNativeMethod(API_TYPE.REMOVE_PUBLISH_STREAM_URL, { url: url });\n    }\n    AgoraRtcEngine.removePublishStreamUrl = removePublishStreamUrl;\n    /**\n     * Sets the video layout and audio settings for CDN live. (CDN live only.)\n     *\n     * The SDK triggers the [onTranscodingUpdated]{@link AgoraRtcEvents.onTranscodingUpdated} callback when you call the\n     * `setLiveTranscoding` method to update the transcoding setting.\n     *\n     * **Note**\n     *\n     * - This method applies to `LIVE_BROADCASTING` only.\n     * - Ensure that you enable the RTMP Converter service before using this function.\n     * - If you call the `setLiveTranscoding` method to update the transcoding setting for the first time, the SDK does\n     * not trigger the `onTranscodingUpdated` callback.\n     *\n     * @param transcoding Sets the CDN live audio/video transcoding settings. See [LiveTranscoding]{@link AgoraRtcEngine.LiveTranscoding}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setLiveTranscoding(transcoding) {\n        return callNativeMethod(API_TYPE.SET_LIVE_TRANSCODING, { transcoding: transcoding });\n    }\n    AgoraRtcEngine.setLiveTranscoding = setLiveTranscoding;\n    /**\n     * Adds a watermark image to the local video.\n     *\n     * This method adds a PNG watermark image to the local video in the live streaming. Once the watermark image is added, all\n     * the audience in the channel (CDN audience included), and the recording device can see and capture it. Agora supports\n     * adding only one watermark image onto the local video, and the newly watermark image replaces the previous one.\n     *\n     * The watermark position depends on the settings in the [setVideoEncoderConfiguration]{@link AgoraRtcEngine.setVideoEncoderConfiguration}\n     * method:\n     * - If the orientation mode of the encoding video is\n     * [ORIENTATION_MODE_FIXED_LANDSCAPE]{@link AgoraRtcEngine.ORIENTATION_MODE.ORIENTATION_MODE_FIXED_LANDSCAPE} or the landscape mode in\n     * [ORIENTATION_MODE_ADAPTIVE]{@link AgoraRtcEngine.ORIENTATION_MODE.ORIENTATION_MODE_ADAPTIVE}, the watermark uses the landscape orientation.\n     * - If the orientation mode of the encoding video is\n     * [ORIENTATION_MODE_FIXED_PORTRAIT]{@link AgoraRtcEngine.ORIENTATION_MODE.ORIENTATION_MODE_FIXED_PORTRAIT} or the portrait mode in\n     * [ORIENTATION_MODE_ADAPTIVE]{@link AgoraRtcEngine.ORIENTATION_MODE.ORIENTATION_MODE_ADAPTIVE}, the watermark uses the portrait orientation.\n     * - When setting the watermark position, the region must be less than the dimensions set in the `setVideoEncoderConfiguration`\n     * method. Otherwise, the watermark image will be cropped.\n     *\n     * **Note**\n     *\n     * - Ensure that you have called the [enableVideo]{@link AgoraRtcEngine.enableVideo} method to enable the video module before calling this\n     * method.\n     * - If you only want to add a watermark image to the local video for the audience in the CDN live streaming channel to see and\n     * capture, you can call this method or the [setLiveTranscoding]{@link AgoraRtcEngine.setLiveTranscoding} method.\n     * - This method supports adding a watermark image in the PNG file format only. Supported pixel formats of the PNG image are RGBA,\n     * RGB, Palette, Gray, and Alpha_gray.\n     * - If the dimensions of the PNG image differ from your settings in this method, the image will be cropped or zoomed to conform\n     * to your settings.\n     * - If you have enabled the local video preview by calling the [startPreview]{@link AgoraRtcEngine.startPreview} method, you can use the\n     * `visibleInPreview` member in the `WatermarkOptions` class to set whether or not the watermark is visible in preview.\n     * - If you have enabled the mirror mode for the local video, the watermark on the local video is also mirrored. To avoid mirroring\n     * the watermark, Agora recommends that you do not use the mirror and watermark functions for the local video at the same time.\n     * You can implement the watermark function in your application layer.\n     *\n     * @param watermarkUrl The local file path of the watermark image to be added. This method supports adding a watermark image\n     * from the local absolute or relative file path.\n     * @param options The watermark's options to be added. See [WatermarkOptions]{@link AgoraRtcEngine.WatermarkOptions}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function addVideoWatermark(watermarkUrl, options) {\n        return callNativeMethod(API_TYPE.ADD_VIDEO_WATER_MARK_2, {\n            watermarkUrl: watermarkUrl,\n            options: options,\n        });\n    }\n    AgoraRtcEngine.addVideoWatermark = addVideoWatermark;\n    /**\n     * Removes the watermark image from the video stream added by the\n     * [addVideoWatermark]{@link AgoraRtcEngine.addVideoWatermark} method.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function clearVideoWatermarks() {\n        return callNativeMethod(API_TYPE.CLEAR_VIDEO_WATER_MARKS);\n    }\n    AgoraRtcEngine.clearVideoWatermarks = clearVideoWatermarks;\n    /**\n     * Enables/Disables image enhancement and sets the options.\n     *\n     * **Note**\n     *\n     * - Call this method after calling the [enableVideo]{@link AgoraRtcEngine.enableVideo} method.\n     * - Currently this method does not apply for macOS.\n     *\n     * @param enabled Sets whether or not to enable image enhancement:\n     * - true: enables image enhancement.\n     * - false: disables image enhancement.\n     * @param options Sets the image enhancement option. See BeautyOptions.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setBeautyEffectOptions(enabled, options) {\n        return callNativeMethod(API_TYPE.SET_BEAUTY_EFFECT_OPTIONS, {\n            enabled: enabled,\n            options: options,\n        });\n    }\n    AgoraRtcEngine.setBeautyEffectOptions = setBeautyEffectOptions;\n    /**\n     * Adds a voice or video stream URL address to the live streaming.\n     *\n     * The [onStreamPublished]{@link AgoraRtcEvents.onStreamPublished} callback returns the inject status. If this method\n     * call is successful, the server pulls the voice or video stream and injects it into a live channel. This is\n     * applicable to scenarios where all audience members in the channel can watch a live show and interact with each other.\n     *\n     * The `addInjectStreamUrl` method call triggers the following callbacks:\n     * - The local client:\n     *   - [onStreamInjectedStatus]{@link AgoraRtcEvents.onStreamInjectedStatus}, with the state of the injecting the online stream.\n     *   - [onUserJoined]{@link AgoraRtcEvents.onUserJoined}(uid: 666), if the method call is successful and the online media stream\n     * is injected into the channel.\n     * - The remote client: [onUserJoined]{@link AgoraRtcEvents.onUserJoined}(uid: 666), if the method call is successful and the\n     * online media stream is injected into the channel.\n     *\n     * **Note**\n     *\n     * - Ensure that you enable the RTMP Converter service before using this function.\n     * - This method applies to the SDK of v3.1.2 and later.\n     * - This method applies to the `LIVE_BROADCASTING` profile only.\n     * - You can inject only one media stream into the channel at the same time.\n     *\n     * @param url The URL address to be added to the ongoing streaming. Valid protocols are RTMP, HLS, and HTTP-FLV.\n     * - Supported audio codec type: AAC.\n     * - Supported video codec type: H264 (AVC).\n     * @param config [InjectStreamConfig]{@link AgoraRtcEngine.InjectStreamConfig} contains the configuration of\n     * the added voice or video stream.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     *   - -2(`ERR_INVALID_ARGUMENT`): The injected URL does not exist. Call this method again to inject the stream and\n     * ensure that the URL is valid.\n     *   - -3(`ERR_NOT_READY`): The user is not in the channel.\n     *   - -4(`ERR_NOT_SUPPORTED`): The channel profile is not `LIVE_BROADCASTING`. Call the\n     * [setChannelProfile]{@link AgoraRtcEngine.setChannelProfile} method and set the channel profile to `LIVE_BROADCASTING`\n     * before calling this method.\n     *   - -7(ERR_NOT_INITIALIZED): The SDK is not initialized. Ensure that the Agora engine is initialized before\n     * calling this method.\n     */\n    function addInjectStreamUrl(url, config) {\n        return callNativeMethod(API_TYPE.ADD_INJECT_STREAM_URL, { url: url, config: config });\n    }\n    AgoraRtcEngine.addInjectStreamUrl = addInjectStreamUrl;\n    /**\n     * Starts to relay media streams across channels.\n     *\n     * After a successful method call, the SDK triggers the\n     * [onChannelMediaRelayStateChanged]{@link AgoraRtcEvents.onChannelMediaRelayStateChanged} and\n     * [onChannelMediaRelayEvent]{@link AgoraRtcEvents.onChannelMediaRelayEvent} callbacks, and these callbacks return the\n     * state and events of the media stream relay.\n     * - If the `onChannelMediaRelayStateChanged` callback returns\n     * [RELAY_STATE_RUNNING]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_STATE.RELAY_STATE_RUNNING}(2) and\n     * [RELAY_OK]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_ERROR.RELAY_OK}(0), and the `onChannelMediaRelayEvent` callback returns\n     * [RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_EVENT.RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL}(4),\n     * the host starts sending data to the destination channel.\n     * - If the `onChannelMediaRelayStateChanged` callback returns\n     * [RELAY_STATE_FAILURE]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_STATE.RELAY_STATE_FAILURE}(3), an exception occurs during\n     * the media stream relay.\n     *\n     * **Note**\n     *\n     * - Call this method after the [joinChannel]{@link AgoraRtcEngine.joinChannel} method.\n     * - This method takes effect only when you are a host in a `LIVE_BROADCASTING` channel.\n     * - After a successful method call, if you want to call this method again, ensure that you call the\n     * [stopChannelMediaRelay]{@link AgoraRtcEngine.stopChannelMediaRelay} method to quit the current relay.\n     * - Contact sales-us@AgoraRtcEngine.io before implementing this function.\n     * - We do not support string user accounts in this API.\n     *\n     * @param configuration The configuration of the media stream relay:\n     * [ChannelMediaRelayConfiguration]{@link AgoraRtcEngine.ChannelMediaRelayConfiguration}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function startChannelMediaRelay(configuration) {\n        return callNativeMethod(API_TYPE.START_CHANNEL_MEDIA_RELAY, {\n            configuration: configuration,\n        });\n    }\n    AgoraRtcEngine.startChannelMediaRelay = startChannelMediaRelay;\n    /**\n     * Updates the channels for media stream relay.\n     *\n     * After a successful [startChannelMediaRelay]{@link AgoraRtcEngine.startChannelMediaRelay} method call, if you want to\n     * relay the media  stream to more channels, or leave the current relay channel, you can call the\n     * [updateChannelMediaRelay]{@link AgoraRtcEngine.updateChannelMediaRelay} method.\n     *\n     * After a successful method call, the SDK triggers the\n     * [onChannelMediaRelayEvent]{@link AgoraRtcEvents.onChannelMediaRelayEvent} callback with the\n     * [RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_EVENT.RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL}(7)\n     * state code.\n     *\n     * @note Call this method after the `startChannelMediaRelay` method to update the destination channel.\n     *\n     * @param configuration The media stream relay configuration:\n     * [ChannelMediaRelayConfiguration]{@link AgoraRtcEngine.ChannelMediaRelayConfiguration}.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function updateChannelMediaRelay(configuration) {\n        return callNativeMethod(API_TYPE.UPDATE_CHANNEL_MEDIA_RELAY, {\n            configuration: configuration,\n        });\n    }\n    AgoraRtcEngine.updateChannelMediaRelay = updateChannelMediaRelay;\n    /**\n     * Stops the media stream relay.\n     *\n     * Once the relay stops, the host quits all the destination channels.\n     *\n     * After a successful method call, the SDK triggers the\n     * [onChannelMediaRelayStateChanged]{@link AgoraRtcEvents.onChannelMediaRelayStateChanged} callback. If the callback returns\n     * [RELAY_STATE_IDLE]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_STATE.RELAY_STATE_IDLE}(0) and\n     * [RELAY_OK]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_ERROR.RELAY_OK}(0), the host successfully stops the relay.\n     *\n     * @note If the method call fails, the SDK triggers the `onChannelMediaRelayStateChanged` callback with the\n     * [RELAY_ERROR_SERVER_NO_RESPONSE]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_ERROR.RELAY_ERROR_SERVER_NO_RESPONSE}(2) or\n     * [RELAY_ERROR_SERVER_CONNECTION_LOST]{@link AgoraRtcEngine.CHANNEL_MEDIA_RELAY_ERROR.RELAY_ERROR_SERVER_CONNECTION_LOST}(8) state code.\n     * You can leave the channel by calling the [leaveChannel]{@link AgoraRtcEngine.leaveChannel} method, and the media stream relay\n     * automatically stops.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function stopChannelMediaRelay() {\n        return callNativeMethod(API_TYPE.STOP_CHANNEL_MEDIA_RELAY);\n    }\n    AgoraRtcEngine.stopChannelMediaRelay = stopChannelMediaRelay;\n    /**\n     * Removes the voice or video stream URL address from the live streaming.\n     *\n     * This method removes the URL address (added by the [addInjectStreamUrl]{@link AgoraRtcEngine.addInjectStreamUrl} method) from the\n     * live streaming.\n     *\n     * @note If this method is called successfully, the SDK triggers the [onUserOffline]{@link AgoraRtcEvents.onUserOffline} callback\n     * and returns a stream `uid` of `666`.\n     *\n     * @param url The URL address of the injected stream to be removed.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function removeInjectStreamUrl(url) {\n        return callNativeMethod(API_TYPE.REMOVE_INJECT_STREAM_URL, { url: url });\n    }\n    AgoraRtcEngine.removeInjectStreamUrl = removeInjectStreamUrl;\n    /**\n     * Agora supports reporting and analyzing customized messages.\n     *\n     * This function is in the beta stage with a free trial. The ability provided in its beta test version is reporting a maximum of\n     * 10 message pieces within 6 seconds, with each message piece not exceeding 256 bytes.\n     *\n     * To try out this function, contact [support@AgoraRtcEngine.io](mailto:support@AgoraRtcEngine.io) and discuss the format of customized messages\n     * with us.\n     */\n    function sendCustomReportMessage(id, category, event, label, value) {\n        return callNativeMethod(API_TYPE.SEND_CUSTOM_REPORT_MESSAGE, {\n            id: id,\n            category: category,\n            event: event,\n            label: label,\n            value: value,\n        });\n    }\n    AgoraRtcEngine.sendCustomReportMessage = sendCustomReportMessage;\n    /**\n     * Gets the current connection state of the SDK.\n     *\n     * @return See [CONNECTION_STATE_TYPE]{@link AgoraRtcEngine.CONNECTION_STATE_TYPE}.\n     */\n    function getConnectionState() {\n        return callNativeMethod(API_TYPE.GET_CONNECTION_STATE);\n    }\n    AgoraRtcEngine.getConnectionState = getConnectionState;\n    /**\n     * TODO\n     *\n     * @param userId\n     * @param enable\n     */\n    function enableRemoteSuperResolution(userId, enable) {\n        return callNativeMethod(API_TYPE.ENABLE_REMOTE_SUPER_RESOLUTION, {\n            userId: userId,\n            enable: enable,\n        });\n    }\n    AgoraRtcEngine.enableRemoteSuperResolution = enableRemoteSuperResolution;\n    /**\n     * Sends the metadata.\n     *\n     * **Note**\n     *\n     * - Call this method after [registerMediaMetadataObserver]{@link AgoraRtcEngine.registerMediaMetadataObserver}.\n     * - Ensure that the size of the metadata does not exceed the value set in the\n     * [setMaxMetadataSize]{@link AgoraRtcEngine.setMaxMetadataSize} callback.\n     *\n     * @param uid ID of the user who sends the metadata.\n     * @param size The size of the sent metadata.\n     * @param buffer The sent metadata.\n     * @param timeStampMs The timestamp (ms) of the metadata.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function sendMetadata(_a) {\n        var uid = _a.uid, size = _a.size, buffer = _a.buffer, timeStampMs = _a.timeStampMs;\n        return callNativeMethod(API_TYPE.SEND_METADATA, { uid: uid, size: size, timeStampMs: timeStampMs }, buffer);\n    }\n    AgoraRtcEngine.sendMetadata = sendMetadata;\n    /**\n     * Sets the maximum size of the [Metadata]{@link AgoraRtcEngine.Metadata}.\n     *\n     * The metadata includes the following parameters:\n     * - `uid`: ID of the user who sends the metadata.\n     * - `size`: The size of the sent or received metadata.\n     * - `buffer`: The sent or received metadata.\n     * - `timeStampMs`: The timestamp (ms) of the metadata.\n     *\n     * @note Call this method after [registerMediaMetadataObserver]{@link AgoraRtcEngine.registerMediaMetadataObserver}.\n     *\n     * @param size The maximum size of the buffer of the metadata that you want to use. The highest value is 1024 bytes.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setMaxMetadataSize(size) {\n        return callNativeMethod(API_TYPE.SET_MAX_META_SIZE, { size: size });\n    }\n    AgoraRtcEngine.setMaxMetadataSize = setMaxMetadataSize;\n    /**\n     * Registers the metadata observer.\n     *\n     * You need to specify the metadata type in this method.\n     *\n     * This method enables you to add synchronized metadata in the video stream for more diversified live interactive\n     * streaming, such as sending shopping links, digital coupons, and online quizzes.\n     *\n     * **Note**\n     *\n     * - Call this method before the [joinChannel]{@link AgoraRtcEngine.joinChannel} method.\n     * - This method applies to the `LIVE_BROADCASTING` channel profile.\n     *\n     * @param type See [METADATA_TYPE]{@link AgoraRtcEngine.METADATA_TYPE}. The SDK supports `VIDEO_METADATA(0)` only for now.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function registerMediaMetadataObserver(type) {\n        return callNativeMethod(API_TYPE.REGISTER_MEDIA_META_DATA_OBSERVER, {\n            type: type,\n        });\n    }\n    AgoraRtcEngine.registerMediaMetadataObserver = registerMediaMetadataObserver;\n    /**\n     * Provides technical preview functionalities or special customizations by configuring the SDK with JSON options.\n     *\n     * The JSON options are not public by default. Agora is working on making commonly used JSON options public in a standard way.\n     *\n     * @param parameters Sets the parameter as a JSON string in the specified format.\n     *\n     * @return\n     * - 0: Success.\n     * - < 0: Failure.\n     */\n    function setParameters(parameters) {\n        return callNativeMethod(API_TYPE.SET_PARAMETERS, { parameters: parameters });\n    }\n    AgoraRtcEngine.setParameters = setParameters;\n})(AgoraRtcEngine || (AgoraRtcEngine = {}));\n(function (AgoraRtcEngine) {\n    AgoraRtcEngine.audioDeviceManager = {\n        enumeratePlaybackDevices: function () {\n            var count = callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.GET_COUNT);\n            return __spreadArrays(Array(count)).map(function (_, index) {\n                var device = callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.GET_DEVICE, {\n                    index: index,\n                });\n                return device;\n            });\n        },\n        enumerateRecordingDevices: function () {\n            var count = callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.GET_COUNT);\n            return __spreadArrays(Array(count)).map(function (_, index) {\n                var device = callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.GET_DEVICE, {\n                    index: index,\n                });\n                return device;\n            });\n        },\n        getPlaybackDevice: function () {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.GET_CURRENT_DEVICE);\n        },\n        getPlaybackDeviceInfo: function () {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.GET_CURRENT_DEVICE_INFO);\n        },\n        getPlaybackDeviceMute: function () {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.GET_DEVICE_MUTE);\n        },\n        getPlaybackDeviceVolume: function () {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.GET_DEVICE_VOLUME);\n        },\n        getRecordingDevice: function () {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.GET_CURRENT_DEVICE);\n        },\n        getRecordingDeviceInfo: function () {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.GET_CURRENT_DEVICE_INFO);\n        },\n        getRecordingDeviceMute: function () {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.GET_DEVICE_MUTE);\n        },\n        getRecordingDeviceVolume: function () {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.GET_DEVICE_VOLUME);\n        },\n        release: function () {\n            // TODO\n        },\n        setPlaybackDevice: function (deviceId) {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.SET_DEVICE, {\n                deviceId: deviceId,\n            });\n        },\n        setPlaybackDeviceMute: function (mute) {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.SET_DEVICE_MUTE, {\n                mute: mute,\n            });\n        },\n        setPlaybackDeviceVolume: function (volume) {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.SET_DEVICE_VOLUME, { volume: volume });\n        },\n        setRecordingDevice: function (deviceId) {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.SET_DEVICE, {\n                deviceId: deviceId,\n            });\n        },\n        setRecordingDeviceMute: function (mute) {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.SET_DEVICE_MUTE, { mute: mute });\n        },\n        setRecordingDeviceVolume: function (volume) {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.SET_DEVICE_VOLUME, { volume: volume });\n        },\n        startAudioDeviceLoopbackTest: function (indicationInterval) {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.START_AUDIO_DEVICE_LOOP_BACK_TEST, { indicationInterval: indicationInterval });\n            // TODO return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.START_AUDIO_DEVICE_LOOP_BACK_TEST, {indicationInterval});\n        },\n        startPlaybackDeviceTest: function (testAudioFilePath) {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.START_DEVICE_TEST, { testAudioFilePath: testAudioFilePath });\n        },\n        startRecordingDeviceTest: function (indicationInterval) {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.START_DEVICE_TEST, { indicationInterval: indicationInterval });\n        },\n        stopAudioDeviceLoopbackTest: function () {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.STOP_AUDIO_DEVICE_LOOP_BACK_TEST);\n            // TODO return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.STOP_AUDIO_DEVICE_LOOP_BACK_TEST);\n        },\n        stopPlaybackDeviceTest: function () {\n            return callNativeMethodPlayback(API_TYPE_DEVICE_MANAGER.STOP_DEVICE_TEST);\n        },\n        stopRecordingDeviceTest: function () {\n            return callNativeMethodRecording(API_TYPE_DEVICE_MANAGER.STOP_DEVICE_TEST);\n        },\n    };\n    AgoraRtcEngine.videoDeviceManager = {\n        enumerateVideoDevices: function () {\n            var count = callNativeMethodVideo(API_TYPE_DEVICE_MANAGER.GET_COUNT);\n            return __spreadArrays(Array(count)).map(function (_, index) {\n                var device = callNativeMethodVideo(API_TYPE_DEVICE_MANAGER.GET_DEVICE, {\n                    index: index,\n                });\n                return device;\n            });\n        },\n        getDevice: function () {\n            return callNativeMethodVideo(API_TYPE_DEVICE_MANAGER.GET_CURRENT_DEVICE);\n        },\n        release: function () {\n            // TODO\n        },\n        setDevice: function (deviceId) {\n            return callNativeMethodVideo(API_TYPE_DEVICE_MANAGER.SET_DEVICE, {\n                deviceId: deviceId,\n            });\n        },\n        startDeviceTest: function (hwnd) {\n            return callNativeMethodVideo(API_TYPE_DEVICE_MANAGER.START_DEVICE_TEST, {\n                hwnd: hwnd,\n            });\n        },\n        stopDeviceTest: function () {\n            return callNativeMethodVideo(API_TYPE_DEVICE_MANAGER.STOP_DEVICE_TEST);\n        },\n    };\n})(AgoraRtcEngine || (AgoraRtcEngine = {}));\n\n\n//# sourceURL=webpack://agora-cef-sdk/./src/AgoraRtcEngine.ts?");

/***/ }),

/***/ "./node_modules/yuv-buffer/yuv-buffer.js":
/*!***********************************************!*\
  !*** ./node_modules/yuv-buffer/yuv-buffer.js ***!
  \***********************************************/
/***/ (function(module) {

eval("/*\nCopyright (c) 2014-2016 Brion Vibber <brion@pobox.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n\n/**\n * Represents metadata about a YUV frame format.\n * @typedef {Object} YUVFormat\n * @property {number} width - width of encoded frame in luma pixels\n * @property {number} height - height of encoded frame in luma pixels\n * @property {number} chromaWidth - width of encoded frame in chroma pixels\n * @property {number} chromaHeight - height of encoded frame in chroma pixels\n * @property {number} cropLeft - upper-left X coordinate of visible crop region, in luma pixels\n * @property {number} cropTop - upper-left Y coordinate of visible crop region, in luma pixels\n * @property {number} cropWidth - width of visible crop region, in luma pixels\n * @property {number} cropHeight - height of visible crop region, in luma pixels\n * @property {number} displayWidth - final display width of visible region, in luma pixels\n * @property {number} displayHeight - final display height of visible region, in luma pixels\n */\n\n/**\n * Represents underlying image data for a single luma or chroma plane.\n * Cannot be interpreted without the format data from a frame buffer.\n * @typedef {Object} YUVPlane\n * @property {Uint8Array} bytes - typed array containing image data bytes\n * @property {number} stride - byte distance between rows in data\n */\n\n/**\n * Represents a YUV image frame buffer, with enough format information\n * to interpret the data usefully. Buffer objects use generic objects\n * under the hood and can be transferred between worker threads using\n * the structured clone algorithm.\n *\n * @typedef {Object} YUVFrame\n * @property {YUVFormat} format\n * @property {YUVPlane} y\n * @property {YUVPlane} u\n * @property {YUVPlane} v\n */\n\n/**\n * Holder namespace for utility functions and constants related to\n * YUV frame and plane buffers.\n *\n * @namespace\n */\nvar YUVBuffer = {\n  /**\n   * Validate a plane dimension\n   * @param {number} dim - vertical or horizontal dimension\n   * @throws exception on zero, negative, or non-integer value\n   */\n  validateDimension: function(dim) {\n    if (dim <= 0 || dim !== (dim | 0)) {\n      throw 'YUV plane dimensions must be a positive integer';\n    }\n  },\n\n  /**\n   * Validate a plane offset\n   * @param {number} dim - vertical or horizontal dimension\n   * @throws exception on negative or non-integer value\n   */\n  validateOffset: function(dim) {\n    if (dim < 0 || dim !== (dim | 0)) {\n      throw 'YUV plane offsets must be a non-negative integer';\n    }\n  },\n\n  /**\n   * Validate and fill out a YUVFormat object structure.\n   *\n   * At least width and height fields are required; other fields will be\n   * derived if left missing or empty:\n   * - chromaWidth and chromaHeight will be copied from width and height as for a 4:4:4 layout\n   * - cropLeft and cropTop will be 0\n   * - cropWidth and cropHeight will be set to whatever of the frame is visible after cropTop and cropLeft are applied\n   * - displayWidth and displayHeight will be set to cropWidth and cropHeight.\n   *\n   * @param {YUVFormat} fields - input fields, must include width and height.\n   * @returns {YUVFormat} - validated structure, with all derivable fields filled out.\n   * @throws exception on invalid fields or missing width/height\n   */\n  format: function(fields) {\n    var width = fields.width,\n      height = fields.height,\n      chromaWidth = fields.chromaWidth || width,\n      chromaHeight = fields.chromaHeight || height,\n      cropLeft = fields.cropLeft || 0,\n      cropTop = fields.cropTop || 0,\n      cropWidth = fields.cropWidth || width - cropLeft,\n      cropHeight = fields.cropHeight || height - cropTop,\n      displayWidth = fields.displayWidth || cropWidth,\n      displayHeight = fields.displayHeight || cropHeight;\n    this.validateDimension(width);\n    this.validateDimension(height);\n    this.validateDimension(chromaWidth);\n    this.validateDimension(chromaHeight);\n    this.validateOffset(cropLeft);\n    this.validateOffset(cropTop);\n    this.validateDimension(cropWidth);\n    this.validateDimension(cropHeight);\n    this.validateDimension(displayWidth);\n    this.validateDimension(displayHeight);\n    return {\n      width: width,\n      height: height,\n      chromaWidth: chromaWidth,\n      chromaHeight: chromaHeight,\n      cropLeft: cropLeft,\n      cropTop: cropTop,\n      cropWidth: cropWidth,\n      cropHeight: cropHeight,\n      displayWidth: displayWidth,\n      displayHeight: displayHeight\n    };\n  },\n\n  /**\n   * Allocate a new YUVPlane object of the given size.\n   * @param {number} stride - byte distance between rows\n   * @param {number} rows - number of rows to allocate\n   * @returns {YUVPlane} - freshly allocated planar buffer\n   */\n  allocPlane: function(stride, rows) {\n    YUVBuffer.validateDimension(stride);\n    YUVBuffer.validateDimension(rows);\n    return {\n      bytes: new Uint8Array(stride * rows),\n      stride: stride\n    }\n  },\n\n  /**\n   * Pick a suitable stride for a custom-allocated thingy\n   * @param {number} width - width in bytes\n   * @returns {number} - new width in bytes at least as large\n   * @throws exception on invalid input width\n   */\n  suitableStride: function(width) {\n    YUVBuffer.validateDimension(width);\n    var alignment = 4,\n      remainder = width % alignment;\n    if (remainder == 0) {\n      return width;\n    } else {\n      return width + (alignment - remainder);\n    }\n  },\n\n  /**\n   * Allocate or extract a YUVPlane object from given dimensions/source.\n   * @param {number} width - width in pixels\n   * @param {number} height - height in pixels\n   * @param {Uint8Array} source - input byte array; optional (will create empty buffer if missing)\n   * @param {number} stride - row length in bytes; optional (will create a default if missing)\n   * @param {number} offset - offset into source array to extract; optional (will start at 0 if missing)\n   * @returns {YUVPlane} - freshly allocated planar buffer\n   */\n  allocPlane: function(width, height, source, stride, offset) {\n    var size, bytes;\n\n    this.validateDimension(width);\n    this.validateDimension(height);\n\n    offset = offset || 0;\n\n    stride = stride || this.suitableStride(width);\n    this.validateDimension(stride);\n    if (stride < width) {\n      throw \"Invalid input stride for YUV plane; must be larger than width\";\n    }\n\n    size = stride * height;\n\n    if (source) {\n      if (source.length - offset < size) {\n        throw \"Invalid input buffer for YUV plane; must be large enough for stride times height\";\n      }\n      bytes = source.slice(offset, offset + size);\n    } else {\n      bytes = new Uint8Array(size);\n      stride = stride || this.suitableStride(width);\n    }\n\n    return {\n      bytes: bytes,\n      stride: stride\n    };\n  },\n\n  /**\n   * Allocate a new YUVPlane object big enough for a luma plane in the given format\n   * @param {YUVFormat} format - target frame format\n   * @param {Uint8Array} source - input byte array; optional (will create empty buffer if missing)\n   * @param {number} stride - row length in bytes; optional (will create a default if missing)\n   * @param {number} offset - offset into source array to extract; optional (will start at 0 if missing)\n   * @returns {YUVPlane} - freshly allocated planar buffer\n   */\n  lumaPlane: function(format, source, stride, offset) {\n    return this.allocPlane(format.width, format.height, source, stride, offset);\n  },\n\n  /**\n   * Allocate a new YUVPlane object big enough for a chroma plane in the given format,\n   * optionally copying data from an existing buffer.\n   *\n   * @param {YUVFormat} format - target frame format\n   * @param {Uint8Array} source - input byte array; optional (will create empty buffer if missing)\n   * @param {number} stride - row length in bytes; optional (will create a default if missing)\n   * @param {number} offset - offset into source array to extract; optional (will start at 0 if missing)\n   * @returns {YUVPlane} - freshly allocated planar buffer\n   */\n  chromaPlane: function(format, source, stride, offset) {\n    return this.allocPlane(format.chromaWidth, format.chromaHeight, source, stride, offset);\n  },\n\n  /**\n   * Allocate a new YUVFrame object big enough for the given format\n   * @param {YUVFormat} format - target frame format\n   * @param {YUVPlane} y - optional Y plane; if missing, fresh one will be allocated\n   * @param {YUVPlane} u - optional U plane; if missing, fresh one will be allocated\n   * @param {YUVPlane} v - optional V plane; if missing, fresh one will be allocated\n   * @returns {YUVFrame} - freshly allocated frame buffer\n   */\n  frame: function(format, y, u, v) {\n    y = y || this.lumaPlane(format);\n    u = u || this.chromaPlane(format);\n    v = v || this.chromaPlane(format);\n    return {\n      format: format,\n      y: y,\n      u: u,\n      v: v\n    }\n  },\n\n  /**\n   * Duplicate a plane using new buffer memory.\n   * @param {YUVPlane} plane - input plane to copy\n   * @returns {YUVPlane} - freshly allocated and filled planar buffer\n   */\n  copyPlane: function(plane) {\n    return {\n      bytes: plane.bytes.slice(),\n      stride: plane.stride\n    };\n  },\n\n  /**\n   * Duplicate a frame using new buffer memory.\n   * @param {YUVFrame} frame - input frame to copyFrame\n   * @returns {YUVFrame} - freshly allocated and filled frame buffer\n   */\n  copyFrame: function(frame) {\n    return {\n      format: frame.format,\n      y: this.copyPlane(frame.y),\n      u: this.copyPlane(frame.u),\n      v: this.copyPlane(frame.v)\n    }\n  },\n\n  /**\n   * List the backing buffers for the frame's planes for transfer between\n   * threads via Worker.postMessage.\n   * @param {YUVFrame} frame - input frame\n   * @returns {Array} - list of transferable objects\n   */\n  transferables: function(frame) {\n    return [frame.y.bytes.buffer, frame.u.bytes.buffer, frame.v.bytes.buffer];\n  }\n};\n\nmodule.exports = YUVBuffer;\n\n\n//# sourceURL=webpack://agora-cef-sdk/./node_modules/yuv-buffer/yuv-buffer.js?");

/***/ }),

/***/ "./node_modules/yuv-canvas/build/shaders.js":
/*!**************************************************!*\
  !*** ./node_modules/yuv-canvas/build/shaders.js ***!
  \**************************************************/
/***/ (function(module) {

eval("module.exports = {\n  vertex: \"precision lowp float;\\n\\nattribute vec2 aPosition;\\nattribute vec2 aLumaPosition;\\nattribute vec2 aChromaPosition;\\nvarying vec2 vLumaPosition;\\nvarying vec2 vChromaPosition;\\nvoid main() {\\n    gl_Position = vec4(aPosition, 0, 1);\\n    vLumaPosition = aLumaPosition;\\n    vChromaPosition = aChromaPosition;\\n}\\n\",\n  fragment: \"// inspired by https://github.com/mbebenita/Broadway/blob/master/Player/canvas.js\\n\\nprecision lowp float;\\n\\nuniform sampler2D uTextureY;\\nuniform sampler2D uTextureCb;\\nuniform sampler2D uTextureCr;\\nvarying vec2 vLumaPosition;\\nvarying vec2 vChromaPosition;\\nvoid main() {\\n   // Y, Cb, and Cr planes are uploaded as LUMINANCE textures.\\n   float fY = texture2D(uTextureY, vLumaPosition).x;\\n   float fCb = texture2D(uTextureCb, vChromaPosition).x;\\n   float fCr = texture2D(uTextureCr, vChromaPosition).x;\\n\\n   // Premultipy the Y...\\n   float fYmul = fY * 1.1643828125;\\n\\n   // And convert that to RGB!\\n   gl_FragColor = vec4(\\n     fYmul + 1.59602734375 * fCr - 0.87078515625,\\n     fYmul - 0.39176171875 * fCb - 0.81296875 * fCr + 0.52959375,\\n     fYmul + 2.017234375   * fCb - 1.081390625,\\n     1\\n   );\\n}\\n\",\n  vertexStripe: \"precision lowp float;\\n\\nattribute vec2 aPosition;\\nattribute vec2 aTexturePosition;\\nvarying vec2 vTexturePosition;\\n\\nvoid main() {\\n    gl_Position = vec4(aPosition, 0, 1);\\n    vTexturePosition = aTexturePosition;\\n}\\n\",\n  fragmentStripe: \"// extra 'stripe' texture fiddling to work around IE 11's poor performance on gl.LUMINANCE and gl.ALPHA textures\\n\\nprecision lowp float;\\n\\nuniform sampler2D uStripe;\\nuniform sampler2D uTexture;\\nvarying vec2 vTexturePosition;\\nvoid main() {\\n   // Y, Cb, and Cr planes are mapped into a pseudo-RGBA texture\\n   // so we can upload them without expanding the bytes on IE 11\\n   // which doesn't allow LUMINANCE or ALPHA textures\\n   // The stripe textures mark which channel to keep for each pixel.\\n   // Each texture extraction will contain the relevant value in one\\n   // channel only.\\n\\n   float fLuminance = dot(\\n      texture2D(uStripe, vTexturePosition),\\n      texture2D(uTexture, vTexturePosition)\\n   );\\n\\n   gl_FragColor = vec4(fLuminance, fLuminance, fLuminance, 1);\\n}\\n\"\n};\n\n\n//# sourceURL=webpack://agora-cef-sdk/./node_modules/yuv-canvas/build/shaders.js?");

/***/ }),

/***/ "./node_modules/yuv-canvas/src/FrameSink.js":
/*!**************************************************!*\
  !*** ./node_modules/yuv-canvas/src/FrameSink.js ***!
  \**************************************************/
/***/ (function(module) {

eval("(function() {\n  \"use strict\";\n\n  /**\n   * Create a YUVCanvas and attach it to an HTML5 canvas element.\n   *\n   * This will take over the drawing context of the canvas and may turn\n   * it into a WebGL 3d canvas if possible. Do not attempt to use the\n   * drawing context directly after this.\n   *\n   * @param {HTMLCanvasElement} canvas - HTML canvas element to attach to\n   * @param {YUVCanvasOptions} options - map of options\n   * @throws exception if WebGL requested but unavailable\n   * @constructor\n   * @abstract\n   */\n  function FrameSink(canvas, options) {\n    throw new Error('abstract');\n  }\n\n  /**\n   * Draw a single YUV frame on the underlying canvas, converting to RGB.\n   * If necessary the canvas will be resized to the optimal pixel size\n   * for the given buffer's format.\n   *\n   * @param {YUVBuffer} buffer - the YUV buffer to draw\n   * @see {@link https://www.npmjs.com/package/yuv-buffer|yuv-buffer} for format\n   */\n  FrameSink.prototype.drawFrame = function(buffer) {\n    throw new Error('abstract');\n  };\n\n  /**\n   * Clear the canvas using appropriate underlying 2d or 3d context.\n   */\n  FrameSink.prototype.clear = function() {\n    throw new Error('abstract');\n  };\n\n  module.exports = FrameSink;\n\n})();\n\n\n//# sourceURL=webpack://agora-cef-sdk/./node_modules/yuv-canvas/src/FrameSink.js?");

/***/ }),

/***/ "./node_modules/yuv-canvas/src/SoftwareFrameSink.js":
/*!**********************************************************!*\
  !*** ./node_modules/yuv-canvas/src/SoftwareFrameSink.js ***!
  \**********************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

eval("/*\nCopyright (c) 2014-2016 Brion Vibber <brion@pobox.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n(function() {\n\t\"use strict\";\n\n\tvar FrameSink = __webpack_require__(/*! ./FrameSink.js */ \"./node_modules/yuv-canvas/src/FrameSink.js\"),\n\t\tYCbCr = __webpack_require__(/*! ./YCbCr.js */ \"./node_modules/yuv-canvas/src/YCbCr.js\");\n\n\t/**\n\t * @param {HTMLCanvasElement} canvas - HTML canvas eledment to attach to\n\t * @constructor\n\t */\n\tfunction SoftwareFrameSink(canvas) {\n\t\tvar self = this,\n\t\t\tctx = canvas.getContext('2d'),\n\t\t\timageData = null,\n\t\t\tresampleCanvas = null,\n\t\t\tresampleContext = null;\n\n\n\n\t\tfunction initImageData(width, height) {\n\t\t\timageData = ctx.createImageData(width, height);\n\n\t\t\t// Prefill the alpha to opaque\n\t\t\tvar data = imageData.data,\n\t\t\t\tpixelCount = width * height * 4;\n\t\t\tfor (var i = 0; i < pixelCount; i += 4) {\n\t\t\t\tdata[i + 3] = 255;\n\t\t\t}\n\t\t}\n\n\t\tfunction initResampleCanvas(cropWidth, cropHeight) {\n\t\t\tresampleCanvas = document.createElement('canvas');\n\t\t\tresampleCanvas.width = cropWidth;\n\t\t\tresampleCanvas.height = cropHeight;\n\t\t\tresampleContext = resampleCanvas.getContext('2d');\n\t\t}\n\n\t\t/**\n\t\t * Actually draw a frame into the canvas.\n\t\t * @param {YUVFrame} buffer - YUV frame buffer object to draw\n\t\t */\n\t\tself.drawFrame = function drawFrame(buffer) {\n\t\t\tvar format = buffer.format;\n\n\t\t\tif (canvas.width !== format.displayWidth || canvas.height !== format.displayHeight) {\n\t\t\t\t// Keep the canvas at the right size...\n\t\t\t\tcanvas.width = format.displayWidth;\n\t\t\t\tcanvas.height = format.displayHeight;\n\t\t\t}\n\n\t\t\tif (imageData === null ||\n\t\t\t\t\timageData.width != format.width ||\n\t\t\t\t\timageData.height != format.height) {\n\t\t\t\tinitImageData(format.width, format.height);\n\t\t\t}\n\n\t\t\t// YUV -> RGB over the entire encoded frame\n\t\t\tYCbCr.convertYCbCr(buffer, imageData.data);\n\n\t\t\tvar resample = (format.cropWidth != format.displayWidth || format.cropHeight != format.displayHeight);\n\t\t\tvar drawContext;\n\t\t\tif (resample) {\n\t\t\t\t// hack for non-square aspect-ratio\n\t\t\t\t// putImageData doesn't resample, so we have to draw in two steps.\n\t\t\t\tif (!resampleCanvas) {\n\t\t\t\t\tinitResampleCanvas(format.cropWidth, format.cropHeight);\n\t\t\t\t}\n\t\t\t\tdrawContext = resampleContext;\n\t\t\t} else {\n\t\t\t\tdrawContext = ctx;\n\t\t\t}\n\n\t\t\t// Draw cropped frame to either the final or temporary canvas\n\t\t\tdrawContext.putImageData(imageData,\n\t\t\t\t-format.cropLeft, -format.cropTop, // must offset the offset\n\t\t\t\tformat.cropLeft, format.cropTop,\n\t\t\t\tformat.cropWidth, format.cropHeight);\n\n\t\t\tif (resample) {\n\t\t\t\tctx.drawImage(resampleCanvas, 0, 0, format.displayWidth, format.displayHeight);\n\t\t\t}\n\t\t};\n\n\t\tself.clear = function() {\n\t\t\tctx.clearRect(0, 0, canvas.width, canvas.height);\n\t\t};\n\n\t\treturn self;\n\t}\n\n\tSoftwareFrameSink.prototype = Object.create(FrameSink.prototype);\n\n\tmodule.exports = SoftwareFrameSink;\n})();\n\n\n//# sourceURL=webpack://agora-cef-sdk/./node_modules/yuv-canvas/src/SoftwareFrameSink.js?");

/***/ }),

/***/ "./node_modules/yuv-canvas/src/WebGLFrameSink.js":
/*!*******************************************************!*\
  !*** ./node_modules/yuv-canvas/src/WebGLFrameSink.js ***!
  \*******************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

eval("/*\nCopyright (c) 2014-2016 Brion Vibber <brion@pobox.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n(function() {\n\t\"use strict\";\n\n\tvar FrameSink = __webpack_require__(/*! ./FrameSink.js */ \"./node_modules/yuv-canvas/src/FrameSink.js\"),\n\t\tshaders = __webpack_require__(/*! ../build/shaders.js */ \"./node_modules/yuv-canvas/build/shaders.js\");\n\n\t/**\n\t * Warning: canvas must not have been used for 2d drawing prior!\n\t *\n\t * @param {HTMLCanvasElement} canvas - HTML canvas element to attach to\n\t * @constructor\n\t */\n\tfunction WebGLFrameSink(canvas) {\n\t\tvar self = this,\n\t\t\tgl = WebGLFrameSink.contextForCanvas(canvas),\n\t\t\tdebug = false; // swap this to enable more error checks, which can slow down rendering\n\n\t\tif (gl === null) {\n\t\t\tthrow new Error('WebGL unavailable');\n\t\t}\n\n\t\t// GL!\n\t\tfunction checkError() {\n\t\t\tif (debug) {\n\t\t\t\terr = gl.getError();\n\t\t\t\tif (err !== 0) {\n\t\t\t\t\tthrow new Error(\"GL error \" + err);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfunction compileShader(type, source) {\n\t\t\tvar shader = gl.createShader(type);\n\t\t\tgl.shaderSource(shader, source);\n\t\t\tgl.compileShader(shader);\n\n\t\t\tif (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {\n\t\t\t\tvar err = gl.getShaderInfoLog(shader);\n\t\t\t\tgl.deleteShader(shader);\n\t\t\t\tthrow new Error('GL shader compilation for ' + type + ' failed: ' + err);\n\t\t\t}\n\n\t\t\treturn shader;\n\t\t}\n\n\n\t\tvar program,\n\t\t\tunpackProgram,\n\t\t\terr;\n\n\t\t// In the world of GL there are no rectangles.\n\t\t// There are only triangles.\n\t\t// THERE IS NO SPOON.\n\t\tvar rectangle = new Float32Array([\n\t\t\t// First triangle (top left, clockwise)\n\t\t\t-1.0, -1.0,\n\t\t\t+1.0, -1.0,\n\t\t\t-1.0, +1.0,\n\n\t\t\t// Second triangle (bottom right, clockwise)\n\t\t\t-1.0, +1.0,\n\t\t\t+1.0, -1.0,\n\t\t\t+1.0, +1.0\n\t\t]);\n\n\t\tvar textures = {};\n\t\tvar framebuffers = {};\n\t\tvar stripes = {};\n\t\tvar buf, positionLocation, unpackPositionLocation;\n\t\tvar unpackTexturePositionBuffer, unpackTexturePositionLocation;\n\t\tvar stripeLocation, unpackTextureLocation;\n\t\tvar lumaPositionBuffer, lumaPositionLocation;\n\t\tvar chromaPositionBuffer, chromaPositionLocation;\n\n\t\tfunction createOrReuseTexture(name) {\n\t\t\tif (!textures[name]) {\n\t\t\t\ttextures[name] = gl.createTexture();\n\t\t\t}\n\t\t\treturn textures[name];\n\t\t}\n\n\t\tfunction uploadTexture(name, width, height, data) {\n\t\t\tvar texture = createOrReuseTexture(name);\n\t\t\tgl.activeTexture(gl.TEXTURE0);\n\n\t\t\tif (WebGLFrameSink.stripe) {\n\t\t\t\tvar uploadTemp = !textures[name + '_temp'];\n\t\t\t\tvar tempTexture = createOrReuseTexture(name + '_temp');\n\t\t\t\tgl.bindTexture(gl.TEXTURE_2D, tempTexture);\n\t\t\t\tif (uploadTemp) {\n\t\t\t\t\t// new texture\n\t\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n\t\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n\t\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\n\t\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\n\t\t\t\t\tgl.texImage2D(\n\t\t\t\t\t\tgl.TEXTURE_2D,\n\t\t\t\t\t\t0, // mip level\n\t\t\t\t\t\tgl.RGBA, // internal format\n\t\t\t\t\t\twidth / 4,\n\t\t\t\t\t\theight,\n\t\t\t\t\t\t0, // border\n\t\t\t\t\t\tgl.RGBA, // format\n\t\t\t\t\t\tgl.UNSIGNED_BYTE, // type\n\t\t\t\t\t\tdata // data!\n\t\t\t\t\t);\n\t\t\t\t} else {\n\t\t\t\t\t// update texture\n\t\t\t\t\tgl.texSubImage2D(\n\t\t\t\t\t\tgl.TEXTURE_2D,\n\t\t\t\t\t\t0, // mip level\n\t\t\t\t\t\t0, // x offset\n\t\t\t\t\t\t0, // y offset\n\t\t\t\t\t\twidth / 4,\n\t\t\t\t\t\theight,\n\t\t\t\t\t\tgl.RGBA, // format\n\t\t\t\t\t\tgl.UNSIGNED_BYTE, // type\n\t\t\t\t\t\tdata // data!\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\tvar stripeTexture = textures[name + '_stripe'];\n\t\t\t\tvar uploadStripe = !stripeTexture;\n\t\t\t\tif (uploadStripe) {\n\t\t\t\t\tstripeTexture = createOrReuseTexture(name + '_stripe');\n\t\t\t\t}\n\t\t\t\tgl.bindTexture(gl.TEXTURE_2D, stripeTexture);\n\t\t\t\tif (uploadStripe) {\n\t\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n\t\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n\t\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\n\t\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\n\t\t\t\t\tgl.texImage2D(\n\t\t\t\t\t\tgl.TEXTURE_2D,\n\t\t\t\t\t\t0, // mip level\n\t\t\t\t\t\tgl.RGBA, // internal format\n\t\t\t\t\t\twidth,\n\t\t\t\t\t\t1,\n\t\t\t\t\t\t0, // border\n\t\t\t\t\t\tgl.RGBA, // format\n\t\t\t\t\t\tgl.UNSIGNED_BYTE, //type\n\t\t\t\t\t\tbuildStripe(width, 1) // data!\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t} else {\n\t\t\t\tgl.bindTexture(gl.TEXTURE_2D, texture);\n\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);\n\t\t\t\tgl.texImage2D(\n\t\t\t\t\tgl.TEXTURE_2D,\n\t\t\t\t\t0, // mip level\n\t\t\t\t\tgl.LUMINANCE, // internal format\n\t\t\t\t\twidth,\n\t\t\t\t\theight,\n\t\t\t\t\t0, // border\n\t\t\t\t\tgl.LUMINANCE, // format\n\t\t\t\t\tgl.UNSIGNED_BYTE, //type\n\t\t\t\t\tdata // data!\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\n\t\tfunction unpackTexture(name, width, height) {\n\t\t\tvar texture = textures[name];\n\n\t\t\t// Upload to a temporary RGBA texture, then unpack it.\n\t\t\t// This is faster than CPU-side swizzling in ANGLE on Windows.\n\t\t\tgl.useProgram(unpackProgram);\n\n\t\t\tvar fb = framebuffers[name];\n\t\t\tif (!fb) {\n\t\t\t\t// Create a framebuffer and an empty target size\n\t\t\t\tgl.activeTexture(gl.TEXTURE0);\n\t\t\t\tgl.bindTexture(gl.TEXTURE_2D, texture);\n\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n\t\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);\n\t\t\t\tgl.texImage2D(\n\t\t\t\t\tgl.TEXTURE_2D,\n\t\t\t\t\t0, // mip level\n\t\t\t\t\tgl.RGBA, // internal format\n\t\t\t\t\twidth,\n\t\t\t\t\theight,\n\t\t\t\t\t0, // border\n\t\t\t\t\tgl.RGBA, // format\n\t\t\t\t\tgl.UNSIGNED_BYTE, //type\n\t\t\t\t\tnull // data!\n\t\t\t\t);\n\n\t\t\t\tfb = framebuffers[name] = gl.createFramebuffer();\n\t\t\t}\n\n\t\t\tgl.bindFramebuffer(gl.FRAMEBUFFER, fb);\n\t\t\tgl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);\n\n\t\t\tvar tempTexture = textures[name + '_temp'];\n\t\t\tgl.activeTexture(gl.TEXTURE1);\n\t\t\tgl.bindTexture(gl.TEXTURE_2D, tempTexture);\n\t\t\tgl.uniform1i(unpackTextureLocation, 1);\n\n\t\t\tvar stripeTexture = textures[name + '_stripe'];\n\t\t\tgl.activeTexture(gl.TEXTURE2);\n\t\t\tgl.bindTexture(gl.TEXTURE_2D, stripeTexture);\n\t\t\tgl.uniform1i(stripeLocation, 2);\n\n\t\t\t// Rectangle geometry\n\t\t\tgl.bindBuffer(gl.ARRAY_BUFFER, buf);\n\t\t\tgl.enableVertexAttribArray(positionLocation);\n\t\t\tgl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);\n\n\t\t\t// Set up the texture geometry...\n\t\t\tgl.bindBuffer(gl.ARRAY_BUFFER, unpackTexturePositionBuffer);\n\t\t\tgl.enableVertexAttribArray(unpackTexturePositionLocation);\n\t\t\tgl.vertexAttribPointer(unpackTexturePositionLocation, 2, gl.FLOAT, false, 0, 0);\n\n\t\t\t// Draw into the target texture...\n\t\t\tgl.viewport(0, 0, width, height);\n\n\t\t\tgl.drawArrays(gl.TRIANGLES, 0, rectangle.length / 2);\n\n\t\t\tgl.bindFramebuffer(gl.FRAMEBUFFER, null);\n\n\t\t}\n\n\t\tfunction attachTexture(name, register, index) {\n\t\t\tgl.activeTexture(register);\n\t\t\tgl.bindTexture(gl.TEXTURE_2D, textures[name]);\n\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);\n\n\t\t\tgl.uniform1i(gl.getUniformLocation(program, name), index);\n\t\t}\n\n\t\tfunction buildStripe(width) {\n\t\t\tif (stripes[width]) {\n\t\t\t\treturn stripes[width];\n\t\t\t}\n\t\t\tvar len = width,\n\t\t\t\tout = new Uint32Array(len);\n\t\t\tfor (var i = 0; i < len; i += 4) {\n\t\t\t\tout[i    ] = 0x000000ff;\n\t\t\t\tout[i + 1] = 0x0000ff00;\n\t\t\t\tout[i + 2] = 0x00ff0000;\n\t\t\t\tout[i + 3] = 0xff000000;\n\t\t\t}\n\t\t\treturn stripes[width] = new Uint8Array(out.buffer);\n\t\t}\n\n\t\tfunction initProgram(vertexShaderSource, fragmentShaderSource) {\n\t\t\tvar vertexShader = compileShader(gl.VERTEX_SHADER, vertexShaderSource);\n\t\t\tvar fragmentShader = compileShader(gl.FRAGMENT_SHADER, fragmentShaderSource);\n\n\t\t\tvar program = gl.createProgram();\n\t\t\tgl.attachShader(program, vertexShader);\n\t\t\tgl.attachShader(program, fragmentShader);\n\n\t\t\tgl.linkProgram(program);\n\t\t\tif (!gl.getProgramParameter(program, gl.LINK_STATUS)) {\n\t\t\t\tvar err = gl.getProgramInfoLog(program);\n\t\t\t\tgl.deleteProgram(program);\n\t\t\t\tthrow new Error('GL program linking failed: ' + err);\n\t\t\t}\n\n\t\t\treturn program;\n\t\t}\n\n\t\tfunction init() {\n\t\t\tif (WebGLFrameSink.stripe) {\n\t\t\t\tunpackProgram = initProgram(shaders.vertexStripe, shaders.fragmentStripe);\n\t\t\t\tunpackPositionLocation = gl.getAttribLocation(unpackProgram, 'aPosition');\n\n\t\t\t\tunpackTexturePositionBuffer = gl.createBuffer();\n\t\t\t\tvar textureRectangle = new Float32Array([\n\t\t\t\t\t0, 0,\n\t\t\t\t\t1, 0,\n\t\t\t\t\t0, 1,\n\t\t\t\t\t0, 1,\n\t\t\t\t\t1, 0,\n\t\t\t\t\t1, 1\n\t\t\t\t]);\n\t\t\t\tgl.bindBuffer(gl.ARRAY_BUFFER, unpackTexturePositionBuffer);\n\t\t\t\tgl.bufferData(gl.ARRAY_BUFFER, textureRectangle, gl.STATIC_DRAW);\n\n\t\t\t\tunpackTexturePositionLocation = gl.getAttribLocation(unpackProgram, 'aTexturePosition');\n\t\t\t\tstripeLocation = gl.getUniformLocation(unpackProgram, 'uStripe');\n\t\t\t\tunpackTextureLocation = gl.getUniformLocation(unpackProgram, 'uTexture');\n\t\t\t}\n\t\t\tprogram = initProgram(shaders.vertex, shaders.fragment);\n\n\t\t\tbuf = gl.createBuffer();\n\t\t\tgl.bindBuffer(gl.ARRAY_BUFFER, buf);\n\t\t\tgl.bufferData(gl.ARRAY_BUFFER, rectangle, gl.STATIC_DRAW);\n\n\t\t\tpositionLocation = gl.getAttribLocation(program, 'aPosition');\n\t\t\tlumaPositionBuffer = gl.createBuffer();\n\t\t\tlumaPositionLocation = gl.getAttribLocation(program, 'aLumaPosition');\n\t\t\tchromaPositionBuffer = gl.createBuffer();\n\t\t\tchromaPositionLocation = gl.getAttribLocation(program, 'aChromaPosition');\n\t\t}\n\n\t\t/**\n\t\t * Actually draw a frame.\n\t\t * @param {YUVFrame} buffer - YUV frame buffer object\n\t\t */\n\t\tself.drawFrame = function(buffer) {\n\t\t\tvar format = buffer.format;\n\n\t\t\tvar formatUpdate = (!program || canvas.width !== format.displayWidth || canvas.height !== format.displayHeight);\n\t\t\tif (formatUpdate) {\n\t\t\t\t// Keep the canvas at the right size...\n\t\t\t\tcanvas.width = format.displayWidth;\n\t\t\t\tcanvas.height = format.displayHeight;\n\t\t\t\tself.clear();\n\t\t\t}\n\n\t\t\tif (!program) {\n\t\t\t\tinit();\n\t\t\t}\n\n\t\t\tif (formatUpdate) {\n\t\t\t\tvar setupTexturePosition = function(buffer, location, texWidth) {\n\t\t\t\t\t// Warning: assumes that the stride for Cb and Cr is the same size in output pixels\n\t\t\t\t\tvar textureX0 = format.cropLeft / texWidth;\n\t\t\t\t\tvar textureX1 = (format.cropLeft + format.cropWidth) / texWidth;\n\t\t\t\t\tvar textureY0 = (format.cropTop + format.cropHeight) / format.height;\n\t\t\t\t\tvar textureY1 = format.cropTop / format.height;\n\t\t\t\t\tvar textureRectangle = new Float32Array([\n\t\t\t\t\t\ttextureX0, textureY0,\n\t\t\t\t\t\ttextureX1, textureY0,\n\t\t\t\t\t\ttextureX0, textureY1,\n\t\t\t\t\t\ttextureX0, textureY1,\n\t\t\t\t\t\ttextureX1, textureY0,\n\t\t\t\t\t\ttextureX1, textureY1\n\t\t\t\t\t]);\n\n\t\t\t\t\tgl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n\t\t\t\t\tgl.bufferData(gl.ARRAY_BUFFER, textureRectangle, gl.STATIC_DRAW);\n\t\t\t\t};\n\t\t\t\tsetupTexturePosition(\n\t\t\t\t\tlumaPositionBuffer,\n\t\t\t\t\tlumaPositionLocation,\n\t\t\t\t\tbuffer.y.stride);\n\t\t\t\tsetupTexturePosition(\n\t\t\t\t\tchromaPositionBuffer,\n\t\t\t\t\tchromaPositionLocation,\n\t\t\t\t\tbuffer.u.stride * format.width / format.chromaWidth);\n\t\t\t}\n\n\t\t\t// Create or update the textures...\n\t\t\tuploadTexture('uTextureY', buffer.y.stride, format.height, buffer.y.bytes);\n\t\t\tuploadTexture('uTextureCb', buffer.u.stride, format.chromaHeight, buffer.u.bytes);\n\t\t\tuploadTexture('uTextureCr', buffer.v.stride, format.chromaHeight, buffer.v.bytes);\n\n\t\t\tif (WebGLFrameSink.stripe) {\n\t\t\t\t// Unpack the textures after upload to avoid blocking on GPU\n\t\t\t\tunpackTexture('uTextureY', buffer.y.stride, format.height);\n\t\t\t\tunpackTexture('uTextureCb', buffer.u.stride, format.chromaHeight);\n\t\t\t\tunpackTexture('uTextureCr', buffer.v.stride, format.chromaHeight);\n\t\t\t}\n\n\t\t\t// Set up the rectangle and draw it\n\t\t\tgl.useProgram(program);\n\t\t\tgl.viewport(0, 0, canvas.width, canvas.height);\n\n\t\t\tattachTexture('uTextureY', gl.TEXTURE0, 0);\n\t\t\tattachTexture('uTextureCb', gl.TEXTURE1, 1);\n\t\t\tattachTexture('uTextureCr', gl.TEXTURE2, 2);\n\n\t\t\t// Set up geometry\n\t\t\tgl.bindBuffer(gl.ARRAY_BUFFER, buf);\n\t\t\tgl.enableVertexAttribArray(positionLocation);\n\t\t\tgl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);\n\n\t\t\t// Set up the texture geometry...\n\t\t\tgl.bindBuffer(gl.ARRAY_BUFFER, lumaPositionBuffer);\n\t\t\tgl.enableVertexAttribArray(lumaPositionLocation);\n\t\t\tgl.vertexAttribPointer(lumaPositionLocation, 2, gl.FLOAT, false, 0, 0);\n\n\t\t\tgl.bindBuffer(gl.ARRAY_BUFFER, chromaPositionBuffer);\n\t\t\tgl.enableVertexAttribArray(chromaPositionLocation);\n\t\t\tgl.vertexAttribPointer(chromaPositionLocation, 2, gl.FLOAT, false, 0, 0);\n\n\t\t\t// Aaaaand draw stuff.\n\t\t\tgl.drawArrays(gl.TRIANGLES, 0, rectangle.length / 2);\n\t\t};\n\n\t\tself.clear = function() {\n\t\t\tgl.viewport(0, 0, canvas.width, canvas.height);\n\t\t\tgl.clearColor(0.0, 0.0, 0.0, 0.0);\n\t\t\tgl.clear(gl.COLOR_BUFFER_BIT);\n\t\t};\n\n\t\tself.clear();\n\n\t\treturn self;\n\t}\n\n\t// For Windows; luminance and alpha textures are ssllooww to upload,\n\t// so we pack into RGBA and unpack in the shaders.\n\t//\n\t// This seems to affect all browsers on Windows, probably due to fun\n\t// mismatches between GL and D3D.\n\tWebGLFrameSink.stripe = (function() {\n\t\tif (navigator.userAgent.indexOf('Windows') !== -1) {\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t})();\n\n\tWebGLFrameSink.contextForCanvas = function(canvas) {\n\t\tvar options = {\n\t\t\t// Don't trigger discrete GPU in multi-GPU systems\n\t\t\tpreferLowPowerToHighPerformance: true,\n\t\t\tpowerPreference: 'low-power',\n\t\t\t// Don't try to use software GL rendering!\n\t\t\tfailIfMajorPerformanceCaveat: true,\n\t\t\t// In case we need to capture the resulting output.\n\t\t\tpreserveDrawingBuffer: true\n\t\t};\n\t\treturn canvas.getContext('webgl', options) || canvas.getContext('experimental-webgl', options);\n\t};\n\n\t/**\n\t * Static function to check if WebGL will be available with appropriate features.\n\t *\n\t * @returns {boolean} - true if available\n\t */\n\tWebGLFrameSink.isAvailable = function() {\n\t\tvar canvas = document.createElement('canvas'),\n\t\t\tgl;\n\t\tcanvas.width = 1;\n\t\tcanvas.height = 1;\n\t\ttry {\n\t\t\tgl = WebGLFrameSink.contextForCanvas(canvas);\n\t\t} catch (e) {\n\t\t\treturn false;\n\t\t}\n\t\tif (gl) {\n\t\t\tvar register = gl.TEXTURE0,\n\t\t\t\twidth = 4,\n\t\t\t\theight = 4,\n\t\t\t\ttexture = gl.createTexture(),\n\t\t\t\tdata = new Uint8Array(width * height),\n\t\t\t\ttexWidth = WebGLFrameSink.stripe ? (width / 4) : width,\n\t\t\t\tformat = WebGLFrameSink.stripe ? gl.RGBA : gl.LUMINANCE,\n\t\t\t\tfilter = WebGLFrameSink.stripe ? gl.NEAREST : gl.LINEAR;\n\n\t\t\tgl.activeTexture(register);\n\t\t\tgl.bindTexture(gl.TEXTURE_2D, texture);\n\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, filter);\n\t\t\tgl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, filter);\n\t\t\tgl.texImage2D(\n\t\t\t\tgl.TEXTURE_2D,\n\t\t\t\t0, // mip level\n\t\t\t\tformat, // internal format\n\t\t\t\ttexWidth,\n\t\t\t\theight,\n\t\t\t\t0, // border\n\t\t\t\tformat, // format\n\t\t\t\tgl.UNSIGNED_BYTE, //type\n\t\t\t\tdata // data!\n\t\t\t);\n\n\t\t\tvar err = gl.getError();\n\t\t\tif (err) {\n\t\t\t\t// Doesn't support luminance textures?\n\t\t\t\treturn false;\n\t\t\t} else {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t};\n\n\tWebGLFrameSink.prototype = Object.create(FrameSink.prototype);\n\n\tmodule.exports = WebGLFrameSink;\n})();\n\n\n//# sourceURL=webpack://agora-cef-sdk/./node_modules/yuv-canvas/src/WebGLFrameSink.js?");

/***/ }),

/***/ "./node_modules/yuv-canvas/src/YCbCr.js":
/*!**********************************************!*\
  !*** ./node_modules/yuv-canvas/src/YCbCr.js ***!
  \**********************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

eval("/*\nCopyright (c) 2014-2019 Brion Vibber <brion@pobox.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n(function() {\n\t\"use strict\";\n\n\tvar depower = __webpack_require__(/*! ./depower.js */ \"./node_modules/yuv-canvas/src/depower.js\");\n\n\t/**\n\t * Basic YCbCr->RGB conversion\n\t *\n\t * @author Brion Vibber <brion@pobox.com>\n\t * @copyright 2014-2019\n\t * @license MIT-style\n\t *\n\t * @param {YUVFrame} buffer - input frame buffer\n\t * @param {Uint8ClampedArray} output - array to draw RGBA into\n\t * Assumes that the output array already has alpha channel set to opaque.\n\t */\n\tfunction convertYCbCr(buffer, output) {\n\t\tvar width = buffer.format.width | 0,\n\t\t\theight = buffer.format.height | 0,\n\t\t\thdec = depower(buffer.format.width / buffer.format.chromaWidth) | 0,\n\t\t\tvdec = depower(buffer.format.height / buffer.format.chromaHeight) | 0,\n\t\t\tbytesY = buffer.y.bytes,\n\t\t\tbytesCb = buffer.u.bytes,\n\t\t\tbytesCr = buffer.v.bytes,\n\t\t\tstrideY = buffer.y.stride | 0,\n\t\t\tstrideCb = buffer.u.stride | 0,\n\t\t\tstrideCr = buffer.v.stride | 0,\n\t\t\toutStride = width << 2,\n\t\t\tYPtr = 0, Y0Ptr = 0, Y1Ptr = 0,\n\t\t\tCbPtr = 0, CrPtr = 0,\n\t\t\toutPtr = 0, outPtr0 = 0, outPtr1 = 0,\n\t\t\tcolorCb = 0, colorCr = 0,\n\t\t\tmultY = 0, multCrR = 0, multCbCrG = 0, multCbB = 0,\n\t\t\tx = 0, y = 0, xdec = 0, ydec = 0;\n\n\t\tif (hdec == 1 && vdec == 1) {\n\t\t\t// Optimize for 4:2:0, which is most common\n\t\t\toutPtr0 = 0;\n\t\t\toutPtr1 = outStride;\n\t\t\tydec = 0;\n\t\t\tfor (y = 0; y < height; y += 2) {\n\t\t\t\tY0Ptr = y * strideY | 0;\n\t\t\t\tY1Ptr = Y0Ptr + strideY | 0;\n\t\t\t\tCbPtr = ydec * strideCb | 0;\n\t\t\t\tCrPtr = ydec * strideCr | 0;\n\t\t\t\tfor (x = 0; x < width; x += 2) {\n\t\t\t\t\tcolorCb = bytesCb[CbPtr++] | 0;\n\t\t\t\t\tcolorCr = bytesCr[CrPtr++] | 0;\n\n\t\t\t\t\t// Quickie YUV conversion\n\t\t\t\t\t// https://en.wikipedia.org/wiki/YCbCr#ITU-R_BT.2020_conversion\n\t\t\t\t\t// multiplied by 256 for integer-friendliness\n\t\t\t\t\tmultCrR   = (409 * colorCr | 0) - 57088 | 0;\n\t\t\t\t\tmultCbCrG = (100 * colorCb | 0) + (208 * colorCr | 0) - 34816 | 0;\n\t\t\t\t\tmultCbB   = (516 * colorCb | 0) - 70912 | 0;\n\n\t\t\t\t\tmultY = 298 * bytesY[Y0Ptr++] | 0;\n\t\t\t\t\toutput[outPtr0    ] = (multY + multCrR) >> 8;\n\t\t\t\t\toutput[outPtr0 + 1] = (multY - multCbCrG) >> 8;\n\t\t\t\t\toutput[outPtr0 + 2] = (multY + multCbB) >> 8;\n\t\t\t\t\toutPtr0 += 4;\n\n\t\t\t\t\tmultY = 298 * bytesY[Y0Ptr++] | 0;\n\t\t\t\t\toutput[outPtr0    ] = (multY + multCrR) >> 8;\n\t\t\t\t\toutput[outPtr0 + 1] = (multY - multCbCrG) >> 8;\n\t\t\t\t\toutput[outPtr0 + 2] = (multY + multCbB) >> 8;\n\t\t\t\t\toutPtr0 += 4;\n\n\t\t\t\t\tmultY = 298 * bytesY[Y1Ptr++] | 0;\n\t\t\t\t\toutput[outPtr1    ] = (multY + multCrR) >> 8;\n\t\t\t\t\toutput[outPtr1 + 1] = (multY - multCbCrG) >> 8;\n\t\t\t\t\toutput[outPtr1 + 2] = (multY + multCbB) >> 8;\n\t\t\t\t\toutPtr1 += 4;\n\n\t\t\t\t\tmultY = 298 * bytesY[Y1Ptr++] | 0;\n\t\t\t\t\toutput[outPtr1    ] = (multY + multCrR) >> 8;\n\t\t\t\t\toutput[outPtr1 + 1] = (multY - multCbCrG) >> 8;\n\t\t\t\t\toutput[outPtr1 + 2] = (multY + multCbB) >> 8;\n\t\t\t\t\toutPtr1 += 4;\n\t\t\t\t}\n\t\t\t\toutPtr0 += outStride;\n\t\t\t\toutPtr1 += outStride;\n\t\t\t\tydec++;\n\t\t\t}\n\t\t} else {\n\t\t\toutPtr = 0;\n\t\t\tfor (y = 0; y < height; y++) {\n\t\t\t\txdec = 0;\n\t\t\t\tydec = y >> vdec;\n\t\t\t\tYPtr = y * strideY | 0;\n\t\t\t\tCbPtr = ydec * strideCb | 0;\n\t\t\t\tCrPtr = ydec * strideCr | 0;\n\n\t\t\t\tfor (x = 0; x < width; x++) {\n\t\t\t\t\txdec = x >> hdec;\n\t\t\t\t\tcolorCb = bytesCb[CbPtr + xdec] | 0;\n\t\t\t\t\tcolorCr = bytesCr[CrPtr + xdec] | 0;\n\n\t\t\t\t\t// Quickie YUV conversion\n\t\t\t\t\t// https://en.wikipedia.org/wiki/YCbCr#ITU-R_BT.2020_conversion\n\t\t\t\t\t// multiplied by 256 for integer-friendliness\n\t\t\t\t\tmultCrR   = (409 * colorCr | 0) - 57088 | 0;\n\t\t\t\t\tmultCbCrG = (100 * colorCb | 0) + (208 * colorCr | 0) - 34816 | 0;\n\t\t\t\t\tmultCbB   = (516 * colorCb | 0) - 70912 | 0;\n\n\t\t\t\t\tmultY = 298 * bytesY[YPtr++] | 0;\n\t\t\t\t\toutput[outPtr    ] = (multY + multCrR) >> 8;\n\t\t\t\t\toutput[outPtr + 1] = (multY - multCbCrG) >> 8;\n\t\t\t\t\toutput[outPtr + 2] = (multY + multCbB) >> 8;\n\t\t\t\t\toutPtr += 4;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tmodule.exports = {\n\t\tconvertYCbCr: convertYCbCr\n\t};\n})();\n\n\n//# sourceURL=webpack://agora-cef-sdk/./node_modules/yuv-canvas/src/YCbCr.js?");

/***/ }),

/***/ "./node_modules/yuv-canvas/src/depower.js":
/*!************************************************!*\
  !*** ./node_modules/yuv-canvas/src/depower.js ***!
  \************************************************/
/***/ (function(module) {

eval("/*\nCopyright (c) 2014-2016 Brion Vibber <brion@pobox.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n(function() {\n  \"use strict\";\n\n  /**\n   * Convert a ratio into a bit-shift count; for instance a ratio of 2\n   * becomes a bit-shift of 1, while a ratio of 1 is a bit-shift of 0.\n   *\n   * @author Brion Vibber <brion@pobox.com>\n   * @copyright 2016\n   * @license MIT-style\n   *\n   * @param {number} ratio - the integer ratio to convert.\n   * @returns {number} - number of bits to shift to multiply/divide by the ratio.\n   * @throws exception if given a non-power-of-two\n   */\n  function depower(ratio) {\n    var shiftCount = 0,\n      n = ratio >> 1;\n    while (n != 0) {\n      n = n >> 1;\n      shiftCount++\n    }\n    if (ratio !== (1 << shiftCount)) {\n      throw 'chroma plane dimensions must be power of 2 ratio to luma plane dimensions; got ' + ratio;\n    }\n    return shiftCount;\n  }\n\n  module.exports = depower;\n})();\n\n\n//# sourceURL=webpack://agora-cef-sdk/./node_modules/yuv-canvas/src/depower.js?");

/***/ }),

/***/ "./node_modules/yuv-canvas/src/yuv-canvas.js":
/*!***************************************************!*\
  !*** ./node_modules/yuv-canvas/src/yuv-canvas.js ***!
  \***************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

eval("/*\nCopyright (c) 2014-2016 Brion Vibber <brion@pobox.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n(function() {\n  \"use strict\";\n\n  var FrameSink = __webpack_require__(/*! ./FrameSink.js */ \"./node_modules/yuv-canvas/src/FrameSink.js\"),\n    SoftwareFrameSink = __webpack_require__(/*! ./SoftwareFrameSink.js */ \"./node_modules/yuv-canvas/src/SoftwareFrameSink.js\"),\n    WebGLFrameSink = __webpack_require__(/*! ./WebGLFrameSink.js */ \"./node_modules/yuv-canvas/src/WebGLFrameSink.js\");\n\n  /**\n   * @typedef {Object} YUVCanvasOptions\n   * @property {boolean} webGL - Whether to use WebGL to draw to the canvas and accelerate color space conversion. If left out, defaults to auto-detect.\n   */\n\n  var YUVCanvas = {\n    FrameSink: FrameSink,\n\n    SoftwareFrameSink: SoftwareFrameSink,\n\n    WebGLFrameSink: WebGLFrameSink,\n\n    /**\n     * Attach a suitable FrameSink instance to an HTML5 canvas element.\n     *\n     * This will take over the drawing context of the canvas and may turn\n     * it into a WebGL 3d canvas if possible. Do not attempt to use the\n     * drawing context directly after this.\n     *\n     * @param {HTMLCanvasElement} canvas - HTML canvas element to attach to\n     * @param {YUVCanvasOptions} options - map of options\n     * @returns {FrameSink} - instance of suitable subclass.\n     */\n    attach: function(canvas, options) {\n      options = options || {};\n      var webGL = ('webGL' in options) ? options.webGL : WebGLFrameSink.isAvailable();\n      if (webGL) {\n        return new WebGLFrameSink(canvas, options);\n      } else {\n        return new SoftwareFrameSink(canvas, options);\n      }\n    }\n  };\n\n  module.exports = YUVCanvas;\n})();\n\n\n//# sourceURL=webpack://agora-cef-sdk/./node_modules/yuv-canvas/src/yuv-canvas.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		if(__webpack_module_cache__[moduleId]) {
/******/ 			return __webpack_module_cache__[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	!function() {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = function(exports, definition) {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	}();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	!function() {
/******/ 		__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }
/******/ 	}();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	!function() {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = function(exports) {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	}();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/AgoraRtcEngine.ts");
/******/ 	
/******/ 	return __webpack_exports__;
/******/ })()
;
});